{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3997","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3998","fieldValue":" This paper presents two single-channel speech dereverberation methods to enhance the quality of speech signals that have been recorded in an enclosed space. For both methods, the room acoustics are modeled using a non-negative approximation of the convolutive transfer function (N-CTF), and to additionally exploit the spectral properties of the speech signal, such as the low-rank nature of the speech spectrogram, the speech spectrogram is modeled using non-negative matrix factorization (NMF). Two methods are described to combine the N-CTF and NMF models. In the first method, referred to as the integrated method, a cost function is constructed by directly integrating the speech NMF model into the N-CTF model, while in the second method, referred to as the weighted method, the N-CTF and NMF based cost functions are weighted and summed. Efficient update rules are derived to solve both optimization problems. In addition, an extension of the integrated method is presented, which exploits the temporal dependencies of the speech signal. Several experiments are performed on reverberant speech signals with and without background noise, where the integrated method yields a considerably higher speech quality than the baseline N-CTF method and a state-of-the-art spectral enhancement method. Moreover, the experimental results indicate that the weighted method can even lead to a better performance in terms of instrumental quality measures, but that the optimal weighting parameter depends on the room acoustics and the utilized NMF model. Modeling the temporal dependencies in the integrated method was found to be useful only for highly reverberant conditions."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/3998","fieldValue":"Speech dereverberation using non-negative convolutive transfer function and spectro-temporal modeling"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3998","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3998","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3999","fieldValue":" Smartphones can enable monitoring signs of distress as a human goes about his daily routine. Motivated by this possibility of 24x7 distress detection, we investigate detection of screaming and crying in urban environments, which we categorize into the contexts of indoors (home and office), outdoors, human conversation, large human gatherings, machinery, and audio from multimedia devices. Prior works are often restricted to specific environments or controlled settings. We propose a novel two-stage supervised learning based method, with tunable decision parameters for each stage, to achieve a desired true distress (scream and cry) detection rate (DR) and false alarm rate (FAR). We observe that the choice of the parameters is a function of the signal-to-noise ratio (SNR) of the distress signal, which is the ratio of the power of the distress signal to the power of the context audio. In the absence of SNR information, we show that a simple SNR estimation scheme performs well. Alternately, we show how the decision parameters can be selected based on the context estimated by the method. We show the results of testing the proposal over hundred hours of audio data recorded by the smartphones of ten volunteers as they went about their daily routines. Achieved performance is exemplified by a DR of 93.16% and a FAR of 4.76% at a SNR of 20 dB. The corresponding values for a SNR of 10 dB are 84.13% and 4.77%. Finally, we compare with, which also deals with audio event detection in noisy environments."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3999","fieldValue":"MFCC"}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3999","fieldValue":"SVM"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3999","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3999","fieldValue":"ACM"}