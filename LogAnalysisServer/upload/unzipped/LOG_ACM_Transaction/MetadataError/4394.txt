{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24162","fieldValue":" Community question answering (CQA) sites use a collaborative paradigm to satisfy complex information needs. Although the task of matching questions to their best answers has been tackled for more than a decade, the social question-answering practice is a complex process. The factors influencing the accuracy of question-answer matching are many and hard to disentangle. We approach the task from an application-oriented perspective, probing the space of several dimensions relevant to this problem: features, algorithms, and topics. We gather under a learning to rank framework the most extensive feature set used in literature to date, including 225 features from five different families. We test the power of such features in predicting the best answer to a question on the largest dataset from Yahoo Answers used for this task so far (40M answers) and provide a faceted analysis of the results along different topical areas and question types. We propose a novel family of distributional semantics measures that most of the time can seamlessly replace widely used linguistic similarity features, being more than one order of magnitude faster to compute and providing greater predictive power. The best feature set reaches an improvement between 11&percnt; and 26&percnt; in P@1 compared to recent well-established state-of-the-art methods."}{"fieldName":"dc.description","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/24162","fieldValue":"Author Affiliation: IBM Watson, NY, USA (Molino, Piero); Yahoo Labs London, UK (Aiello, Luca Maria); Universit&#225; degli Studi di Bari Aldo Moro, Italy (Lops, Pasquale)"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24162","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24162","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24163","fieldValue":" As location-based social network (LBSN) services become increasingly popular, trip recommendation that recommends a sequence of points of interest (POIs) to visit for a user emerges as one of many important applications of LBSNs. Personalized trip recommendation tailors to usersâ\u20AC™ specific tastes by learning from past check-in behaviors of users and their peers. Finding the optimal trip that maximizes userâ\u20AC™s experiences for a given time budget constraint is an NP-hard problem and previous solutions do not consider three practical and important constraints. One constraint is POI availability, where a POI may be only available during a certain time window. Another constraint is uncertain traveling time, where the traveling time between two POIs is uncertain. In addition, the diversity of the POIs included in the trip plays an important role in userâ\u20AC™s final adoptions. This work presents efficient solutions to personalized trip recommendation by incorporating these constraints and leveraging them to prune the search space. We evaluated the efficiency and effectiveness of our solutions on real-life LBSN datasets."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/24163","fieldValue":"Trip Recommendation Meets Real-World Constraints: POI Availability, Diversity, and Traveling Time Uncertainty"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24163","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24163","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24164","fieldValue":" A Question Answering (QA) system is concerned with building a system that automatically answer questions posed by humans in a natural language. Compared to other languages, little effort was directed towards QA systems for Arabic. Due to the difficulty of handling why-questions, most Arabic QA systems tend to ignore it. In this article, we specifically address the why-question for Arabic using two different approaches and compare their performance and the quality of their answer. The first is the baseline approach, a generic method that is used to answer all types of questions, including factoid; and for the second approach, we use Rhetorical Structure Theory (RST). We evaluate both schemes using a corpus of 700 textual documents in different genres collected from Open Source Arabic Corpora (OSAC), and a set of 100 question-answer pairs. Overall, the performance measures of recall, precision, and c@1 was 68&percnt; (all three measures) for the baseline approach, and 71&percnt;, 78&percnt;, and 77.4&percnt;, respectively, for the RST-based approach. The recently introduced extension of the accuracy, the c@1 measure, rewards unanswered questions over those wrongly answered."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24164","fieldValue":"RST"}