{"fieldName":"dc.relation.haspart","informationCode":"ERR_FORMAT_HASPART","handle":"12345678_acm\/1050","fieldValue":"[{\"visible\":false,\"sortKey\":\"11\",\"expandable\":true,\"handle\":\"12345678_acm\/1061\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 11\"},{\"visible\":false,\"sortKey\":\"10\",\"expandable\":true,\"handle\":\"12345678_acm\/1060\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 10\"},{\"visible\":false,\"sortKey\":\"9\",\"expandable\":true,\"handle\":\"12345678_acm\/1059\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 9\"},{\"visible\":false,\"sortKey\":\"8\",\"expandable\":true,\"handle\":\"12345678_acm\/1058\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 8\"},{\"visible\":false,\"sortKey\":\"7\",\"expandable\":true,\"handle\":\"12345678_acm\/1057\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 7\"},{\"visible\":false,\"sortKey\":\"6\",\"expandable\":true,\"handle\":\"12345678_acm\/1056\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 6\"},{\"visible\":false,\"sortKey\":\"5\",\"expandable\":true,\"handle\":\"12345678_acm\/1055\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 5\"},{\"visible\":false,\"sortKey\":\"4\",\"expandable\":true,\"handle\":\"12345678_acm\/1054\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 4\"},{\"visible\":false,\"sortKey\":\"3\",\"expandable\":true,\"handle\":\"12345678_acm\/1053\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 3\"},{\"visible\":false,\"sortKey\":\"2\",\"expandable\":true,\"handle\":\"12345678_acm\/1052\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 2\"},{\"visible\":false,\"sortKey\":\"1\",\"expandable\":true,\"handle\":\"12345678_acm\/1051\",\"title\":\"ACM Transactions on Autonomous and Adaptive Systems (TAAS) : Volume 1\"}]"}{"fieldName":"dc.relation.haspart","informationCode":"ERR_FORMAT_HASPART","handle":"12345678_acm\/6099","fieldValue":"[{\"visible\":false,\"sortKey\":\"December 2015\",\"expandable\":true,\"handle\":\"12345678_acm\/6163\",\"title\":\"Issue 4, December 2015\"},{\"visible\":false,\"sortKey\":\"May 2015\",\"expandable\":true,\"handle\":\"12345678_acm\/6162\",\"title\":\"Issue 3(Special Issue on Embedded Platforms for Crypto and Regular Papers), May 2015\"},{\"visible\":false,\"sortKey\":\"March 2015\",\"expandable\":true,\"handle\":\"12345678_acm\/6161\",\"title\":\"Issue 2, March 2015\"},{\"visible\":false,\"sortKey\":\"January 2015\",\"expandable\":true,\"handle\":\"12345678_acm\/6160\",\"title\":\"Issue 1, January 2015\"}]"}{"fieldName":"dc.relation.haspart","informationCode":"ERR_FORMAT_HASPART","handle":"12345678_acm\/6100","fieldValue":"[{\"visible\":false,\"sortKey\":\"August 2016\",\"expandable\":true,\"handle\":\"12345678_acm\/6168\",\"title\":\"Issue 4(Special Issue on ESWEEK2015 and Regular Papers), August 2016\"},{\"visible\":false,\"sortKey\":\"July 2016\",\"expandable\":true,\"handle\":\"12345678_acm\/6167\",\"title\":\"Issue 3, July 2016\"},{\"visible\":false,\"sortKey\":\"May 2016\",\"expandable\":true,\"handle\":\"12345678_acm\/6166\",\"title\":\"Issue 2(Special Issue on Innovative Design, Special Issue on MEMOCODE 2014 and Special Issue on M2M\/IOT), May 2016\"},{\"visible\":false,\"sortKey\":\"February 2016\",\"expandable\":true,\"handle\":\"12345678_acm\/6165\",\"title\":\"Issue 1, February 2016\"},{\"visible\":false,\"sortKey\":\"December 2015\",\"expandable\":true,\"handle\":\"12345678_acm\/6164\",\"title\":\"Issue 1, December 2015\"}]"}{"fieldName":"dc.relation.haspart","informationCode":"ERR_FORMAT_HASPART","handle":"12345678_acm\/6101","fieldValue":"[{\"visible\":false,\"sortKey\":\"December 2016\",\"expandable\":true,\"handle\":\"12345678_acm\/6170\",\"title\":\"Issue 2, December 2016\"},{\"visible\":false,\"sortKey\":\"October 2016\",\"expandable\":true,\"handle\":\"12345678_acm\/6169\",\"title\":\"Issue 1, October 2016\"}]"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6171","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6171","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6172","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6172","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6173","fieldValue":" This article presents a technique for the efficient compiler management of software-exposed heterogeneous memory. In many lower-end embedded chips, often used in microcontrollers and DSP processors, heterogeneous memory units such as scratch-pad SRAM, internal DRAM, external DRAM, and ROM are visible directly to the software, without automatic management by a hardware caching mechanism. Instead, the memory units are mapped to different portions of the address space. Caches are avoided due to their cost and power consumption, and because they make it difficult to guarantee real-time performance. For this important class of embedded chips, the allocation of data to different memory units to maximize performance is the responsibility of the software.Current practice typically leaves it to the programmer to partition the data among different memory units. We present a compiler strategy that automatically partitions the data among the memory units. We show that this strategy is optimal, relative to the profile run, among all static partitions for global and stack data. For the first time, our allocation scheme for stacks distributes the stack among multiple memory units. For global and stack data, the scheme is provably equal to or better than any other compiler scheme or set of programmer annotations. Results from our benchmarks show a 44.2&percnt; reduction in runtime from using our distributed stack strategy vs. using a unified stack, and a further 11.8&percnt; reduction in runtime from using a linear optimization strategy for allocation vs. a simpler greedy strategy; both in the case of the SRAM size being 20&percnt; of the total data size. For some programs, less than 5&percnt; of data in SRAM achieves a similar speedup."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6173","fieldValue":"ACM"}