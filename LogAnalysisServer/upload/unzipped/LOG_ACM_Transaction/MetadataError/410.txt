{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12300","fieldValue":"ACM"}{"fieldName":"dc.relation.haspart","informationCode":"ERR_FORMAT_HASPART","handle":"12345678_acm\/2125","fieldValue":"[{\"visible\":false,\"sortKey\":\"November 2007\",\"expandable\":true,\"handle\":\"12345678_acm\/2145\",\"title\":\"Issue 4, November 2007\"},{\"visible\":false,\"sortKey\":\"August 2007\",\"expandable\":true,\"handle\":\"12345678_acm\/2144\",\"title\":\"Issue 3, August 2007\"},{\"visible\":false,\"sortKey\":\"May 2007\",\"expandable\":true,\"handle\":\"12345678_acm\/2143\",\"title\":\"Issue 2, May 2007\"},{\"visible\":false,\"sortKey\":\"February 2007\",\"expandable\":true,\"handle\":\"12345678_acm\/2142\",\"title\":\"Issue 1, February 2007\"}]"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12301","fieldValue":" Wireless transmission of a single bit can require over 1000 times more energy than a single computation. It can therefore be beneficial to perform additional computation to reduce the number of bits transmitted. If the energy required to compress data is less than the energy required to send it, there is a net energy savings and an increase in battery life for portable computers. This article presents a study of the energy savings possible by losslessly compressing data prior to transmission. A variety of algorithms were measured on a StrongARM SA-110 processor. This work demonstrates that, with several typical compression algorithms, there is a actually a net energy increase when compression is applied before transmission. Reasons for this increase are explained and suggestions are made to avoid it. One such energy-aware suggestion is asymmetric compression, the use of one compression algorithm on the transmit side and a different algorithm for the receive path. By choosing the lowest-energy compressor and decompressor on the test platform, overall energy to send and receive data can be reduced by 11&percnt; compared with a well-chosen symmetric pair, or up to 57&percnt; over the default symmetric zlib scheme."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12301","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12301","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12302","fieldValue":" This article presents the design, implementation, and evaluation of EScheduler, an energy-efficient soft real-time CPU scheduler for multimedia applications running on a mobile device. EScheduler seeks to minimize the total energy consumed by the device while meeting multimedia timing requirements. To achieve this goal, EScheduler integrates dynamic voltage scaling into the traditional soft real-time CPU scheduling: It decides at what CPU speed to execute applications in addition to when to execute what applications. EScheduler makes these scheduling decisions based on the probability distribution of cycle demand of multimedia applications and obtains their demand distribution via online profiling.We have implemented EScheduler in the Linux kernel and evaluated it on a laptop with a variable-speed CPU and typical multimedia codecs. Our experimental results show four findings: first, the cycle demand distribution of our studied codecs is stable or changes slowly. This stability implies the feasibility to perform our proposed energy-efficient scheduling with low overhead. Second, EScheduler delivers soft performance guarantees to these codecs by bounding their deadline miss ratio under the application-specific performance requirements. Third, EScheduler reduces the total energy of the laptop by 14.4&percnt; to 37.2&percnt; relative to the scheduling algorithm without voltage scaling and by 2&percnt; to 10.5&percnt; relative to voltage scaling algorithms without considering the demand distribution. Finally, EScheduler saves energy by 2&percnt; to 5&percnt; by explicitly considering the discrete CPU speeds and the corresponding total power of the whole laptop, rather than assuming continuous speeds and cubic speed-power relationship."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12302","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12302","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12303","fieldValue":" This article presents a new mechanism that enables applications to run correctly when device drivers fail. Because device drivers are the principal failing component in most systems, reducing driver-induced failures greatly improves overall reliability. Earlier work has shown that an operating system can survive driver failures &lsqb;Swift et al. 2005&rsqb;, but the applications that depend on them cannot. Thus, while operating system reliability was greatly improved, application reliability generally was not.To remedy this situation, we introduce a new operating system mechanism called a shadow driver. A shadow driver monitors device drivers and transparently recovers from driver failures. Moreover, it assumes the role of the failed driver during recovery. In this way, applications using the failed driver, as well as the kernel itself, continue to function as expected.We implemented shadow drivers for the Linux operating system and tested them on over a dozen device drivers. Our results show that applications and the OS can indeed survive the failure of a variety of device drivers. Moreover, shadow drivers impose minimal performance overhead. Lastly, they can be introduced with only modest changes to the OS kernel and with no changes at all to existing device drivers."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12303","fieldValue":"I\/O"}