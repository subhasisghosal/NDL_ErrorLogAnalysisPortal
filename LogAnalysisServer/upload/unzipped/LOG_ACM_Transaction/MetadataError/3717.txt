{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/21952","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/21953","fieldValue":" The modern processor landscape is a varied and diverse community. As such, developers need a way to quickly and fairly compare various devices for use with particular applications. This article expands the authorsâ\u20AC™ previously published computational-density metrics and presents an analysis of a new generation of various device architectures, including CPU, DSP, FPGA, GPU, and hybrid architectures. Also, new memory metrics are added to expand the existing suite of metrics to characterize the memory resources on various processing devices. Finally, a new relational metric, realizable utilization (RU), is introduced, which quantifies the fraction of the computational density metric that an application achieves within an individual implementation. The RU metric can be used to provide valuable feedback to application developers and architecture designers by highlighting the upper bound on specific application optimization and providing a quantifiable measure of theoretical and realizable performance. Overall, the analysis in this article quantifies the performance tradeoffs among the architectures studied, the memory characteristics of different device types, and the efficiency of device architectures."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/21953","fieldValue":"Analysis of Fixed, Reconfigurable, and Hybrid Devices with Computational, Memory, I\/O, & Realizable-Utilization Metrics"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/21953","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/21953","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/21954","fieldValue":"Chao, Hung-Lin"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/21954","fieldValue":"Tung, Sheng-Ya"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/21954","fieldValue":"Hsiung, Pao-Ann"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/21954","fieldValue":" Network-on-Chip (NoC) has been proposed as a promising communication architecture to replace the dedicated interconnections and shared buses for future embedded system platforms. In such a parallel platform, mapping application tasks to the NoC is a key issue because it affects throughput significantly due to the problem of communication congestion. Increased communication latency, low system performance, and low resource utilization are some side-effects of a bad mapping. Current mapping algorithms either do not consider link utilizations or consider only the current utilizations. Besides, to design an efficient NoC platform, mapping task to computation nodes and scheduling communication should be taken into consideration. In this work, we propose an efficient algorithm for dynamic task mapping with congestion speculation (DTMCS) that not only includes the conventional application mapping, but also further considers future traffic patterns based on the link utilization. The proposed algorithm can reduce overall congestion, instead of only improving the current packet blocking situation. Our experiment results have demonstrated that compared to the state-of-the-art congestion-aware Path Load algorithm, the proposed DTMCS algorithm can reduce up to 40.5&percnt; of average communication latency, while the maximal communication latency can be reduced by up to 67.7&percnt;."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/21954","fieldValue":"ACM"}