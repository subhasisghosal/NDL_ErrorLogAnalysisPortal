{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6349","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6349","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6350","fieldValue":" We have devised an algorithm for minimal placement of bank selections in partitioned memory architectures. This algorithm is parameterizable for a chosen metric, such as speed, space, or energy. Bank switching is a technique that increases the code and data memory in microcontrollers without extending the address buses. Given a program in which variables have been assigned to data banks, we present a novel optimization technique that minimizes the overhead of bank switching through cost-effective placement of bank selection instructions. The placement is controlled by a number of different objectives, such as runtime, low power, small code size or a combination of these parameters. We have formulated the minimal placement of bank selection instructions as a discrete optimization problem that is mapped to a partitioned boolean quadratic programming (PBQP) problem. We implemented the optimization as part of a PIC Microchip backend and evaluated the approach for several optimization objectives. Our benchmark suite comprises programs from MiBench and DSPStone plus a microcontroller real-time kernel and drivers for microcontroller hardware devices. Our optimization achieved a reduction in program memory space of between 2.7 and 18.2&percent;, and an overall improvement with respect to instruction cycles between 5.0 and 28.8&percent;. Our optimization achieved the minimal solution for all benchmark programs. We investigated the scalability of our approach toward the requirements of future generations of microcontrollers. This study was conducted as a worst-case analysis on the entire MiBench suite. Our results show that our optimization (1) scales well to larger numbers of memory banks, (2) scales well to the larger problem sizes that will become feasible with future microcontrollers, and (3) achieves minimal placement for more than 72&percent; of all functions from MiBench."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6350","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6350","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6351","fieldValue":" One scarce resource in embedded systems is memory. Multitasking makes the lack of memory problem even worse. Most current embedded systems, which do not provide virtual memory, simply divide physical memory and evenly assign contiguous memory chunks to multiple applications. Such simple memory management can frequently cause the lack of available memory for some applications, while others are not using the full amount of assigned memory. To overcome inefficiency in current memory management, we present an efficient heap management scheme that allows multiple applications to share heap space. To reduce overall heap memory usage, applications adaptively acquire subheaps out of shared pool of memory and release surplus subheaps to shared pool. As a result, applications see noncontiguous multiple subheaps as a heap in their address space. We target Java applications to implement our heap-sharing scheme in the KVM from Sun Microsystems. To protect fragmented heap space with a limited number of regions in memory protection unit (MPU), we maintain only a limited number of subheaps. We experimentally evaluate our heap management scheme with J2ME MIDP applications. Our static and dynamic schemes reduce heap memory usage, on average, by 30 and 27&percent;, respectively. For both schemes, overheads are kept low. The execution times in our schemes are increased only by 0.01&percent; for static scheme and 0.35&percent; for dynamic scheme, on average."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6351","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6351","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/6352","fieldValue":"So, Hayden Kwok-Hay"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6352","fieldValue":" This paper explores the design and implementation of BORPH, an operating system designed for FPGA-based reconfigurable computers. Hardware designs execute as normal UNIX processes under BORPH, having access to standard OS services, such as file system support. Hardware and software components of user designs may, therefore, run as communicating processes within BORPH's runtime environment. The familiar language independent UNIX kernel interface facilitates easy design reuse and rapid application development. To develop hardware designs, a Simulink-based design flow that integrates with BORPH is employed. Performances of BORPH on two on-chip systems implemented on a BEE2 platform are compared."}