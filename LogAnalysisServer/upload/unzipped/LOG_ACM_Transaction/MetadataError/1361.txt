{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/15202","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/15202","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/15203","fieldValue":" Many key problems in computer graphics require the computation of integrals. Due to the nature of the integrand and of the domain of integration, these integrals seldom can be computed analytically. As a result, numerical techniques are used to find approximate solutions to these problems. While the numerical analysis literature offers many integration techniques, the choice of which method to use for specific computer graphic problems is a difficult one. This choice must be driven by the numerical efficiency of the method, and ultimately, by its visual impact on the computed image. In this paper, we begin to address these issues by methodically analyzing deterministic and stochastic numerical techniques and their application to the type of one-dimensional problems that occur in computer graphics, especially in the context of linear light source integration. In addition to traditional methods such as Gauss-Legendre quadratures, we also examine Voronoi diagram-based sampling, jittered quadratures, random offset quadratures, weighted Monte Carlo, and a newly introduced method of compounding known as a difficulty driven compound quadrature.We compare the effectiveness of these methods using a three-pronged approach. First, we compare the frequency domain characteristics of all the methods using periodograms. Next, applying ideas found in the numerical analysis literature, we examine the numerical and visual performance profiles of these methods for seven different one-parameter problem families. We then present results from the application of the methods for the example of linear light sources. Finally, we summarize the relative effectiveness of the methods surveyed, showing the potential power of difficulty-driven compound quadratures."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/15203","fieldValue":"On numerical solutions to one-dimensional integration problems with applications to linear light sources"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/15203","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/15203","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/15204","fieldValue":" We introduce a new set of illumination basis functions designed for lighting bumpy surfaces. This lighting includes shadowing and interreflection. To create an image with a new light direction, only a linear combination of precomputed textures is required. This is possible by using a carefully selected set of steerable basis functions. Steerable basis lights have the property that they allow lights to move continuously without jarring visual artifacts. The new basis lights are shown to produce images of high visual quality with as few as 49 basis textures."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/15204","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/15204","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/2440","fieldValue":" Publishing data for analysis from a table containing personal records, while maintaining individual privacy, is a problem of increasing importance today. The traditional approach of deidentifying records is to remove identifying fields such as social security number, name, etc. However, recent research has shown that a large fraction of the U.S. population can be identified using nonkey attributes (called quasi-identifiers) such as date of birth, gender, and zip code. The k-anonymity model protects privacy via requiring that nonkey attributes that leak information are suppressed or generalized so that, for every record in the modified table, there are at least kâˆ\u20191 other records having exactly the same values for quasi-identifiers. We propose a new method for anonymizing data records, where quasi-identifiers of data records are first clustered and then cluster centers are published. To ensure privacy of the data records, we impose the constraint that each cluster must contain no fewer than a prespecified number of data records. This technique is more general since we have a much larger choice for cluster centers than k-anonymity. In many cases, it lets us release a lot more information without compromising privacy. We also provide constant factor approximation algorithms to come up with such a clustering. This is the first set of algorithms for the anonymization problem where the performance is independent of the anonymity parameter k. We further observe that a few outlier points can significantly increase the cost of anonymization. Hence, we extend our algorithms to allow an &epsi; fraction of points to remain unclustered, that is, deleted from the anonymized publication. Thus, by not releasing a small fraction of the database records, we can ensure that the data published for analysis has less distortion and hence is more useful. Our approximation algorithms for new clustering objectives are of independent interest and could be applicable in other clustering scenarios as well."}