{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/8231","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/8232","fieldValue":" R&D project selection plays an important role in government funding agencies, as allocation of billions of dollars among the proposals deemed highly influential and contributive solely depend on it. Efficacious assignment of reviewers is one of the most critical processes that controls the quality of the entire project selection and also has a serious implication on business profit. Current methods that focus on workflow automation are more efficient than manual assignment; however, they are not effective, as they fail to consider the real insight of core tasks. Other decision models that analyze core tasks are effective but inefficient when handling large amounts of submissions, and they suffer from irrelevant assignment. Furthermore, they largely ignore real deep insight of back-end data such as quality of the reviewers (e.g., quality and citation impact of their produced research) and the effect of social relationships in project selection processes that are essential for identifying reviewers for interdisciplinary proposal evaluation. In light of these deficiencies, this research proposes a novel hybrid process analytics approach to decompose the complex reviewer assignment process into manageable subprocesses and applies data-driven decision models cum process analytics systematically from a triangular perspective via the research analytics framework to achieve high operational efficiencies and high-quality assignment. It also analyzes big data from scientific databases and generates visualized decision-ready information to support effective decision making. The proposed approach has been implemented to aid the project selection process of the largest funding agency in China and has been tested. The test results show that the proposed approach has the potential to add great benefits, including cost saving, improved effectiveness, and increased business value."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/8232","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/8232","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/8233","fieldValue":"Sun, Sherry X"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/8233","fieldValue":" Business process integration has become prevalent as business increasingly crosses organizational boundaries. To address the issue of protecting organizationsâ\u20AC™ competitive knowledge and private information while also enabling business-to-business (B2B) collaboration, past research has focused mainly on customized public and private process design, as well as structural correctness of the integrated workflow. However, a dataflow perspective is important for business process integration. This article presents a data-flow perspective using workflow management and mathematical techniques to address data exchange problems in independent multistakeholder business process integration in dynamic circumstances. The research is conducted following a design science paradigm. We build artifacts that include interorganizational workflow concepts, a workflow model, and a public dataset calculation method. The use of the proposed artifacts is illustrated by applying them to a real-world case in the Shenzhen (Chaiwan) port. The utility of the artifacts is evaluated through interviews with practitioners in industry. We conclude that this research complements the control-flow perspective in the interorganizational workflow management area and also contributes to B2B information-sharing literature; further, the dataflow formalism can help practitioners to formally provide the right data at the right time in dynamic circumstances."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/8233","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/8233","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/8234","fieldValue":"Tan, Yao-Hua"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/8234","fieldValue":" In business environments, different sorts of regulations are imposed to restrict the behavior of both public and private organizations, ranging from legal regulations to internal policies. Regulatory compliance is important for the safety of individual actors as well as the overall business environment. However, complexity derives from not only the contents of the regulations but also their interdependencies. As such, the verification of whether actors are able to comply with the combined regulations cannot be done by checking each regulation separately. To these ends, we introduce a normative structure Norm Nets (NNs) for modeling sets of interrelated regulations and setting a basis for compliance checking of organizational interactions against interrelated regulations. NNs support a modular design by providing the constructs to represent regulations and the relationships between them. Additionally, we propose a computational mechanism to reason about regulatory compliance by mapping NNs to Colored Petri Nets (CPNs). We show that compliance checking of both individual actorsâ\u20AC™ behavior and the collective behavior of the business environment can be achieved automatically using state space analysis techniques of CPNs. The approach is illustrated with a case study from the domain of international trade."}