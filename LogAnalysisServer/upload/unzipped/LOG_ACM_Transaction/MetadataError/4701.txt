{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25137","fieldValue":" Some queueing systems require tremendously long simulation runlengths to obtain accurate estimators of certain steady-state performance measures when the servers are heavily utilized. However, this is not uniformly the case. We analyze a number of single-station Markovian queueing models, demonstrating that several steady-state performance measures can be accurately estimated with modest runlengths. Our analysis reinforces the meta result that if the queue is â\u20ACœwell dimensioned,â\u20AC? then simulation runlengths will be modest. Queueing systems can be well dimensioned because customers abandon if they are forced to wait in line too long, or because the queue is operated in the â\u20ACœquality- and efficiency-driven regimeâ\u20AC? in which servers are heavily utilized but wait times are short. The results are based on computing or bounding the asymptotic variance and bias for several standard single-station queueing models and performance measures."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25137","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25137","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25138","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25138","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25139","fieldValue":" Parallel and distributed simulations (or High-Level Architecture (HLA)-based simulations) employing optimistic synchronization allow federates to advance simulation time freely at the risk of overoptimistic executions and execution rollbacks. As a result, the simulation performance may degrade significantly due to the simulation workload imbalance among federates. In this article, we investigate the execution of parallel and distributed simulations on Cloud and data centers with Virtual Execution Environments (VEEs). In order to speed up simulation execution, an Adaptive Resource Provisioning Mechanism in Virtual Execution Environments (ArmVee) is proposed. It is composed of a performance monitor and a resource manager. The former measures federate performance transparently to the simulation application. The latter distributes available resources among federates based on the measured federate performance. Federates with different simulation workloads are thus able to advance their simulation times with comparable speeds, thus are able to avoid wasting time and resources on overoptimistic executions and execution rollbacks. ArmVee is evaluated using a real-world simulation model with various simulation workload inputs and different parameter settings. The experimental results show that ArmVee is able to speed up the simulation execution significantly. In addition, it also greatly reduces memory usage and is scalable."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25139","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25139","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25140","fieldValue":"Erazo, Miguel A"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25140","fieldValue":" A testbed capable of representing detailed operations of complex applications under diverse network conditions is invaluable for understanding the design and performance of new protocols and applications before their real deployment. We introduce a novel method that combines high-performance large-scale network simulation and high-fidelity network emulation, and thus enables real instances of network applications and protocols to run in real operating environments and be tested under simulated network settings. Using our approach, network simulation and emulation can form a symbiotic relationship, through which they are synchronized for an accurate representation of the network-scale traffic behavior. We introduce a model downscaling method along with an efficient queuing model and a traffic reproduction technique, which can significantly reduce the synchronization overhead and improve accuracy. We validate our approach with extensive experiments via simulation and with a real-system implementation. We also present a case study using our approach to evaluate a multipath data transport protocol."}