{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/3904","fieldValue":"Le-Bidan, Raphal"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3904","fieldValue":" We propose a novel method for noise power spectrum estimation in speech enhancement. This method called extended-DATE (E-DATE) extends the -dimensional amplitude trimmed estimator (DATE), originally introduced for additive white gaussian noise power spectrum estimation in \"Robust estimation of noise standard deviation in presence of signals with unknown distributions and occurrences\" (D. Pastor and F. Socheleau, IEEE Trans. Signal Processing, vol. 60, no. 4, pp. 1545-1555, Apr. 2012) to the more challenging scenario of non-stationary noise. The key idea is that, in each frequency bin and within a sufficiently short time period, the noise instantaneous power spectrum can be considered as approximately constant and estimated as the variance of a complex gaussian noise process possibly observed in the presence of the signal of interest. The proposed method relies on the fact that the Short-Time Fourier Transform (STFT) of noisy speech signals is sparse in the sense that transformed speech signals can be represented by a relatively small number of coefficients with large amplitudes in the time-frequency domain. The E-DATE estimator is robust in that it does not require prior information about the signal probability distribution except for the weak-sparseness property. In comparison to other state-of-the-art methods, the E-DATE is found to require the smallest number of parameters (only two). The performance of the proposed estimator has been evaluated in combination with noise reduction and compared to alternative methods. This evaluation involves objective as well as pseudo-subjective criteria."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3904","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3904","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3905","fieldValue":" This paper presents a semantic logic-based approach to determine textual similarity. Three logic form transformations taking into account semantic structure of sentences are proposed. Logic proofs are obtained using an adapted resolution step that drops predicates when a proof cannot be found with standard resolution. Features are extracted from proofs and combined using supervised machine learning to obtain the final similarity scores. Experimental results show that taking into account semantic relations to determine textual similarity yields performance improvements with respect to both baselines and third-party state-of-the-art systems. Specific sentence pairs that benefit from considering semantic relations are discussed. Detailed results provide empirical evidence that either proof direction offers a strong baseline although considering both is beneficial, and that ignoring concepts that are not an argument of a semantic relation is not sound."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3905","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3905","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3906","fieldValue":" This paper presents a new method for automatically assessing the speech intelligibility of patients with dysarthria, which is a motor speech disorder impeding the physical production of speech. The proposed method consists of two main steps: feature representation and prediction. In the feature representation step, the speech utterance is converted into a phone sequence using an automatic speech recognition technique and is then aligned with a canonical phone sequence from a pronunciation dictionary using a weighted finite state transducer to capture the pronunciation mappings such as match, substitution, and deletion. The histograms of the pronunciation mappings on a pre-defined word set are used for features. Next, in the prediction step, a structured sparse linear model incorporated with phonological knowledge that simultaneously addresses phonologically structured sparse feature selection and intelligibility prediction is proposed. Evaluation of the proposed method on a database of 109 speakers consisting of 94 dysarthric and 15 control speakers yielded a root mean square error of 8.14 compared to subjectively rated scores in the range of 0 to 100. This is a promising performance in which the system can be successfully applied to help speech therapists in diagnosing the degree of speech disorder."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/3906","fieldValue":"Automatic intelligibility assessment of dysarthric speech using phonologically-structured sparse linear model"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3906","fieldValue":"ACM"}