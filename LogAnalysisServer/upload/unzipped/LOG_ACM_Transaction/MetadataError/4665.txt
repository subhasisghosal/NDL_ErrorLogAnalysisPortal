{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25053","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25054","fieldValue":"Frazier, Peter I"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25054","fieldValue":"Henderson, Shane G"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25054","fieldValue":" For many discrete simulation optimization applications, it is often difficult to decide which Ranking and Selection (R&S) procedure to use. To efficiently compare R&S procedures, we present a three-layer performance evaluation process. We show that the two most popular performance formulations, namely the Bayesian formulation and the indifference zone formulation, have a common representation analogous to convex risk measures used in mathematical finance. We then specify how a decision maker can impose a performance requirement on R&S procedures that is more adequate for her risk attitude than the indifference zone or the Bayesian performance requirements. Such a performance requirement partitions the space of R&S procedures into acceptable and nonacceptable procedures. The minimal computational budget required for a procedure to become acceptable introduces an easy-to-interpret preference order on the set of R&S policies. We demonstrate with a numerical example how the introduced framework can be used to guide the choice of selection procedure in practice."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25054","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25054","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25055","fieldValue":" Kriging is an increasingly popular metamodeling tool in simulation due to its flexibility in global fitting and prediction. In the fitting of this metamodel, the parameters are often estimated from the simulation data, which introduces parameter estimation uncertainties into the overall prediction error. Traditional plug-in estimators usually ignore these uncertainties, which can be substantial in stochastic simulations. This typically leads to an underestimation of the total variability and an overconfidence in the results. In this article, a Bayesian metamodeling approach for kriging prediction is proposed for stochastic simulations to more appropriately account for the parameter uncertainties. We derive the predictive distribution under certain assumptions and also provide a general Markov Chain Monte Carlo analysis approach to handle more general assumptions on the parameters and design. Numerical results indicate that the Bayesian approach has better coverage and better predictive variance than a previously proposed modified nugget effect kriging model, especially in cases where the stochastic variability is high. In addition, we further consider the important problem of planning the experimental design. We propose a two-stage design approach that systematically balances the allocation of computing resources to new design points and replication numbers in order to reduce the uncertainties and improve the accuracy of the predictions."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25055","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25055","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25056","fieldValue":"Taylor, Simon J E"}