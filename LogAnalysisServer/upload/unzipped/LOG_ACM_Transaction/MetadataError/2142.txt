{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17210","fieldValue":"Lopez-Moreno, Jorge"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17210","fieldValue":" The large-scale mechanical behavior of woven cloth is determined by the mechanical properties of the yarns, the weave pattern, and frictional contact between yarns. Using standard simulation methods for elastic rod models and yarn-yarn contact handling, the simulation of woven garments at realistic yarn densities is deemed intractable. This paper introduces an efficient solution for simulating woven cloth at the yarn level. Central to our solution is a novel discretization of interlaced yarns based on yarn crossings and yarn sliding, which allows modeling yarn-yarn contact implicitly, avoiding contact handling at yarn crossings altogether. Combined with models for internal yarn forces and inter-yarn frictional contact, as well as a massively parallel solver, we are able to simulate garments with hundreds of thousands of yarn crossings at practical frame-rates on a desktop machine, showing combinations of large-scale and fine-scale effects induced by yarn-level mechanics."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17210","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17210","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17211","fieldValue":"Lai, Yu-Kun"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17211","fieldValue":"Wu, Yu-Xin"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17211","fieldValue":"Hu, Shi-Min"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17211","fieldValue":" We present a novel solution to automatic semantic modeling of indoor scenes from a sparse set of low-quality RGB-D images. Such data presents challenges due to noise, low resolution, occlusion and missing depth information. We exploit the knowledge in a scene database containing 100s of indoor scenes with over 10,000 manually segmented and labeled mesh models of objects. In seconds, we output a visually plausible 3D scene, adapting these models and their parts to fit the input scans. Contextual relationships learned from the database are used to constrain reconstruction, ensuring semantic compatibility between both object models and parts. Small objects and objects with incomplete depth information which are difficult to recover reliably are processed with a two-stage approach. Major objects are recognized first, providing a known scene structure. 2D contour-based model retrieval is then used to recover smaller objects. Evaluations using our own data and two public datasets show that our approach can model typical real-world indoor scenes efficiently and robustly."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/17211","fieldValue":"Automatic semantic modeling of indoor scenes from low-quality RGB-D data using contextual information"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17211","fieldValue":"ACM"}