{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13233","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13234","fieldValue":" Coarse-grained reconfigurable architectures (CGRAs) promise high performance at high power efficiency. They fulfil this promise by keeping the hardware extremely simple, and moving the complexity to application mapping. One major challenge comes in the form of data mapping. For reasons of power-efficiency and complexity, CGRAs use multibank local memory, and a row of PEs share memory access. In order for each row of the PEs to access any memory bank, there is a hardware arbiter between the memory requests generated by the PEs and the banks of the local memory. However, a fundamental restriction remains in that a bank cannot be accessed by two different PEs at the same time. We propose to meet this challenge by mapping application operations onto PEs and data into memory banks in a way that avoids such conflicts. To further improve performance on multibank memories, we propose a compiler optimization for CGRA mapping to reduce the number of memory operations by exploiting data reuse. Our experimental results on kernels from multimedia benchmarks demonstrate that our local memory-aware compilation approach can generate mappings that are up to 53&percnt; better in performance (26&percnt; on average) compared to a memory-unaware scheduler."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13234","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13234","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13235","fieldValue":" In many applications, subsequent data manipulations differ only in a small set of parameter values. Because of their reconfigurability, FPGAs (field programmable gate arrays) can be configured with a specialized circuit each time the parameter values change. This technique is called dynamic data folding. The specialized circuits are smaller and faster than their generic counterparts. However, the overhead involved in generating the configurations for the specialized circuits at runtime is very large when conventional tools are used, and this overhead will in many cases negate the benefit of using optimized configurations. This article introduces an automatic method for generating runtime parameterizable configurations from arbitrary Boolean circuits. These configurations, in which some of the configuration bits are expressed as a closed-form Boolean expression of a set of parameters, enable very fast run-time specialization, since specialization only involves evaluating these expressions. Our approach is validated on a ternary content-addressable memory (TCAM). We show that the specialized configurations, produced by our method use 2.82 times fewer LUTs than the generic configuration, and even 1.41 times fewer LUTs than the implementation generated by Xilinx Coregen. Moreover, while Coregen needs hand-crafted generators for each type of circuit, our toolflow can be applied to any VHDL design. Using our automatic and generally applicable method, run-time hardware optimization suddenly becomes feasible for a large class of applications."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13235","fieldValue":"FPGA"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13235","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13235","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13236","fieldValue":" In this article, a parallel transient circuit simulation approach based on an adaptively-controlled time-stepping scheme is proposed. Different from the widely-used implicit numerical integration techniques in most transient simulators, this work exploits the recently-developed explicit telescopic projective numerical integration method for efficient parallel circuit simulation. Because telescopic projective integration addresses the well-known stability issue of explicit numerical integrations by adopting combinations of inner integrators and outer integrators in a multilevel fashion, the simulation time-step is no longer limited by the smallest time constant in the circuit. With dynamic control of telescopic projective integration, the proposed projective integration framework not only leads to noticeable efficiency improvement in circuit simulation, it also lends itself to straightforward parallelization due to its explicit nature. The latter has led to encouraging runtime efficiencies, observed on shared-memory parallel platforms. In addition to solving standard initial-value problems (IVPs) of differential equations, the same telescopic integration framework is adopted for solving final-value problems (FVPs), where the system is integrated backwards in time. Through a new elegant formulation, we show how an IVP and FVP can be simultaneously solved to allow for a coarse-grained bidirectional parallel circuit simulation scheme. Such a bidirectional approach is demonstrated in the context of parallel shooting-Newton-based steady-state circuit analysis. The proposed bidirectional approach has unique and favorable properties: the solutions of the two ODE problems are completely data-independent with built-in automatic load balancing."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13236","fieldValue":"ACM"}