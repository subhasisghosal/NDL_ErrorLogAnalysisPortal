{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7016","fieldValue":" Nowadays, many real-time applications are very complex and as the complexity and the requirements of those systems become more demanding, more hardware processing capacity is necessary. Unfortunately, the correct functioning of real-time systems depends not only on the logically correct response but also on the time when it is produced. General-purpose processor design fails to deliver analyzability due to their nondeterministic behavior caused by the use of cache memories, dynamic branch prediction, speculative execution, and out-of-order pipelines. In this article, we investigate the pipeline performance of Very Long Instruction Word (VLIW) architectures for real-time systems with an in-order pipeline considering Worst-Case Execution Time (WCET) performance. Techniques on obtaining the WCET of VLIW machines are also considered and we make a quantification on how important are hardware techniques such as static branch prediction, predication, and pipeline speed of complex operations such as memory access and multiplication for high-performance real-time systems. The memory hierarchy is out of the scope of this article and we used a classic deterministic structure formed by a direct mapped instruction cache and a data scratchpad memory. A VLIW prototype was implemented in VHDL from scratch considering the HP VLIW ST231 ISA. We also show some compiler insights and we use a representative subset of the MÃ¤lardalenâ\u20AC™s WCET benchmarks for validation and performance quantification."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7016","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7016","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/7017","fieldValue":"Kim, Sang-Hoon"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/7017","fieldValue":"Kim, Jin-Soo"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7017","fieldValue":" As the mobile computing environment evolves, users demand high-quality apps and better user experience. Consequently, memory demand in mobile devices has soared. Device manufacturers have fulfilled the demand by equipping devices with more RAM. However, such a hardware approach is only a temporary solution and does not scale well in the resource-constrained mobile environment. Meanwhile, mobile systems adopt a new app life cycle and a memory reclamation scheme tailored for the life cycle. When a user leaves an app, the app is not terminated but cached in memory as long as there is enough free memory. If the free memory gets low, a victim app is terminated and the associated memory to the app is reclaimed. This process-level approach has worked well in the mobile environment. However, user experience can be impaired severely because the victim selection policy does not consider the user experience. In this article, we propose a novel memory reclamation scheme called SmartLMK. SmartLMK minimizes the impact of the process-level reclamation on user experience. The worthiness to keep an app in memory is modeled by means of user-perceived app launch time and app usage statistics. The memory footprint and impending memory demand are estimated from the history of the memory usage. Using these values and memory models, SmartLMK picks up the least valuable apps and terminates them at once. Our evaluation on a real Android-based smartphone shows that SmartLMK efficiently distinguishes the valuable apps among cached apps and keeps those valuable apps in memory. As a result, the user-perceived app launch time can be improved by up to 13.2&percnt;."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7017","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7017","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7018","fieldValue":" Energy consumption in mobile devices is an important issue for both system developers and users. Users are aware of the battery-related information of their mobile devices and tend to take appropriate actions to increase the battery life. In this article, we propose a framework that accurately estimates the remaining battery time of applications at runtime. The framework profiles the power behavior of applications tied with activated hardware components and estimates the remaining battery budget utilizing the battery-related data provided by the device. The experiments validate that our method predicts the remaining battery time for applications with approximately 93&percnt; of accuracy."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7018","fieldValue":"ACM"}