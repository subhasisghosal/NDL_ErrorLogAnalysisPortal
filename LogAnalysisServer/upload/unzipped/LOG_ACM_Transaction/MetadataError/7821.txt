{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10455","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10456","fieldValue":" Loss measurements are widely used in today's networks. There are existing standards and commercial products to perform these measurements. The missing element is a rigorous statistical methodology for their analysis. Indeed, most existing tools ignore the correlation between packet losses and severely underestimate the errors in the measured loss ratios. In this paper, we present a rigorous technique for analyzing performance measurements, in particular, for estimating confidence intervals of packet loss measurements. The task is challenging because Internet packet loss ratios are typically small and the packet loss process is bursty. Our approach, SAIL, is motivated by some simple observations about the mechanism of packet losses. Packet losses occur when the buffer in a switch or router fills, when there are major routing instabilities, or when the hosts are overloaded, and so we expect packet loss to proceed in episodes of loss, interspersed with periods of successful packet transmission. This can be modeled as a simple ON\/OFF process, and in fact, empirical measurements suggest that an alternating renewal process is a reasonable approximation to the real underlying loss process. We use this structure to build a hidden semi-Markov model (HSMM) of the underlying loss process and, from this, to estimate both loss ratios and confidence intervals on these loss ratios. We use both simulations and a set of more than 18 000 hours of real Internet measurements (between dedicated measurement hosts, PlanetLab hosts, Web and DNS servers) to cross-validate our estimates and show that they are better than any current alternative."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10456","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/10456","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10456","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10457","fieldValue":" In this paper, we study distributed scheduling in multihop multiple-input-multiple-output (MIMO) networks. We first develop a \"MIMO-pipe\" model that provides the upper layers a set of rates and signal-to-interference-plus-noise ratio (SINR) requirements that capture the rate-reliability tradeoff in MIMO communications. The main thrust of this paper is then dedicated to developing distributed carrier sense multiple access (CSMA) algorithms for MIMO-pipe scheduling under the SINR interference model. We choose the SINR model over the extensively studied protocol-based interference models because it more naturally captures the impact of interference in wireless networks. The coupling among the links caused by the interference under the SINR model makes the problem of devising distributed scheduling algorithms very challenging. To that end, we explore the CSMA algorithms for MIMO-pipe scheduling from two perspectives. We start with an idealized continuous-time CSMA network, where control messages can be exchanged in a collision-free manner, and devise a CSMA-based link scheduling algorithm that can achieve throughput optimality under the SINR model. Next, we consider a discrete-time CSMA network, where the message exchanges suffer from collisions. For this more challenging case, we develop a \"conservative\" scheduling algorithm by imposing a more stringent SINR constraint on the MIMO-pipe model. We show that the proposed conservative scheduling achieves an efficiency ratio bounded from below."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10457","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/10457","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10457","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1952","fieldValue":" JavaScript is a sequential programming language that has a large potential for parallel execution in Web applications. Thread-level speculation can take advantage of this, but it has a large memory overhead. In this article, we evaluate the effects of adjusting various parameters for thread-level speculation. Our results clearly show that thread-level speculation is a useful technique for taking advantage of multicore architectures for JavaScript in Web applications, that nested speculation is required in thread-level speculation, and that the execution characteristics of Web applications significantly reduce the needed memory, the number of threads, and the depth of our speculation."}