{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25758","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25759","fieldValue":" To preserve the privacy of multimedia big data and achieve the efficient data aggregation in wireless multimedia sensor networks (WMSNs), a distributed compressed sensing--based privacy-preserving data aggregation (DCSPDA) approach is proposed in this article. First, in this approach, the original multimedia sensor data are compressed and measured by distributed compressed sensing (DCS) and the compressed data measurements are uploaded to the sink, by which the inherent characteristics between sensor data can be obtained. Second, the original multimedia data are jointly recovered and the common and innovation sparse components are obtained through solving the optimization problem and linear equations at the sink. Third, through least squares support vector machine (LSSVM) learning of the sparse components, the sparse position configuration can be determined and disseminated for each node to conduct the privacy-preserving data configuration. After receiving the configuration message, original multimedia sensor data are accordingly customized, compressed, and measured by the common measurement matrix, aggregated at the cluster heads, and transmitted to the sink. Finally, the aggregated multimedia sensor data are recovered by the sink according to the data configuration to achieve the privacy-preserving data aggregation and transmission. Our comparative simulation results validate the efficiency and scalability of DCSPDA and demonstrate that the proposed approach can effectively reduce the communication overheads and provide reliable privacy-preserving with low computational complexity for WMSNs."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25759","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25759","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25760","fieldValue":" With the advent of social networks and cloud computing, the amount of multimedia data produced and communicated within social networks is rapidly increasing. In the meantime, social networking platforms based on cloud computing have made multimedia big data sharing in social networks easier and more efficient. The growth of social multimedia, as demonstrated by social networking sites such as Facebook and YouTube, combined with advances in multimedia content analysis, underscores potential risks for malicious use, such as illegal copying, piracy, plagiarism, and misappropriation. Therefore, secure multimedia sharing and traitor tracing issues have become critical and urgent in social networks. In this article, a joint fingerprinting and encryption (JFE) scheme based on tree-structured Haar wavelet transform (TSHWT) is proposed with the purpose of protecting media distribution in social network environments. The motivation is to map hierarchical community structure of social networks into a tree structure of Haar wavelet transform for fingerprinting and encryption. First, fingerprint code is produced using social network analysis (SNA). Second, the content is decomposed based on the structure of fingerprint code by the TSHWT. Then, the content is fingerprinted and encrypted in the TSHWT domain. Finally, the encrypted contents are delivered to users via hybrid multicast-unicast. The proposed method, to the best of our knowledge, is the first scalable JFE method for fingerprinting and encryption in the TSHWT domain using SNA. The use of fingerprinting along with encryption using SNA not only provides a double layer of protection for social multimedia sharing in social network environment but also avoids big data superposition effect. Theory analysis and experimental results show the effectiveness of the proposed JFE scheme."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25760","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25760","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3486","fieldValue":" Computational systems for generating expressive musical performances have been studied for several decades now. These models are generally evaluated by comparing their predictions with actual performances, both from a performance parameter and a subjective point of view, often focusing on very specific aspects of the model. However, little is known about how listeners evaluate the generated performances and what factors influence their judgement and appreciation. In this article, we present two studies, conducted during two dedicated workshops, to start understanding how the audience judges entire performances employing different approaches to generating musical expression. In the preliminary study, 40 participants completed a questionnaire in response to five different computer-generated and computer-assisted performances, rating preference and describing the expressiveness of the performances. In the second, â\u20ACœGATMâ\u20AC? (Gruppo di Analisi e Teoria Musicale) study, 23 participants also completed the Music Cognitive Style questionnaire. Results indicated that music systemizers tend to describe musical expression in terms of the formal aspects of the music, and music empathizers tend to report expressiveness in terms of emotions and characters. However, high systemizers did not differ from high empathizers in their mean preference score across the five pieces. We also concluded that listeners tend not to focus on the basic technical aspects of playing when judging computer-assisted and computer-generated performances. Implications for the significance of individual differences in judging musical expression are discussed."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/3486","fieldValue":"The Role of Individual Difference in Judging Expressiveness of Computer-Assisted Music Performances by Experts"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3486","fieldValue":"ACM"}