{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/19517","fieldValue":" Efficiently allocating the computational resources of many-core systems is one of the most prominent challenges, especially when resource requirements may vary unpredictably at runtime. This is even more challenging when facing unreliable coresâ\u20AC\u201Da scenario that becomes common as the number of cores increases and integration sizes shrink. To address this challenge, this article presents an optimal method for the allocation of the resources to software-pipelined applications. Here we show how runtime observations of the resource requirements of tasks can be used to adapt resource allocations. Furthermore, we show how the optimum can be traded for a high degree of scalability by clustering applications in a distributed, hierarchical manner. To diminish the negative effects of unreliable cores, this article shows how self-organization can effectively restore the integrity of such a hierarchy when it is corrupted by a failing core. Experiments on Intelâ\u20AC™s 48-core Single-Chip Cloud Computer and in a many-core simulator show that a significant improvement in system throughput can be achieved over the current state of the art."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/19517","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19517","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/19518","fieldValue":" Packet-switched network-on-chip (NoC) has provided a scalable solution to the communications for tiled multicore processors. However, the virtual channel (VC) buffers in the NoC consume significant dynamic and leakage power. To improve the energy efficiency of the router design, it is advantageous to use small buffer sizes while still maintaining throughput of the network. This article proposes two new virtual channel allocation (VA) mechanisms, termed fixed VC assignment with dynamic VC allocation (FVADA) and adjustable VC assignment with dynamic VC allocation (AVADA). VCs are designated to output ports and allocated to packets according to such assignment. This can help to reduce the head-of-line blocking. Such VC-output port assignment can also be adjusted dynamically to accommodate traffic changes. Simulation results show that both mechanisms can improve network throughput by 41&percnt; on average. Real traffic evaluation shows a network latency reduction of up to 66&percnt;. In addition, AVADA can outperform the baseline in throughput with only half of the buffer size. Finally, we are able to achieve comparable or better throughput than a previous dynamic VC allocator while reducing its critical path delay by 57&percnt;. Hence, the proposed VA mechanisms are suitable for low-power, high-throughput, and high-frequency NoC designs."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/19518","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19518","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/19519","fieldValue":"Siegel, Andrew R"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/19519","fieldValue":"Siegel, Stephen F"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/19519","fieldValue":" Next-generation HPC computing platforms are likely to be characterized by significant, unpredictable nonuniformities in execution time among compute nodes and cores. The resulting load imbalances from this nonuniformity are expected to arise from a variety of sourcesâ\u20AC\u201Dmanufacturing discrepancies, dynamic power management, runtime component failure, OS jitter, software-mediated resiliency, and TLB\/- cache performance variations, for example. It is well understood that existing algorithms with frequent points of bulk synchronization will perform relatively poorly in the presence of these sources of process nonuniformity. Thus, recasting classic bulk synchronous algorithms into more asynchronous, coarse-grained parallelism is a critical area of research for next-generation computing. We propose a class of parallel algorithms for explicit stencil computations that can tolerate these nonuniformities by decoupling per process communication and computation in order for each process to progress asynchronously while maintaining solution correctness. These algorithms are benchmarked with a 1D domain decomposed (â\u20ACœslabbedâ\u20AC?) implementation of the 2D heat equation as a model problem, and are tested in the presence of simulated nonuniform process execution rates. The resulting performance is compared to a classic bulk synchronous implementation of the model problem. Results show that the runtime of this articleâ\u20AC™s algorithm on a machine with simulated process nonuniformities is 5--99&percnt; slower than the runtime of its classic counterpart on a machine free of nonuniformities. However, when both algorithms are run on a machine with comparable synthetic process nonuniformities, this articleâ\u20AC™s algorithm is 1--37 times faster than its classic counterpart."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19519","fieldValue":"BSP"}