{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19377","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/19378","fieldValue":" Data sequences generated by on-line sensors can become arbitrarily large and must, therefore, be pared down to fit into available memory. For situations where only the most recent data is of interest, this problem can be solved with optimal efficiency by a simple circular buffer: it fills each memory location with useful data, and requires just one write to memory per update. The algorithm presented here provides essentially the same efficiency, but while maintaining a continuously updated, fixed-size, compressed representation of the entire data sequence. Each value in these compressed sequences represents a statistic (an average, maximum, random sample, etc.) computed over a contiguous chunk of the original sequence. Compressing circular buffers gain their efficiency by using an alternative indexing sequence, based on well-known principles of elementary number theory, to ensure that each newly written value gets stored in the unoccupied location created when the two oldest sequential over-sampled values are compressed into one. The associated Java implementation supports a variety of aggregating statistics and is used to compare the algorithm's performance with a more obvious approach (doubling)."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/19378","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19378","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/19379","fieldValue":"Van Zee, Field G"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/19379","fieldValue":"van de Geijn, Robert A"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/19379","fieldValue":"Quintana-Ort, Gregorio"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/19379","fieldValue":" We show how both the tridiagonal and bidiagonal QR algorithms can be restructured so that they become rich in operations that can achieve near-peak performance on a modern processor. The key is a novel, cache-friendly algorithm for applying multiple sets of Givens rotations to the eigenvector\/singular vector matrix. This algorithm is then implemented with optimizations that: (1) leverage vector instruction units to increase floating-point throughput, and (2) fuse multiple rotations to decrease the total number of memory operations. We demonstrate the merits of these new QR algorithms for computing the Hermitian eigenvalue decomposition (EVD) and singular value decomposition (SVD) of dense matrices when all eigenvectors\/singular vectors are computed. The approach yields vastly improved performance relative to traditional QR algorithms for these problems and is competitive with two commonly used alternatives---Cuppenâ\u20AC™s Divide-and-Conquer algorithm and the method of Multiple Relatively Robust Representations---while inheriting the more modest O(n) workspace requirements of the original QR algorithms. Since the computations performed by the restructured algorithms remain essentially identical to those performed by the original methods, robust numerical properties are preserved."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19379","fieldValue":"EVD"}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19379","fieldValue":"SVD"}