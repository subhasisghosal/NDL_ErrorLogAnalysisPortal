{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/3029","fieldValue":"Yang, Ping-Che"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/3029","fieldValue":"Chang, Jason S"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3029","fieldValue":" We introduce a method for learning to predict text and grammatical construction in a computer-assisted translation and writing framework. In our approach, predictions are offered on the fly to help the user make appropriate lexical and grammar choices during the translation of a source text, thus improving translation quality and productivity. The method involves automatically generating general-to-specific word usage summaries (i.e., writing suggestion module), and automatically learning high-confidence word- or phrase-level translation equivalents (i.e., translation suggestion module). At runtime, the source text and its translation prefix entered by the user are broken down into n-grams to generate grammar and translation predictions, which are further combined and ranked via translation and language models. These ranked prediction candidates are iteratively and interactively displayed to the user in a pop-up menu as translation or writing hints. We present a prototype writing assistant, TransAhead, that applies the method to a human-computer collaborative environment. Automatic and human evaluations show that novice translators or language learners substantially benefit from our system in terms of translation performance (i.e., translation accuracy and productivity) and language learning (i.e., collocation usage and grammar). In general, our methodology of inline grammar and text predictions or suggestions has great potential in the field of computer-assisted translation, writing, or even language learning."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3029","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3029","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/21289","fieldValue":" We propose a scalably efficient scheme for detecting large-scale physically correlated events in sensor networks. Specifically, we show that in a network of n sensors arbitrarily distributed in the plane, a sample of O(1\/&epsis; log 1\/&epsis;) sensor nodes (mice) is sufficient to catch any, and only those, events that affect Î© (&epsis;n) nodes (elephants), for any 0 < &epsis; < 1, as long as the geometry of the event has a bounded Vapnik-Chervonenkis (VC) dimension. In fact, the scheme is provably able to estimate the size of an event within the approximation error of Â±&epsis;n\/4, which can be improved further at the expense of more mice. The detection algorithm itself requires knowledge of the event geometry (e.g., circle, ellipse, or rectangle) for the sake of computational efficiency, but the combinatorial bound on the sample size (set of mice) depends only on the VC, dimension of the event class and not the precise shape geometry. While nearly optimal in theory, due to implicit constant factors, these â\u20ACœscale-freeâ\u20AC? bounds still prove too large in practice if applied blindly. We therefore propose heuristic improvements and perform empirical parameter tuning to counter the pessimism inherent in these theoretical estimates. Using a variety of data distributions and event geometries, we show through simulations that the final scheme is eminently scalable and practical, say, for n â\u2030¥ 1000. The overall simplicity and generality of our technique suggests that it is well suited for a wide class of sensornet applications, including monitoring of physical environments, network anomalies, network security, or any abstract binary event that affects a significant number of nodes in the network."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/21289","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/21289","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/21290","fieldValue":" Sensors may fail due to various reasons such as heat, malicious activity, environmental hazards, extended use, and lack of power. As more and more sensors fail, certain desired properties such as barrier coverage will diminish and eventually fall below a desired level. In such a case, the network will have to be repaired. It is therefore desirable to have mechanisms to monitor network properties. In this article, we are interested in measuring the quality of barrier coverage, which is known to be an appropriate model of coverage for movement detection applications such as intrusion detection. In the literature, researchers only consider whether or not a sensor network provides barrier coverage. This is equivalent to measuring its quality as either 0 or 1. We believe quality of barrier coverage is not binary and propose a metric for measuring it. If the measured quality is short of a desired value, we further identify all local regions that need to be repaired. The identified regions are minimal in the sense that if one of them is not repaired then the resulting network will still be short of quality. We also discuss how to actually repair a region."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/21290","fieldValue":"ACM"}