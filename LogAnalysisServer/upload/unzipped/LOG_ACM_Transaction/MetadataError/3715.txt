{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/21947","fieldValue":" Dynamic biomedical systems are mathematically described by Ordinary Differential Equations (ODEs) and their solution is often one of the most computationally intensive parts in biomedical simulations. With high inherent parallelism, hardware acceleration based on Field-Programmable Gate Arrays (FPGAs) has great potential to increase the computational performance of the model simulations, while being very power-efficient. However, the manual hardware implementation is complex and time consuming. The advantages of FPGA designs can only be realised if there is a general solution to automate the process. In this article, we propose a domain-specific high-level synthesis tool called ODoST that automatically generates an FPGA-based Hardware Accelerator Module (HAM) from a high-level description. In this direct approach, ODE equations are directly mapped to processing pipelines without any intermediate architecture layer of processing elements. We evaluate the generated HAMs on real hardware based on their resource usage, processing speed, and power consumption, and compare them with CPUs and a GPU. The results show that FPGA implementations can achieve 15.3 times more speedup compared to a single core CPU solution and perform similarly to an auto-generated GPU solution, while the FPGA implementations can achieve 14.5 times more power efficiency than the CPU and 3.1 times compared to the optimised GPU solution. Improved speedups are foreseeable based on further optimisations."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/21947","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/21947","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/21948","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/21948","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/21949","fieldValue":" In addition to optimizing for long-path timing and routability, commercial FPGA routing engines must also optimize for various timing constraints, enabling users to fine tune their designs. These timing constraints involve both long- and short-path timing requirements. The intricacies of commercial FPGA architectures add difficulty to the problem of supporting such constraints. In this work, we introduce specific delay window routing as a general method for optimization during the routing stage of the FPGA design flow, which can be applied to various timing constraints constituting both long- and short-path requirements. Furthermore, we propose a key adjustment to standard FPGA routing technology for the purposes of specific delay window routing. By using dual-wave expansion instead of traditional single-wave expansion, we solve the critical issue of inaccurate delay estimation in our wave search, which would otherwise make routing according to a specific delay window difficult. Our results show that this dual-wave method can support stricter timing constraints than the standard single-wave method. For a suite of designs with constraints requiring connections to meet a target delay within 250ps, our dual-wave method could satisfy the requirement for all designs, whereas the single-wave method failed for more than two thirds of the designs."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/21949","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/21949","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/21950","fieldValue":" The energy in FPGA computations is dominated by data communication energy, either in the form of memory references or data movement on interconnect. In this article, we explore how to use data placement and parallelism to reduce communication energy. We show that parallelism can reduce energy and that the optimal level of parallelism increases with the problem size. We further explore how FPGA memory architecture (memory block size(s), memory banking, and spacing between memory banks) can impact communication energy, and determine how to organize the memory architecture to guarantee that the energy overhead compared to the optimally matched architecture for the design is never more than 60&percnt;. We specifically show that an architecture with 32 bit wide, 16Kb internally banked memories placed every 8 columns of 10 4-LUT logic blocks is within 61&percnt; of the optimally matched architecture across the VTR 7 benchmark set and a set of parallelism-tunable benchmarks. Without internal banking, the worst-case overhead is 98&percnt;, achieved with an architecture with 32 bit wide, 8Kb memories placed every 9 columns, roughly comparable to the memory organization on the Cyclone V (where memories are placed about every 10 columns). Monolithic 32 bit wide, 16Kb memories placed every 10 columns (comparable to 18Kb and 20Kb memories used in Virtex 4 and Stratix V FPGAs) have a 180&percnt; worst-case energy overhead. Furthermore, we show practical cases where designs mapped for optimal parallelism use 4.7 Ã\u2014 less energy than designs using a single processing element."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/21950","fieldValue":"FPGA"}