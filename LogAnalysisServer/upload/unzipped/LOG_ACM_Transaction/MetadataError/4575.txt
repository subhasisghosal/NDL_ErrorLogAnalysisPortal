{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24827","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24828","fieldValue":" Measurements of network traffic have shown that self-similarity is a ubiquitous phenomenon spanning across diverse network environments. In previous work, we have explored the feasibility of exploiting long-range correlation structure in self-similar traffic for congestion control. We have advanced the framework of multiple time scale congestion control and shown its effectiveness at enhancing performance for rate-based feedback control. In this article, we extend the multiple time scale control framework to window-based congestion control, in particular, TCP. This is performed by interfacing TCP with a large time scale module that adjusts the aggressiveness of bandwidth consumpton behavior exhibited by TCP as a function of large time scale network state, that is, information that exceeds the time horizon of the feedback loop as determined by RTT. How to effectively utilize such informationâ\u20AC\u201Ddue to its probabilistic nature, dispersion over multiple time scales, and realization on top of existing window-based congestion controlsâ\u20AC\u201Dis a nontrivial problem. First, we define a modular extension of TCP (a function call with a simple interface that applies to various flavors of TCP, e.g., Tahoe, Reno, and Vegas) and show that it significantly improves performance. Second, we show that multiple time scale TCP endows the underlying feedback control with proacativity by bridging the uncertainty gap associated with reactive controls which is exacerbated by the high delay-bandwidth product in broadband wide area networks. Third, we investigate the influence of three traffic control dimensionsâ\u20AC\u201Dtracking ability, connection duration, and fairnessâ\u20AC\u201Don performance. Performance evaluation of multiple time scale TCP is facilitated by a simulation benchmark environment based on physical modeling of self-similar traffic. We explicate our methodology for disc"}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24828","fieldValue":"TCP"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24828","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24828","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24829","fieldValue":" In this paper, we investigate the problem of topology aggregation (TA) for scalable, QoS-based routing in hierarchical networks. TA is the process of summarizing the topological information of a subset of network elements. This summary is flooded throughout the network and used by various nodes to determine appropriate routes for connection requests. A key issue in the design of a TA scheme is the appropriate balance between compaction and the corresponding routing performance. The contributions of this paper are twofold. First, we introduce a source-oriented approach to TA, hich provides better performance than existing approaches. The intuition behind this approach is that the advertised topology-state information is used by source nodes to determine tentative routes for connection requests. Accordingly, only information relevant to source nodes needs to be advertised. We integrate the source-oriented approach into three new TA schemes that provide different trade-offs between compaction and accuracy. Second, we extend our source-oriented approach to multi-QoS-based TA. A key issue here is the determination of appropriate values for the multiple QoS parameters associated with a logical link. Two new approaches to computing these values are introduced. Extensive simulations are used to evaluate the performance of out proposed schemes."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24829","fieldValue":"PNNI"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24829","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24829","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24830","fieldValue":" In this paper we consider the problem of estimating blocking probabili ties in the multiservice loss system via simulation, applying the static Monte Carlo method with importance sampling. Earlier approaches to this problem include the use of either a single exponentially twisted version of the steady state distribution of the system or a composite of individual exponentially twisted distributions. Here, a different approach is introduced, where the original estimation problem is first decomposed into independent simpler subproblems, each roughly corresponding to estimating the blocking probability contribution from a single link. Then two importance sampling distributions are presented, which very closely approximate the ideal importance sampling distribution for each subproblem. In both methods, the idea is to try to generate samples directly into the blocking state region. The difference between the methods is that the first method, the inverse convolution method, achieves this exactly, while the second one, using a fitted Gaussian distibution, only approximately. The inverse convolution algorithm, however, has a higher memory requirement. Finally, a dynamic control algorithm is given for optimally allocating the samples between different subproblems. The numerical results demonstrate that the variance reduction obtained with the methods, especially with the inverse convolution method, is tryly remarkable, between 670 and 1,000,000 in the examples under consideration."}