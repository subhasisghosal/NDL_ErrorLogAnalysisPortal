{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/3921","fieldValue":"Evaluation of statistical inference tests applied to subjective audio quality data with small sample size"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3921","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3921","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3922","fieldValue":" We present a novel approach to separating pitched signals from single-channel mixtures by harmonic bandwidth companding. Recalling that in a short analysis window the harmonic waveform envelope conveys information about approximate amplitude and frequency time variations, we show that proper linear waveform envelope smoothing reduces frequency spread around the harmonics and thus compresses the harmonic bandwidth. Such an action largely relaxes worst-case separation scenarios, which are caused by large proportions of overlapped harmonics. The distortion in separated signals due to harmonic bandwidth compression is compensated by an inverse system--the harmonic bandwidth expander. The benefit of such an approach is that explicit classification in overlapped and non-overlapped harmonics is no longer needed. Moreover, the underlying signal model is linear-in-parameters which allows for an efficient estimation via linear least-squares. The results show that harmonic bandwidth companding significantly outperforms two state-of-the-art separation methods."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3922","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3922","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/3923","fieldValue":"Chien, Jen-Tzung"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3923","fieldValue":" This paper presents the group sparse learning for acoustic models where a sequence of acoustic features is driven by Markov chain and each feature vector is represented by groups of basis vectors. The group of common bases represents the features across Markov states within a regression class. The group of individual basis compensates the intra-state residual information. Laplace distribution is used as the sparse prior of sensing weights for group basis representation. Laplace parameter serves as regularization parameter or automatic relevance determination which controls the selection of relevant bases for acoustic modeling. The groups of regularization parameters and basis vectors are estimated from training data by maximizing the marginal likelihood over sensing weights which is implemented by Laplace approximation using the Hessian matrix and the maximum a posteriori parameters. Model uncertainty is compensated through full Bayesian treatment. The connection of Laplace group sensing to lasso regularization is illustrated. Experiments on noisy speech recognition show the robustness of group sparse acoustic models in presence of different noise types and SNRs."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3923","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3923","fieldValue":"ACM"}