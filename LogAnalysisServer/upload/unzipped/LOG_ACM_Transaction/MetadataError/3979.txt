{"fieldName":"dc.title","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/22826","fieldValue":"EDITORIAL"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/22826","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/22826","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3228","fieldValue":" We conducted three experiments to compare distance perception in real and virtual environments. In Experiment 1, adults estimated how long it would take to walk to targets in real and virtual environments by starting and stopping a stopwatch while looking at a target person standing between 20 and 120 ft away. The real environment was a large grassy lawn in front of a university building. We replicated this scene in our virtual environment using a nonstereoscopic, large-screen immersive display system. We found that people underestimated time to walk in both environments for distances of 40 to 60 ft and beyond. However, time-to-walk estimates were virtually identical across the two environments, particularly when people made real environment estimates first. In Experiment 2, 10- and 12-year-old children and adults estimated time to walk in real and virtual environments both with and without vision. Adults underestimated time to walk in both environments for distances of 60 to 80 ft and beyond. Again, their estimates were virtually identical in the real and virtual environment both with and without vision. Twelve-year-olds' time-to-walk estimates were also very similar across the two environments under both viewing conditions, but 10-year-olds exhibited greater underestimation in the virtual than in the real environment. A third experiment showed that adults' time-to-walk estimates were virtually identical to walking without vision. We conclude that distance perception may be better in virtual environments involving large-screen immersive displays than in those involving head-mounted displays (HMDS)."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3228","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3228","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/22827","fieldValue":"Al Dallal, Jehad"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/22827","fieldValue":"Briand, Lionel C"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/22827","fieldValue":" The building of highly cohesive classes is an important objective in object-oriented design. Class cohesion refers to the relatedness of the class members, and it indicates one important aspect of the class design quality. A meaningful class cohesion metric helps object-oriented software developers detect class design weaknesses and refactor classes accordingly. Several class cohesion metrics have been proposed in the literature. Most of these metrics are applicable based on low-level design information such as attribute references in methods. Some of these metrics capture class cohesion by counting the number of method pairs that share common attributes. A few metrics measure cohesion more precisely by considering the degree of interaction, through attribute references, between each pair of methods. However, the formulas applied by these metrics to measure the degree of interaction cause the metrics to violate important mathematical properties, thus undermining their construct validity and leading to misleading cohesion measurement. In this paper, we propose a formula that precisely measures the degree of interaction between each pair of methods, and we use it as a basis to introduce a low-level design class cohesion metric (LSCC). We verify that the proposed formula does not cause the metric to violate important mathematical properties. In addition, we provide a mechanism to use this metric as a useful indicator for refactoring weakly cohesive classes, thus showing its usefulness in improving class cohesion. Finally, we empirically validate LSCC. Using four open source software systems and eleven cohesion metrics, we investigate the relationship between LSCC, other cohesion metrics, and fault occurrences in classes. Our results show that LSCC is one of three metrics that explains more accurately the presence of faults in classes. LSCC is the only one among the three metrics to comply with important mathematical properties, and statistical analysis shows it captures a measurement dimension of its own. This suggests that LSCC is a better alternative, when taking into account both theoretical and empirical results, as a measure to guide the refactoring of classes. From a more general standpoint, the results suggest that class quality, as measured in terms of fault occurrences, can be more accurately explained by cohesion metrics that account for the degree of interaction between each pair of methods."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/22827","fieldValue":"ACM"}