{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/7256","fieldValue":"Sanchez-Ruiz, Antonio"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/7256","fieldValue":"Catarino, joo"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7256","fieldValue":" Virtual environments offer an ideal setting to develop intelligent training applications. Yet, their ability to support complex procedures depends on the appropriate integration of knowledge-based techniques and natural interaction. In this article, we describe the implementation of an intelligent rehearsal system for biohazard laboratory procedures, based on the real-time instantiation of task models from the traineeâ\u20AC™s actions. A virtual biohazard laboratory has been recreated using the Unity3D engine, in which users interact with laboratory objects using keyboard\/mouse input or hand gestures through a Kinect device. Realistic behavior for objects is supported by the implementation of a relevant subset of common sense and physics knowledge. User interaction with objects leads to the recognition of specific actions, which are used to progressively instantiate a task-based representation of biohazard procedures. The dynamics of this instantiation process supports trainee evaluation as well as real-time assistance. This system is designed primarily as a rehearsal system providing real-time advice and supporting user performance evaluation. We provide detailed examples illustrating error detection and recovery, and results from on-site testing with students from the Faculty of Medical Sciences at Kyushu University. In the study, we investigate the usability aspect by comparing interaction with mouse and Kinect devices and the effect of real-time task recognition on recovery time after user mistakes."}{"fieldName":"dc.description","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/7256","fieldValue":"Author Affiliation: INESC-ID and Instituto Superior T&#233;cnico, Universidade de Lisboa, Porto Salvo, Portugal (Catarino, joo; Oliveira, Joo; Prada, Rui); Faculty of Medical Sciences, Kyushu University, Fukuoka, Japan (Fujimoto, Shuji); National Institute of Infectious Diseases, Tokyo, Japan (Shigematsu, Mika); National Institute of Informatics, Tokyo, Japan (Prendinger, Helmut; Alvarez, Nahum); Universidad Complutense de Madrid, Madrid, Spain (Sanchez-Ruiz, Antonio); School of Engineering and Digital Arts, University of Kent, Canterbury, UK (Cavazza, Marc)"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7256","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7256","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7257","fieldValue":" In this article, we propose and implement a new model for context recognition and identification. Our work is motivated by the importance of â\u20ACœworking in contextâ\u20AC? for knowledge workers to stay focused and productive. A computer application that can identify the current context in which the knowledge worker is working can (among other things) provide the worker with contextual support, for example, by suggesting relevant information sources, or give an overview of how he or she spent his or her time during the day. We present a descriptive model for the context of a knowledge worker. This model describes the contextual elements in the work environment of the knowledge worker and how these elements relate to each other. This model is operationalized in an algorithm, the contextual interactive activation model (CIA), which is based on the interactive activation model by Rumelhart and McClelland. It consists of a layered connected network through which activation flows. We have tested CIA in a context identification setting. In this case, the data that we use as input is low-level computer interaction logging data. We found that topical information and entities were the most relevant types of information for context identification. Overall the proposed CIA model is more effective than traditional supervised methods in identifying the active context from sparse input data, with less labelled training data."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7257","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7257","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7258","fieldValue":" Authentication based on touchless mid-air gestures would benefit a multitude of ubiquitous computing applications, especially those that are used in clean environments (e.g., medical environments or clean rooms). In order to explore the potential of mid-air gestures for novel authentication approaches, we performed a series of studies and design experiments. First, we collected data from more then 200 users during a 3-day science event organized within a shopping mall. These data were used to investigate capabilities of the Leap Motion sensor, observe interaction in the wild, and to formulate an initial design problem. The design problem, as well as the design of mid-air gestures for authentication purposes, were iterated in subsequent design activities. In a final study with 13 participants, we evaluated two mid-air gestures for authentication purposes in different situations, including different body positions. Our results highlight a need for different mid-air gestures for differing situations and carefully chosen constraints for mid-air gestures. We conclude by proposing an exemplary system, which aims to provide tool-support for designers and engineers, allowing them to explore authentication gestures in the original context of use and thus support them with the design of contextual mid-air authentication gestures."}