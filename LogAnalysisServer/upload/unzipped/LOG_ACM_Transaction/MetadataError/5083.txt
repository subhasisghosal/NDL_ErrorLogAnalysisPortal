{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3866","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3866","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3867","fieldValue":" We consider the estimation of an audio source from multiple noisy observations, where the correlation between noise in the different observations is low. We propose a two-stage method for this estimation problem. The method does not require any information about noise and assumes that the signal of interest has a sparse time-frequency representation. The first stage uses this assumption to obtain the best linear combination of the observations. The second stage estimates the amount of remaining noise and applies a post-filter to further enhance the reconstruction. We discuss the optimality of this method under a specific model and demonstrate its usefulness on synthetic and real data."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3867","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3867","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3868","fieldValue":" Speaker diarization has become a key process within other speech processing systems which take advantage of single-speaker speech signals. Furthermore, finding recurrent speakers among a set of audio recordings, known as cross-show diarization, is gaining attention in the last years. Current state-of-the-art-systems provide good performance, but usually at the cost of long processing times. This limitation may make current systems not suitable for real-life applications. In this line, the speaker diarization approach based on binary key modeling provides a very fast yet accurate alternative. In this paper, we present the last improvements applied in binary key speaker diarization with the aim of further speeding up the process and improving performance. In addition, we propose a novel method for cross-show speaker diarization based on binary keys. Experimental results show the effectiveness of the proposed improvements for single-show speaker diarization, both in terms of speed and performance, obtaining a real-time factor of 0.0354xRT and a 16.8% relative improvement in performance. Furthermore, our proposed cross-show approach provides very competitive performance, just slightly worse than its single-show diarization counterpart, and exhibits a real time factor of 0.04xRT."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3868","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3868","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3869","fieldValue":" The work presented here proposes a new voice conversion (VC) approach based on hidden Markov models (HMMs) for spectral conversion and excitation estimation. This paper is divided in two main parts: First, an initial HMM-based VC system is presented and compared to a state-of-the-art ML-GMM VC system in a monolingual conversion scenario with parallel training data; The second part shows the necessary modifications to use the HMM VC system in a cross-lingual conversion scenario and compares it with a cross-lingual VC system based on artificial neural networks (ANNs). The results of the tests show improved performance of the proposed HMM VC system compared with both the ML-GMM and ANN-based VC alternatives, while at the same time keeping most of the flexibility afforded by the ANN approach with respect to training data requirements."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/3869","fieldValue":"A new hmm-based voice conversion methodology evaluated on monolingual and cross-lingual conversion tasks"}