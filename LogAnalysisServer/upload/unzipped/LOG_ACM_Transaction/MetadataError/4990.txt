{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3652","fieldValue":"NIST SRE"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3652","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3652","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3653","fieldValue":" The task of query-by-example spoken term detection (QbE-STD) is to find a spoken query within spoken audio data. Current state-of-the-art techniques assume zero prior knowledge about the language of the audio data, and thus explore dynamic time warping (DTW) based techniques for the QbE-STD task. In this paper, we use a variant of DTW based algorithm referred to as non-segmental DTW (NS-DTW), with a computational upper bound of O(mn) and analyze the performance of QbE-STD with Gaussian posteriorgrams obtained from spectral and temporal features of the speech signal. The results show that frequency domain linear prediction cepstral coefficients, which capture the temporal dynamics of the speech signal, can be used as an alternative to traditional spectral parameters such as linear prediction cepstral coefficients, perceptual linear prediction cepstral coefficients and Mel-frequency cepstral coefficients. We also introduce another variant of NS-DTW called fast NS-DTW (FNS-DTW) which uses reduced feature vectors for search. With a reduction factor of α ∈ N, we show that the computational upper bound for FNS-DTW is $O(mn\/α^2$) which is faster than NS-DTW."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/3653","fieldValue":"Query-by-example spoken term detection using frequency domain linear prediction and non-segmental dynamic time warping"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3653","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3653","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3654","fieldValue":" This paper introduces two new frequency domain overdetermined blind source separation (BSS) algorithms: Inter-frequency Correlation with Microphone Diversity (ICMD), and ICA with Triggered Principal component analysis (ITP). In the first, we consider different sets of microphones, where in each set the number of microphones and sources are equal. In the second, we extract principal components from an overdetermined mixture to form a determined mixture for separation. Both techniques utilize inter-frequency correlation to align permutations via energy profiles. Both monitor the condition number of an inter-frequency cross-correlation matrix of the normalized de-mixed signals' envelopes to determine if separation has failed for the current ICA input configuration; if so, the input configuration is revised and efficiently realigned to produce a better mixture for separation. The complexities and performances of these algorithms are examined in both simulations and a real-room measurement, with three and five sources. They are also compared to other recent frequency domain BSS algorithms for benchmarking purposes. Results show that generally, ICMD and ITP show similar performance with each other and with one of the benchmarking algorithms. However, ICMD is more computationally efficient."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3654","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3654","fieldValue":"ACM"}