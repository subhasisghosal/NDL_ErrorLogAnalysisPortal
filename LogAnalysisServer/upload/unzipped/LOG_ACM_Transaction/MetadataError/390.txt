{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12247","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12248","fieldValue":" Application-level networking is a promising software organizationfor improving performance and functionality for important networkservices. The Xok\/ExOS exokernel system includes application-levelsupport for standard network services, while at the same timeallowing application writers to specialize networking services.This paper describes how Xok\/ExOS's kernel mechanisms and libraryoperating system organization achieve this flexibility, andretrospectively shares our experiences and lessons learned (bothpositive and negative). It also describes how we used thisflexibility to build and specialize three network data services:the Cheetah HTTP server, the webswamp Web benchmarking tool, and anapplication-level TCP forwarder. Overall measurements show largeperformance improvements relative to similar services built onconventional interfaces, in each case reaching the maximum possibleend-to-end performance for the experimental platform. For example,Cheetah provides factor of 2--4 increases in throughput compared tohighly tuned socket-based implementations and factor of 3--8increases compared to conventional systems. Webswamp can offerloads that are two to eight times heavier. The TCP forwarderprovides 50--300% higher throughput while also providing end-to-endTCP semantics that cannot be achieved with POSIX sockets. With moredetailed measurements and profiling, these overall performanceimprovements are also broken down and attributed to the specificspecializations described, providing server writers with insightsinto where to focus their optimization efforts."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12248","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12248","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/2118","fieldValue":" Photonic interconnects have emerged as the prime candidate technology for efficient networks on chip at future process nodes. However, the high optical loss of many nanophotonic components coupled with the low efficiency of current laser sources results in exceedingly high total power requirements for the laser. As optical interconnects stay on even during periods of system inactivity, most of this power is wasted, which has prompted research on laser gating. Unfortunately, prior work has been complicated by the long laser turn-on delays and has failed to deliver the full savings. In this article, we propose ProLaser, a laser control mechanism that monitors the requests sent on the interconnect, the cache, and the coherence directory to detect highly correlated events and turn on proactively the lasers of a photonic interconnect. While ProLaser requires fast lasers with a turn-on delay of a few nanoseconds, a technology that is still experimental, several types of such lasers that are suitable for power gating have already been manufactured over the last decade. Overall, ProLaser saves 42% to 85% of the laser power, outperforms the current state of the art by 2Ã\u2014 on average, and closely tracks (within 2%--6%) a perfect prediction scheme with full knowledge of future interconnect requests. Moreover, the power savings of ProLaser allow the cores to exploit a higher-power budget and run faster, achieving speedups of 1.5 to 1.7Ã\u2014 (1.6Ã\u2014 on average)."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/2118","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/2118","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12249","fieldValue":" Failure-resilient, scalable, and secure read-write access to shared information by mobile and static users over wireless and wired networks is a fundamental computing challenge. In this article, we describe how the Coda file system has evolved to meet this challenge through the development of mechanisms for server replication, disconnected operation, adaptive use of weak connectivity, isolation-only transactions, translucent caching, and opportunistic exploitation of hardware surrogates. For each mechanism, the article explains how usage experience with it led to the insights for another mechanism. It also shows how Coda has been influenced by the work of other researchers and by industry. The article closes with a discussion of the technical and nontechnical lessons that can be learned from the evolution of the system."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12249","fieldValue":"UNIX"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12249","fieldValue":"ACM"}