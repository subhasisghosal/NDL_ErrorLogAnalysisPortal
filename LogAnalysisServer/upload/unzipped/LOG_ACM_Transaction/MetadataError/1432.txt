{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/15391","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/15392","fieldValue":" We propose a new powerful way of synthesizing moiré images that enables the creation of dynamically moving messages incorporating text, symbols, and color elements. Moiré images appear when superposing a base layer made of replicated base bands and a revealing layer made of a line grating comprising thin transparent lines. Each replicated base band contains the same image, e.g. text or color motifs. Since the base bands and the revealing line grating have similar periods, the revealed moiré image is the image located within each base band, enlarged along one dimension. By considering the formation of the moiré image as a line sampling process, we derive the linear transformation between the base layer and the moiré image. We obtain the geometric layout of the resulting moiré image, i.e. its orientation, size and displacement direction when moving the revealing layer on top of the base layer. Interesting moiré images can be synthesized by applying geometric transformations to both the base and the revealing layers. We propose a mathematical model describing the geometric transformation that a moiré image undergoes, when its base layer and its revealing layer are subject to different freely chosen non-linear geometric transformations. By knowing in advance the layout of a moiré image as a function of the layouts of the base layer and of the revealing layer, we are able to create moiré components running up and down at different speeds and orientations upon translation of the revealing layer. We also derive layer transformations which yield periodic moiré images despite the fact that both the base and the revealing layers are curved. By offering a new means of artistic expression, band moiré images can be used to create new designs and to synthesize visually appealing applications."}{"fieldName":"dc.subject","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/15392","fieldValue":"2D moir&eacute;s images"}{"fieldName":"dc.subject","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/15392","fieldValue":"Band moir&eacute;s"}{"fieldName":"dc.subject","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/15392","fieldValue":"Moir&eacute; effect"}{"fieldName":"dc.subject","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/15392","fieldValue":"Moir&eacute; transformation"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/15392","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/15392","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/15393","fieldValue":" We propose a real-time 3D audio rendering pipeline for complex virtual scenes containing hundreds of moving sound sources. The approach, based on auditory culling and spatial level-of-detail, can handle more than ten times the number of sources commonly available on consumer 3D audio hardware, with minimal decrease in audio quality. The method performs well for both indoor and outdoor environments. It leverages the limited capabilities of audio hardware for many applications, including interactive architectural acoustics simulations and automatic 3D voice management for video games.Our approach dynamically eliminates inaudible sources and groups the remaining audible sources into a budget number of clusters. Each cluster is represented by one impostor sound source, positioned using perceptual criteria. Spatial audio processing is then performed only on the impostor sound sources rather than on every original source thus greatly reducing the computational cost.A pilot validation study shows that degradation in audio quality, as well as localization impairment, are limited and do not seem to vary significantly with the cluster budget. We conclude that our real-time perceptual audio rendering pipeline can generate spatialized audio for complex auditory environments without introducing disturbing changes in the resulting perceived soundfield."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/15393","fieldValue":"ACM"}