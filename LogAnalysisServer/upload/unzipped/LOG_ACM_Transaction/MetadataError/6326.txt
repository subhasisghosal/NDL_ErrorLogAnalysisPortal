{"fieldName":"dc.subject","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6830","fieldValue":"3G"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6830","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6830","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6831","fieldValue":" On-chip temperatures continue to rise, in spite of design efforts towards more efficient cooling and novel low-power technologies. Run-time thermal management techniques, such as speed scaling and system throttling, constitute a standard component in today's processors. One such technique is the feedback control of the processing speed based on the on-chip temperature. If suitably designed, such a controller can ensure that the temperature of the processor does not exceed a given bound, independent of the application. Such isolation of needs is encouraging. However, from the application's stand-point, such a processor must provide performance guarantees; in particular, the guarantee that real-time jobs do not have worst-case delays larger than their relative deadlines. For applications which exhibit variability, such as bursty arrival patterns, computing such guarantees is not apparent. As key enablers in such a computation, for the specific setting of First-Come-First-Serve (FCFS) scheduling, we (a) define and prove a monotonicity principle satisfied by the processor with the said controller, and (b) propose a thermally clipped processor model. We identify the worst-case trace simulating which on a suitably chosen thermally clipped processor provides the tight upper-bound on the worst-case delay. These results hold for general models of (a) the power consumption of the processor, (b) its thermal model, (c) the speed scaling law, and (d) the task model. For this modelling scope, we show that the same worst-case trace also leads to the worst-case temperature of the processor. This is useful to characterise tasks which do not load the processor sufficiently to hit the given peak temperature bound. We demonstrate the utility of this calculation by designing a shaper to delay the arrival times of jobs and thereby restrict the observed worst-case temperature while still meeting the task's deadlines."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6831","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6831","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6832","fieldValue":" Most previous work on cache analysis for WCET estimation assumes a particular replacement policy called LRU. In contrast, much less work has been done for non-LRU policies, since they are generally considered to be very unpredictable. However, most commercial processors are actually equipped with these non-LRU policies, since they are more efficient in terms of hardware cost, power consumption and thermal output, while still maintaining almost as good average-case performance as LRU. In this work, we study the analysis of MRU, a non-LRU replacement policy employed in mainstream processor architectures like Intel Nehalem. Our work shows that the predictability of MRU has been significantly underestimated before, mainly because the existing cache analysis techniques and metrics do not match MRU well. As our main technical contribution, we propose a new cache hit\/miss classification, k-Miss, to better capture the MRU behavior, and develop formal conditions and efficient techniques to decide k-Miss memory accesses. A remarkable feature of our analysis is that the k-Miss classifications under MRU are derived by the analysis result of the same program under LRU. Therefore, our approach inherits the advantages in efficiency and precision of the state-of-the-art LRU analysis techniques based on abstract interpretation. Experiments with instruction caches show that our proposed MRU analysis has both good precision and high efficiency, and the obtained estimated WCET is rather close to (typically 1&percnt;âˆ¼8&percnt; more than) that obtained by the state-of-the-art LRU analysis, which indicates that MRU is also a good candidate for cache replacement policies in real-time systems."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6832","fieldValue":"MRU"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6832","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6832","fieldValue":"ACM"}