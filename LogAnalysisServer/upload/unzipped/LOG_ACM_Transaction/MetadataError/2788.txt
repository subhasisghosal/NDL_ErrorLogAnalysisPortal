{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/19224","fieldValue":"Dumas, Jean-Guillaume"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/19224","fieldValue":" In the past two decades, some major efforts have been made to reduce exact (e.g. integer, rational, polynomial) linear algebra problems to matrix multiplication in order to provide algorithms with optimal asymptotic complexity. To provide efficient implementations of such algorithms one need to be careful with the underlying arithmetic. It is well known that modular techniques such as the Chinese remainder algorithm or the p-adic lifting allow very good practical performance, especially when word size arithmetic is used. Therefore, finite field arithmetic becomes an important core for efficient exact linear algebra libraries. In this article, we study high performance implementations of basic linear algebra routines over word size prime fields: especially matrix multiplication; our goal being to provide an exact alternate to the numerical BLAS library. We show that this is made possible by a careful combination of numerical computations and asymptotically faster algorithms. Our kernel has several symbolic linear algebra applications enabled by diverse matrix multiplication reductions: symbolic triangularization, system solving, determinant, and matrix inverse implementations are thus studied."}{"fieldName":"dc.subject","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/19224","fieldValue":"Winograd&rsquo;s symbolic matrix multiplication"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/19224","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19224","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/19225","fieldValue":" We present and compare three C functions to compute the logarithm of the cumulative standard normal distribution. The first is a new algorithm derived from Algorithm 304â\u20AC™s calculation of the standard normal distribution via a series or continued fraction approximation, and it is good to the accuracy of the machine. The second is based on Algorithm 715â\u20AC™s calculation of the standard normal distribution via rational Chebyshev approximation. This is related to, and an improvement on, the algorithm for the logarithm of the normal distribution available in the software package R. The third is a new and simple algorithm that uses the compilerâ\u20AC™s implementation of the error function, and complement of the error function, to compute the log of the normal distribution."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/19225","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/19225","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/19226","fieldValue":" We present a stable and efficient Fortran implementation of polynomial interpolation at the Padua points on the square $[â\u20AC\u2030âˆ\u2019â\u20AC\u20301,1]^2$. These points are unisolvent and their Lebesgue constant has minimal order of growth (log square of the degree). The algorithm is based on the representation of the Lagrange interpolation formula in a suitable orthogonal basis, and takes advantage of a new matrix formulation together with the machine-specific optimized BLAS subroutine for the matrix-matrix product. Extension to interpolation on rectangles, triangles and ellipses is also described."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/19226","fieldValue":"ACM"}