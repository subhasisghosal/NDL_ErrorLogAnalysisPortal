{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/4029","fieldValue":" Fundamental frequency estimation, known as pitch estimation in speech signals is of interest both to the research community and to industry. Meanwhile, the particle filter is known to be a powerful Bayesian inference method to track dynamic parameters in nonlinear state-space models. In this paper, we propose a speech model under a time-varying source-filter speech model, and use variable rate particle filters (VRPF) to develop methods for estimation of pitch periods in speech signals. A Rao--Blackwellised variable rate particle filter (RBVRPF) is also implemented. The proposed VRPF and RBVRPF are compared with a state-of-the-art pitch estimation algorithm, the YIN algorithm. Simulation results show that more accurate estimation of pitch can be obtained by VRPF and RBVRPF even under strong background noise conditions."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/4029","fieldValue":"{\"doi\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/4029","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/4029","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/4030","fieldValue":" Automatic note-level transcription is considered one of the most challenging tasks in music information retrieval. The specific case of flamenco singing transcription poses a particular challenge due to its complex melodic progressions, intonation inaccuracies, the use of a high degree of ornamentation, and the presence of guitar accompaniment. In this study, we explore the limitations of existing state of the art transcription systems for the case of flamenco singing and propose a specific solution for this genre: We first extract the predominant melody and apply a novel contour filtering process to eliminate segments of the pitch contour which originate from the guitar accompaniment. We formulate a set of onset detection functions based on volume and pitch characteristics to segment the resulting vocal pitch contour into discrete note events. A quantised pitch label is assigned to each note event by combining global pitch class probabilities with local pitch contour statistics. The proposed system outperforms state of the art singing transcription systems with respect to voicing accuracy, onset detection, and overall performance when evaluated on flamenco singing datasets."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/4030","fieldValue":"{\"doi\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/4030","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/4030","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/4031","fieldValue":" Local sound field synthesis allows for synthesizing a given desired sound field inside a limited target region such that the field is free of considerable spatial aliasing artifacts. Spatial aliasing artifacts are a consequence of overlaps due to unavoidable repetitions of the space-spectral coefficients of the secondary source driving function. We analyze various conceivable analytic ways of restricting the bandwidth of the spatial spectrum of the driving function such that considerable overlapping is prevented: local spatial bandlimitation (A), spectral windowing (B), and local spatial bandlimitation plus spectral windowing (C). While solution B is computationally significantly more efficient than A and C, it provides only limited control over the spatial location around which the aliasing-free region evolves. Solutions A and C provide more flexibility and higher accuracy whereby both achieve largely identical results so that the spectral windowing after the local spatial bandlimitation may be skipped. We present a detailed analysis of the properties of the spatial aliasing artifacts arising in the synthesis of a virtual plane wave. We establish a procedure for predicting the maximum possible size of the aliasing-free target region depending on its location and on the propagation direction of the desired sound field. The results can help reducing regularization in numerical solutions as they represent physical limitations that can be considered in the choice of parameters."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/4031","fieldValue":"{\"doi\":\"\"}"}