{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25596","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25596","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25597","fieldValue":"Hsu, Cheng-Hsin"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25597","fieldValue":" This article presents the design of a complete, open-source, testbed for broadcast networks that offer mobile TV services. Although basic architectures and protocols have been developed for such networks, detailed performance tuning and analysis are still needed, especially when these networks scale to serve many diverse TV channels to numerous subscribers. The detailed performance analysis could also motivate designing new protocols and algorithms for enhancing future mobile TV networks. Currently, many researchers evaluate the performance of mobile TV networks using simulation and\/or theoretical modeling methods. These methods, while useful for early assessment, typically abstract away many necessary details of actual, fairly complex, networks. Therefore, an open-source platform for evaluating new ideas in a real mobile TV network is needed. This platform is currently not possible with commercial products, because they are sold as black boxes without the source code. In this article, we summarize our experiences in designing and implementing a testbed for mobile TV networks. We integrate off-the-shelf hardware components with carefully designed software modules to realize a scalable testbed that covers almost all aspects of real networks. We use our testbed to empirically analyze various performance aspects of mobile TV networks and validate\/refute several claims made in the literature as well as discover\/quantify multiple important performance tradeoffs."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25597","fieldValue":"DVB-H"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25597","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25597","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/3470","fieldValue":"Ramic-Brkic, Belma"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3470","fieldValue":" Visual perception is becoming increasingly important in computer graphics. Research on human visual perception has led to the development of perception-driven computer graphics techniques, where knowledge of the human visual system (HVS) and, in particular, its weaknesses are exploited when rendering and displaying 3D graphics. Findings on limitations of the HVS have been used to maintain high perceived quality but reduce the computed quality of some of the image without this quality difference being perceived. This article investigates the amount of time for which (if at all) such limitations could be exploited in the presence of smell. The results show that for our experiment, adaptation to smell does indeed affect participantsâ\u20AC™ ability to determine quality difference in the animations. Having been exposed to a smell before undertaking the experiment, participants were able to determine the quality in a similar fashion to the â\u20ACœno smellâ\u20AC? condition, whereas without adaptation, participants were not able to distinguish the quality difference."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3470","fieldValue":"ACM"}