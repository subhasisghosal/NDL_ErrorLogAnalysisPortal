{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1030","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1030","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/1307","fieldValue":"Leung, Ho-Fung"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1307","fieldValue":" Most previous works on coordination in cooperative multiagent systems study the problem of how two (or more) players can coordinate on Pareto-optimal Nash equilibrium(s) through fixed and repeated interactions in the context of cooperative games. However, in practical complex environments, the interactions between agents can be sparse, and each agent's interacting partners may change frequently and randomly. To this end, we investigate the multiagent coordination problems in cooperative environments under a social learning framework. We consider a large population of agents where each agent interacts with another agent randomly chosen from the population in each round. Each agent learns its policy through repeated interactions with the rest of the agents via social learning. It is not clear a priori if all agents can learn a consistent optimal coordination policy in such a situation. We distinguish two different types of learners depending on the amount of information each agent can perceive: individual action learner and joint action learner. The learning performance of both types of learners is evaluated under a number of challenging deterministic and stochastic cooperative games, and the influence of the information sharing degree on the learning performance also is investigatedâ\u20AC\u201Da key difference from the learning framework involving repeated interactions among fixed agents."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1307","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1307","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/4005","fieldValue":" The convergence speed and the computational complexity of adaptive feedback cancellation algorithms both depend on the number of adaptive parameters used to model the acoustic feedback paths. To reduce the number of adaptive parameters it has been proposed to decompose the acoustic feedback paths as the convolution of a time-invariant common part and time-varying variable parts. Instead of estimating all parameters of the common and variable parts by minimizing the misalignment using a least-squares cost function, in this paper we propose to formulate the parameter estimation problem as a min-max optimization problem aiming to maximize the maximum stable gain (MSG). We formulate the min-max optimization problem as a semidefinite program and use a constraint based on Lyapunov theory to guarantee stability of the estimated common pole-zero filter. Experimental results using measured acoustic feedback paths show that the proposed min-max optimization outperforms least-squares optimization in terms of the MSG. Furthermore, the results indicate that the proposed common part decomposition is able to increase the MSG and reduce the number of variable part parameters even for unknown feedback paths that were not included in the optimization. Simulation results using an adaptive feedback cancellation algorithm based on the prediction-error-method show that the convergence speed can be increased by using the proposed feedback path decomposition."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/4005","fieldValue":"A semidefinite programming approach to min-max estimation of the common part of acoustic feedback paths in hearing aids"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/4005","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/4005","fieldValue":"ACM"}