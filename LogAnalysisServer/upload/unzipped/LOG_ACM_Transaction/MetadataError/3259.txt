{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/20706","fieldValue":"Van Nieuwpoort, Rob V."}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/20706","fieldValue":"Jacobs, Ceriel J H"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/20706","fieldValue":" Computational grids have an enormous potential to provide compute power. However, this power remains largely unexploited today for most applications, except trivially parallel programs. Developing parallel grid applications simply is too difficult. Grids introduce several problems not encountered before, mainly due to the highly heterogeneous and dynamic computing and networking environment. Furthermore, failures occur frequently, and resources may be claimed by higher-priority jobs at any time. In this article, we solve these problems for an important class of applications: divide-and-conquer. We introduce a system called Satin that simplifies the development of parallel grid applications by providing a rich high-level programming model that completely hides communication. All grid issues are transparently handled in the runtime system, not by the programmer. Satin's programming model is based on Java, features spawn-sync primitives and shared objects, and uses asynchronous exceptions and an abort mechanism to support speculative parallelism. To allow an efficient implementation, Satin consistently exploits the idea that grids are hierarchically structured. Dynamic load-balancing is done with a novel cluster-aware scheduling algorithm that hides the long wide-area latencies by overlapping them with useful local work. Satin's shared object model lets the application define the consistency model it needs. If an application needs only loose consistency, it does not have to pay high performance penalties for wide-area communication and synchronization. We demonstrate how grid problems such as resource changes and failures can be handled transparently and efficiently. Finally, we show that adaptivity is important in grids. Satin can increase performance considerably by adding and removing compute resources automatically, based on the application's requirements and the utilization of the machines and networks in the grid. Using an extensive evaluation on real grids with up to 960 cores, we demonstrate that it is possible to provide a simple high-level programming model for divide-and-conquer applications, while achieving excellent performance on grids. At the same time, we show that the divide-and-conquer model scales better on large systems than the master-worker approach, since it has no single central bottleneck."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/20706","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/20706","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/20707","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/20707","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/20708","fieldValue":" Modern embedded processors with dedicated address generation unit support memory accesses through auto-increment\/decrement addressing mode. The auto-increment\/decrement mode, if properly utilized, can save address arithmetic instructions, reduce static and dynamic memory footprint of the program, and speed up the execution as well. Liao [1995, 1996] categorized this problem as Simple Offset Assignment (SOA) and General Offset Assignment (GOA), which involves storage layout of variables and assignment of address registers, respectively, proposing several heuristic solutions. This article proposes a new direction for investigating the solution space of the problem. The general idea [Zhuang 2003] is to perform simplification of the underlying access graph through coalescence of the memory locations of program variables. A comprehensive framework is proposed including coalescence-based offset assignment and post\/pre-optimization. Variables not interfering with others (not simultaneously live at any program point) can be coalesced into the same memory location. Coalescing allows simplifications of the access graph yielding better SOA solutions; it also reduces the address register pressure to such low values that some GOA solutions become optimal. Moreover, it can reduce the memory footprint both statically and at runtime for stack variables. Our second optimization (post\/pre-optimization) considers both post- and pre-modification mode for optimizing code across basic blocks, which makes it useful. Making use of both addressing modes further reduces SOA\/GOA cost and our post\/pre-optimization phase is optimal in selecting post or pre mode after variable offsets have been determined. We have shown the advantages of our framework over previous approaches to capture more opportunities to reduce both stack size and SOA\/GOA cost, leading to more speedup."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/20708","fieldValue":"GOA"}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/20708","fieldValue":"SOA"}