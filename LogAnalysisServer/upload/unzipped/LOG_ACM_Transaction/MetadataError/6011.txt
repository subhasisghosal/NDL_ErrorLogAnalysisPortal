{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5944","fieldValue":" Technology increasingly allows us to capture and revisit rich digital records of our lives, processes which we call Technology-Mediated Memory (TMM). We explore whether TMM alters unmediated remembering and also whether such changes affect psychological well-being. Human memory biases promote well-being by adaptively editing our memories, making them more positive. In contrast, TMM often provides rich records of what people actually did and felt, which could disrupt adaptive edits. To explore this, we developed a smartphone-based personal TMM application, Echo, that allows participants to record and later reflect on everyday events. In a month-long deployment, 64 users made over 3200 recordings and reflections. We found that although Echo TMM alters how we remember, these changes remain adaptive. Instead of compromising adaptive biases, Echo TMM helps well-being and benefits are sustained long-term. Logfile analysis shows that participants use Echo strategically to prospectively edit by initially reporting events positively to anticipate future viewing. Participants also distance themselves from past negative events by reflecting more positively than at recording. We discuss design and theoretical implications."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/5944","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/5944","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5945","fieldValue":" In greeting encounters, first impressions of personality and attitude are quickly formed and might determine important relational decisions, such as the likelihood and frequency of subsequent encounters. An anthropomorphic user interface is not immune to these judgments, specifically when exhibiting social interaction skills in public spaces. A favorable impression may help engaging users in interaction and attaining acceptance for long-term interactions. We present three studies implementing a model of first impressions for initiating user interactions with an anthropomorphic museum guide agent with socio-relational skills. We focus on nonverbal behavior exhibiting personality and interpersonal attitude. In two laboratory studies, we demonstrate that impressions of an agent's personality are quickly formed based on proximity, whereas interpersonal attitude is conveyed through smile and gaze. We also found that interpersonal attitude has greater impact than personality on the user's decision to spend time with the agent. These findings are then applied to a museum guide agent exhibited at the Boston Museum of Science. In this field study, we show that employing our model increases the number of visitors engaging in interaction."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/5945","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/5945","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5946","fieldValue":" Smart systems are becoming increasingly ubiquitous and consequently transforming our lives. The level of system autonomy plays a vital role in the development of smart systems as it profoundly affects how people and these systems interact with each other. However, to date, there are very few studies on human interaction with such systems. This paper presents findings from two field studies where two different prototypes for automating energy tariff-switching were developed and evaluated in the wild. Both prototypes offer flexible autonomy by which users can shift the system's level of autonomy among three options: suggestion-only, semi-autonomy, and full autonomy, whenever they like. Our findings based on thematic analysis show that flexible autonomy is a promising way to sustain users' engagement with smart systems, despite their occasional mistakes. The findings also suggest that users take responsibility for the undesired outcomes of automated actions when delegation of autonomy can be adjusted flexibly."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/5946","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/5946","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5947","fieldValue":" Can experimenting with three-dimensional (3D) physical objects in mixed-reality environments produce better learning and enjoyment than flat-screen two-dimensional (2D) interaction? We explored this question with EarthShake: a mixed-reality game bridging physical and virtual worlds via depth-camera sensing, designed to help children learn basic physics principles. In this paper, we report on a controlled experiment with 67 children, 4--8 years old, that examines the effect of observing physical phenomena and collaboration (pairs vs. solo). A follow-up experiment with 92 children tests whether adding simple physical control, such as shaking a tablet, improves learning and enjoyment. Our results indicate that observing physical phenomena in the context of a mixed-reality game leads to significantly more learning and enjoyment compared to screen-only versions. However, there were no significant effects of adding simple physical control or having students play in pairs vs. alone. These results and our gesture analysis provide evidence that children's science learning can be enhanced through experiencing physical phenomena in a mixed-reality environment."}