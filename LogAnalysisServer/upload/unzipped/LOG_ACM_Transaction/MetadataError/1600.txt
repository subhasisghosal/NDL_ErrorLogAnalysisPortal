{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/15830","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/15830","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/15831","fieldValue":" The present contribution aims at creating color images printed with fluorescent inks that are only visible under UV light. The considered fluorescent inks absorb light in the UV wavelength range and reemit part of it in the visible wavelength range. In contrast to normal color printing which relies on the spectral absorption of light by the inks, at low concentration fluorescent inks behave additively, i.e. their light emission spectra sum up. We first analyze to which extent different fluorescent inks can be superposed. Due to the quenching effect, at high concentrations of the fluorescent molecules, the fluorescent effect diminishes. With an ink-jet printer capable of printing pixels at reduced dot sizes, we reduce the concentration of the individual fluorescent inks and are able to create from the blue, red and greenish-yellow inks the new colorants white and magenta. In order to avoid quenching effects, we propose a color halftoning method relying on diagonally oriented pre-computed screen dots, which are printed side by side. For gamut mapping and color separation, we create a 3D representation of the fluorescent ink gamut in CIELAB space by predicting halftone fluorescent emission spectra according to the spectral Neugebauer model. Thanks to gamut mapping and juxtaposed halftoning, we create color images, which are invisible under daylight and have, under UV light, a high resemblance with the original images."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/15831","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/15831","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/15832","fieldValue":" Efficient, realistic rendering of complex scenes is one of the grand challenges in computer graphics. Perceptually based rendering addresses this challenge by taking advantage of the limits of human vision. However, existing methods, based on predicting visible image differences, are too conservative because some kinds of image differences do not matter to human observers. In this paper, we introduce the concept of visual equivalence, a new standard for image fidelity in graphics. Images are visually equivalent if they convey the same impressions of scene appearance, even if they are visibly different. To understand this phenomenon, we conduct a series of experiments that explore how object geometry, material, and illumination interact to provide information about appearance, and we characterize how two kinds of transformations on illumination maps (blurring and warping) affect these appearance attributes. We then derive visual equivalence predictors (VEPs): metrics for predicting when images rendered with transformed illumination maps will be visually equivalent to images rendered with reference maps. We also run a confirmatory study to validate the effectiveness of these VEPs for general scenes. Finally, we show how VEPs can be used to improve the efficiency of two rendering algorithms: Light-cuts and precomputed radiance transfer. This work represents some promising first steps towards developing perceptual metrics based on higher order aspects of visual coding."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/15832","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/15832","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/2501","fieldValue":" Given two rooted, ordered, and labeled trees P and T the tree inclusion problem is to determine if P can be obtained from T by deleting nodes in T. This problem has recently been recognized as an important query primitive in XML databases. Kilpel√§inen and Mannila [1995] presented the first polynomial-time algorithm using quadratic time and space. Since then several improved results have been obtained for special cases when P and T have a small number of leaves or small depth. However, in the worst case these algorithms still use quadratic time and space. Let $n_S, lS, and dS denote the number of nodes, the number of leaves, and the depth of a tree S &in; P, T. In this article we show that the tree inclusion problem can be solved in space O(nT$) and time: O‚é\u203A‚é?min‚éß‚é®‚é©lPnTlPlT log log nT + nTnPnTlog nT+ nT log nT‚é´‚é¨‚é≠‚éû‚é†. This improves or matches the best known time complexities while using only linear space instead of quadratic. This is particularly important in practical applications, such as XML databases, where the space is likely to be a bottleneck."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/2501","fieldValue":"ACM"}