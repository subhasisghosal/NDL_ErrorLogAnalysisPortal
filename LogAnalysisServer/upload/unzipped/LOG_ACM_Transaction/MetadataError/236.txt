{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/11671","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/11671","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/11672","fieldValue":" Many tractable algorithms for solving the Constraint Satisfaction Problem (Csp) have been developed using the notion of the treewidth of some graph derived from the input Csp instance. In particular, the incidence graph of the Csp instance is one such graph. We introduce the notion of an incidence graph for modal logic formulas in a certain normal form. We investigate the parameterized complexity of modal satisfiability with the modal depth of the formula and the treewidth of the incidence graph as parameters. For various combinations of Euclidean, reflexive, symmetric, and transitive models, we show either that modal satisfiability is Fixed Parameter Tractable (Fpt), or that it is W[1]-hard. In particular, modal satisfiability in general models is Fpt, while it is W[1]-hard in transitive models. As might be expected, modal satisfiability in transitive and Euclidean models is Fpt."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/11672","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/11672","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/11673","fieldValue":" Let D denote an infinite alphabet -- a set that consists of infinitely many symbols. A word $wâ\u20AC\u2030=â\u20AC\u2030a0b0a1b1â\u20AC\u2030&ctdot;â\u20AC\u2030anb_n of even length over D can be viewed as a directed graph Gw whose vertices are the symbols that appear in w, and the edges are (a0, b0), (a1, b1), ..., (an, bn). For a positive integer m, define a language Rm such that a word wâ\u20AC\u2030=â\u20AC\u2030a0b0â\u20AC\u2030&ctdot;â\u20AC\u2030anbnâ\u20AC\u2030âˆˆâ\u20AC\u2030Rm if and only if there is a path in the graph Gw of length â\u2030¤â\u20AC\u2030m from the vertex a0 to the vertex bn. We establish the following hierarchy theorem for pebble automata over infinite alphabet. For every positive integer k, (i) there exists a k-pebble automaton that accepts the language R2kâ\u20AC\u2030âˆ\u2019â\u20AC\u20301; (ii) there is no k-pebble automaton that accepts the language R2kâ\u20AC\u2030+â\u20AC\u20301â\u20AC\u2030âˆ\u2019â\u20AC\u20302$. Using this fact, we establish the following main results in this article: (a) a strict hierarchy of the pebble automata languages based on the number of pebbles; (b) the separation of monadic second order logic from the pebble automata languages; (c) the separation of one-way deterministic register automata languages from pebble automata languages."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/11673","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/11673","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/2068","fieldValue":" While hardware is evolving toward heterogeneous multicore architectures, modern software applications are increasingly written in managed languages. Heterogeneity was born of a need to improve energy efficiency; however, we want the performance of our applications not to suffer from limited resources. How best to schedule managed language applications on a mix of big, out-of-order cores and small, in-order cores is an open question, complicated by the host of service threads that perform key tasks such as memory management. These service threads compete with the application for core and memory resources, and garbage collection (GC) must sometimes suspend the application if there is not enough memory available for allocation. In this article, we explore concurrent garbage collectionâ\u20AC™s behavior, particularly when it becomes critical, and how to schedule it on a heterogeneous system to optimize application performance. While some applications see no difference in performance when GC threads are run on big versus small cores, othersâ\u20AC\u201Dthose with GC criticalityâ\u20AC\u201Dsee up to an 18&percnt; performance improvement. We develop a new, adaptive scheduling algorithm that responds to GC criticality signals from the managed runtime, giving more big-core cycles to the concurrent collector when it is under pressure and in danger of suspending the application. Our experimental results show that our GC-criticality-aware scheduler is robust across a range of heterogeneous architectures with different core counts and frequency scaling and across heap sizes. Our algorithm is performance and energy neutral for GC-uncritical Java applications and significantly speeds up GC-critical applications by 16&percnt;, on average, while being 20&percnt; more energy efficient for a heterogeneous multicore with three big cores and one small core."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/2068","fieldValue":"ACM"}