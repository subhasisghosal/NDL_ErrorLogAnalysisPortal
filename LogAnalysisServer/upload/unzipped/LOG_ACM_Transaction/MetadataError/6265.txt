{"fieldName":"dc.subject","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/6683","fieldValue":"Moore&rsquo;s law"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6683","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6683","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6684","fieldValue":" We present QuickStep, a novel system for parallelizing sequential programs. Unlike standard parallelizing compilers (which are designed to preserve the semantics of the original sequential computation), QuickStep is instead designed to generate (potentially nondeterministic) parallel programs that produce acceptably accurate results acceptably often. The freedom to generate parallel programs whose output may differ (within statistical accuracy bounds) from the output of the sequential program enables a dramatic simplification of the compiler, a dramatic increase in the range of applications that it can parallelize, and a significant expansion in the range of parallel programs that it can legally generate. Results from our benchmark set of applications show that QuickStep can automatically generate acceptably accurate and efficient parallel programs---the automatically generated parallel versions of five of our six benchmark applications run between 5.0 and 7.8 times faster on eight cores than the original sequential versions. These applications and parallelizations contain features (such as the use of modern object-oriented programming constructs or desirable parallelizations with infrequent but acceptable data races) that place them inherently beyond the reach of standard approaches."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6684","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6684","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6685","fieldValue":" Escalating variations in modern CMOS designs have become a threat to Mooreâ\u20AC™s law. In light of the increasing costs of standard worst-case design practices, timing speculation has become a popular approach for dealing with static and dynamic non-determinism and increasing yield. Timing speculative architectures allow conservative guardbands to be relaxed, increasing efficiency at the expense of occasional errors, which are corrected or tolerated by an error resilience mechanism. Previous work has proposed circuit- or design-level optimizations that manipulate the error rate behavior of a design to increase the efficiency of timing speculation. In this article, we investigate whether architectural optimizations can also manipulate error rate behavior to significantly increase the effectiveness of timing speculation. To this end, we demonstrate how error rate behavior indeed depends on processor architecture and that architectural optimizations can be used to manipulate the error rate behavior of a processor. Using timing speculation-aware architectural optimizations, we demonstrate enhanced overscaling and up to 29&percnt; additional energy savings for processors that employ Razor-based timing speculation."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6685","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6685","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/6686","fieldValue":"Chippa, Vinay K"}