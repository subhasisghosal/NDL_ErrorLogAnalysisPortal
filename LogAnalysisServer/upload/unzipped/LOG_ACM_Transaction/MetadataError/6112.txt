{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6309","fieldValue":" Because of stringent power constraints, aggressive latency-hiding approaches, such as prefetching, are absent in the state-of-the-art embedded processors. There are two main reasons that make prefetching power inefficient. First, compiler-inserted prefetch instructions increase code size and, therefore, could increase I-cache power. Second, inaccurate prefetching (especially for hardware prefetching) leads to high D-cache power consumption because of useless accesses. In this work, we show that it is possible to support power-efficient prefetching through bit-differential offset assignment. We target the prefetching of relocatable stack variables with a high degree of precision. By assigning the offsets of stack variables in such a way that most consecutive addresses differ by 1 bit, we can prefetch them with compact prefetch instructions to save I-cache power. The compiler first generates an access graph of consecutive memory references and then attempts a layout of the memory locations in the smallest hypercube. Each dimension of the hypercube represents a 1-bit differential addressing. The embedding is carried out in as compact a hypercube as possible in order to save memory space. Each load\/store instruction carries a hint regarding prefetching the next memory reference by encoding its differential address with respect to the current one. To reduce D-cache power cost, we further attempt to assign offsets so that most of the consecutive accesses map to the same cache line. Our prefetching is done using a one entry line buffer [Wilson et al. 1996]. Consequently, many look-ups in D-cache reduce to incremental ones. This results in D-cache activity reduction and power savings. Our prefetcher requires both compiler and hardware support. In this paper, we provide implementation on the processor model close to ARM with small modification to the ISA. We tackle issues such as out-of-order commit, predication, and speculation through simple modifications to the processor pipeline on noncritical paths. Our goal in this work is to boost performance while maintaining\/lowering power consumption. Our results show 12&percnt; speedup and slight power reduction. The runtime virtual space loss for stack and static data is about 11.8&percnt;."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6309","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6309","fieldValue":"ACM"}{"fieldName":"dc.contributor.editor","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/1525","fieldValue":"De Bosschere, Koen"}{"fieldName":"dc.relation.haspart","informationCode":"ERR_FORMAT_HASPART","handle":"12345678_acm\/1525","fieldValue":"[{\"visible\":false,\"sortKey\":\"13\",\"expandable\":true,\"handle\":\"12345678_acm\/1538\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 13\"},{\"visible\":false,\"sortKey\":\"12\",\"expandable\":true,\"handle\":\"12345678_acm\/1537\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 12\"},{\"visible\":false,\"sortKey\":\"11\",\"expandable\":true,\"handle\":\"12345678_acm\/1536\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 11\"},{\"visible\":false,\"sortKey\":\"10\",\"expandable\":true,\"handle\":\"12345678_acm\/1535\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 10\"},{\"visible\":false,\"sortKey\":\"9\",\"expandable\":true,\"handle\":\"12345678_acm\/1534\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 9\"},{\"visible\":false,\"sortKey\":\"8\",\"expandable\":true,\"handle\":\"12345678_acm\/1533\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 8\"},{\"visible\":false,\"sortKey\":\"7\",\"expandable\":true,\"handle\":\"12345678_acm\/1532\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 7\"},{\"visible\":false,\"sortKey\":\"6\",\"expandable\":true,\"handle\":\"12345678_acm\/1531\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 6\"},{\"visible\":false,\"sortKey\":\"5\",\"expandable\":true,\"handle\":\"12345678_acm\/1530\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 5\"},{\"visible\":false,\"sortKey\":\"4\",\"expandable\":true,\"handle\":\"12345678_acm\/1529\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 4\"},{\"visible\":false,\"sortKey\":\"3\",\"expandable\":true,\"handle\":\"12345678_acm\/1528\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 3\"},{\"visible\":false,\"sortKey\":\"2\",\"expandable\":true,\"handle\":\"12345678_acm\/1527\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 2\"},{\"visible\":false,\"sortKey\":\"1\",\"expandable\":true,\"handle\":\"12345678_acm\/1526\",\"title\":\"ACM Transactions on Architecture and Code Optimization (TACO) : Volume 1\"}]"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/6310","fieldValue":"Lueh, Guei-Yuan"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6310","fieldValue":" Managing power concerns in microprocessors has become a pressing research problem across the domains of computer architecture, CAD, and compilers. As a result, several parameterized cycle-level power simulators have been introduced. While these simulators can be quite useful for microarchitectural studies, their generality limits how accurate they can be for any one chip family. Furthermore, their hardware focus means that they do not explicitly enable studying the interaction of different software layers, such as Java applications and their underlying runtime system software. This paper describes and evaluates XTREM, a power-simulation tool tailored for the Intel XScale microarchitecture. In building XTREM, our goals were to develop a microarchitecture simulator that, while still offering size parameterizations for cache and other structures, more accurately reflected a realistic processor pipeline. We present a detailed set of validations based on multimeter power measurements and hardware performance counter sampling. XTREM exhibits an average performance error of only 6.5&percnt; and an even smaller average power error: 4&percnt;. The paper goes on to present an application study enabled by the simulator. Namely, we use XTREM to produce an energy consumption breakdown for Java CDC and CLDC applications. Our simulator measurements indicate that a large percentage of the total energy consumption (up to 35&percnt;) is devoted to the virtual machine's support functions."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6310","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6310","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/6311","fieldValue":"De Sutter, Bjorn"}