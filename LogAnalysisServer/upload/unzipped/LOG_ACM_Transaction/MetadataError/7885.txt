{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1965","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1965","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10583","fieldValue":" A large number of congestion control protocols have been proposed in the last few years, with all having the same purpose--to divide available bandwidth resources among different flows in a fair manner. Each protocol operates on the paradigm of some conception of link price (such as packet losses or packet delays) that determines source transmission rates. Recent work on network utility maximization has brought forth the idea that the fundamental price or Lagrange multiplier for a link is proportional to the queue length at that link, and that different congestion metrics (such as delays or drops) are essentially ways of interpreting such a Lagrange multiplier. We thus ask the following question: Suppose that each flow has a number of congestion control protocols to choose from, which one (or combination) should it choose? We introduce a framework wherein each flow has a utility that depends on throughput and also has a disutility that is some function of the queue lengths encountered along the route taken. Flows must choose a combination of protocols that would maximize their payoffs. We study both the socially optimal, as well as the selfish cases to determine the loss of system-wide value incurred through selfish decision making, so characterizing the \"price of heterogeneity.\" We also propose tolling schemes that incentivize flows to choose one of several different virtual networks catering to particular needs and show that the total system value is greater, hence making a case for the adoption of such virtual networks."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10583","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10583","fieldValue":"TCP\/IP"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/10583","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10583","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10584","fieldValue":" A fundamental problem in survivable routing in wavelength division multiplexing (WDM) optical networks is the computation of a pair of link-disjoint (or node-disjoint) lightpaths connecting a source with a destination, subject to the wavelength continuity constraint. However, this problem is NP-hard when the underlying network topology is a general mesh network. As a result, heuristic algorithms and integer linear programming (ILP) formulations for solving this problem have been proposed. In this paper, we advocate the use of 2-edge connected (or 2-node connected) subgraphs of minimum isolated failure immune networks as the underlying topology for WDM optical networks. We present a polynomial-time algorithm for computing a pair of link-disjoint lightpaths with shortest total length in such networks. The running time of our algorithm is $O(nW^2$), where n is the number of nodes, and W is the number of wavelengths per link. Numerical results are presented to demonstrate the effectiveness and scalability of our algorithm. Extension of our algorithm to the node-disjoint case is straightforward."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10584","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/10584","fieldValue":"A polynomial-time algorithm for computing disjoint lightpath pairs in minimum isolated-failure-immune WDM optical networks"}