{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5480","fieldValue":" Current input device taxonomies and other frameworks typically emphasize the mechanical structure of input devices. We suggest that selecting an appropriate input device for an interactive task requires looking beyond the physical structure of devices to the deeper perceptual structure of the task, the device, and the interrelationship between the perceptual structure of the task and the control properties of the device. We affirm that perception is key to understanding performance of multidimensional input devices on multidimensional tasks. We have therefore extended the theory of processing of percetual structure to graphical interactive tasks and to the control structure of input devices. This allows us to predict task and device combinations that lead to better performance and hypothesize that performance is improved when the perceptual structure of the task matches the control structure of the device. We conducted an experiment in which subjects performed two tasks with different perceptual structures, using two input devices with correspondingly different control structures, a three-dimensional tracker and a mouse. We analyzed both speed and accuracy, as well as the trajectories generated by subjects as they used the unconstrained three-dimensional tracker to perform each task. The result support our hypothesis and confirm the importance of matching the perceptual structure of the task and the control structure of the input device."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/5480","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/5480","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5481","fieldValue":" When some items in a menu are selected more frequently than others, as is often the case, designers or individual users may be able to speed performance and improve preference ratings by placing several high-frequency items at the top of the menu. Design guidelines for split menus were developed and applied. Split menus were implemented and tested in two in situ usability studies and a controlled experiment. In the usability studies performance times were reduced by 17 to 58% depending on the site and menus. In the controlled experiment split menus were significantly faster than alphabetic menus and yielded significantly higher subjective preferences. A possible resolution to the continuing debate among cognitive theorists about predicting menu selection times is offered. We conjecture and offer evidence that, at least when selecting items from pull-down menus, a logarithmic model applies to familiar (high-frequency) items, and a linear model to unfamiliar (low-frequency) items."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/5481","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/5481","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5482","fieldValue":" The development of human-computer interfaces was studied in two large software product development organizations. Researchers joined development projects for approximately one month and participated in interface design while concurrently interviewing other project participants and employees, recording activity in meetings and on electronic networks, and otherwise observing the process. The two organizations differed in their approaches to development, and, in each case, the approach differed in practice from the model supported by the organizational structure. Development practices blocked the successful application of accepted principles of interface design. The obstacles to effective design that results from people noticing and being affected by interface changes, and a lack of communication among those sharing responsibility for different aspects of the interface."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/5482","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/5482","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5483","fieldValue":" When people have meetings or discussions, frequently they use conversational props: physical models, drawings, or other concrete representations of information used to enhance the exchange of information. If the participants are geographically separated, it is difficult to make effective use of props since each physical prop can only exist in one place. Computer applications that allow two or more users to simultaneously view and manipulate the same data can be used to augment human-to-human telecommunication. We have built the Rendezvous system is similar to many UIMSs or user interface toolkits in that it is intended to simplify the construction of graphical direct-manipulation interfaces. It goes beyond these systems by adding functionality to support the construction of multiuser applications. Based on experience with several large applications built with the Rendezvous system, we believe that it is useful for building conversational props and other computer-supported cooperative work (CSCW) applications. We present a list of required features of conversational props, some example applications built with the Rendezvous system, and a description of the Rendezvous system."}