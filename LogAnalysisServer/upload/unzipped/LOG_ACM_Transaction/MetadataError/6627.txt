{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7647","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/7648","fieldValue":"Chen, Bo-Hao"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/7648","fieldValue":"Huang, Shih-Chia"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7648","fieldValue":" Visibility restoration techniques are widely used for information recovery of hazy images in many computer vision applications. Estimation of haze density is an essential task of visibility restoration techniques. However, conventional visibility restoration techniques often suffer from either the generation of serious artifacts or the loss of object information in the restored images due to uneven haze density, which usually means that the images contain heavy haze formation within their background regions and little haze formation within their foreground regions. This frequently occurs when the images feature real-world scenes with a deep depth of field. How to effectively and accurately estimate the haze density in the transmission map for these images is the most challenging aspect of the traditional state-of-the-art techniques. In response to this problem, this work proposes a novel visibility restoration approach that is based on Bi-Histogram modification, and which integrates a haze density estimation module and a haze formation removal module for effective and accurate estimation of haze density in the transmission map. As our experimental results demonstrate, the proposed approach achieves superior visibility restoration efficacy in comparison with the other state-of-the-art approaches based on both qualitative and quantitative evaluations. The proposed approach proves effective and accurate in terms of both background and foreground restoration of various hazy scenarios."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7648","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7648","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7649","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7649","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7650","fieldValue":" In spite of the importance of activity recognition (AR) for intelligent human-computer interaction in emerging smart space applications, state-of-the-art AR technology is not ready or adequate for real-world deployments due to its insufficient accuracy. The accuracy limitation is directly attributed to uncertainties stemming from multiple sources in the AR system. Hence, one of the major goals of AR research is to improve system accuracy by minimizing or managing the uncertainties encountered throughout the AR process. As we cannot manage uncertainties well without measuring them, we must first quantify their impact. Nevertheless, such a quantification process is very challenging given that uncertainties come from diverse and heterogeneous sources. In this article, we propose an approach, which can account for multiple uncertainty sources and assess their impact on AR systems. We introduce several metrics to quantify the various uncertainties and their impact. We then conduct a quantitative impact analysis of uncertainties utilizing data collected from actual smart spaces that we have instrumented. The analysis is intended to serve as groundwork for developing â\u20ACœdiagnosticâ\u20AC? accuracy measures of AR systems capable of pinpointing the sources of accuracy loss. This is to be contrasted with the currently used accuracy measures."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7650","fieldValue":"ACM"}