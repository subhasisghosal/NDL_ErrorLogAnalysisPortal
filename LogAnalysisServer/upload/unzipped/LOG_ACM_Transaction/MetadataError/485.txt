{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12525","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12525","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12526","fieldValue":" We prove a lower bound on the amount of nonuniform advice needed by black-box reductions for the Dense Model Theorem of Green, Tao, and Ziegler, and of Reingold, Trevisan, Tulsiani, and Vadhan. The latter theorem roughly says that for every distribution D that is Î\u201D-dense in a distribution that is Îµâ\u20AC²-indistinguishable from uniform, there exists a â\u20ACœdense modelâ\u20AC? for D, that is, a distribution that is Î\u201D-dense in the uniform distribution and is Îµ-indistinguishable from D. This Îµ-indistinguishability is with respect to an arbitrary small class of functions F. For the natural case where Îµâ\u20AC² â\u2030¥ Î©(ÎµÎ\u201D) and Îµ â\u2030¥ Î\u201DO(1), our lower bound implies that Î©(âˆš(1\/Îµ) log(1\/Î\u201D)Â·log|F|) advice bits are necessary for a certain type of reduction that establishes a stronger form of the Dense Model Theorem (and which encompasses all known proofs of the Dense Model Theorem in the literature). There is only a polynomial gap between our lower bound and the best upper bound for this case (due to Zhang), which is O((1\/Îµ2)log(1\/Î\u201D)Â·log|F|). Our lower bound can be viewed as an analogue of list size lower bounds for list-decoding of error-correcting codes, but for â\u20ACœdense model decodingâ\u20AC? instead."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12526","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12526","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/2198","fieldValue":" This paper studies the distribution of individual displacements for the standard and the Robin Hood linear probing hashing algorithms. When the a table of size m has n elements, the distribution of the search cost of a random element is studied for both algorithms. Specifically, exact distributions for fixed m and n are found as well as when the table is Î±-full, and Î± strictly smaller than 1. Moreover, for full tables, limit laws for both algorithms are derived."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/2198","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/2198","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12527","fieldValue":" We study local filters for two properties of functions of the form f : {0,1}d â\u2020\u2019 R: the Lipschitz property and monotonicity. A local filter with additive error a is a randomized algorithm that is given black-box access to a function f and a query point x in the domain of f. It outputs a value F(x) such that (i) the reconstructed function F(x) satisfies the property (in our case, is Lipschitz or monotone) and (ii) if the input function f satisfies the property, then for every point x in the domain (with high constant probability) the reconstructed value F(x) differs from f(x) by at most a. Local filters were introduced by Saks and Seshadhri [2010]. The relaxed definition we study is due to Bhattacharyya et al. [2012], except that we further relax it by allowing additive error. Local filters for Lipschitz and monotone functions have applications to areas such as data privacy. We show that every local filter for Lipschitz or monotone functions runs in time exponential in the dimension d, even when the filter is allowed significant additive error. Prior lower bounds (for local filters with no additive error, that is, with a=0) applied only to a more restrictive class of filters, for example, nonadaptive filters. To prove our lower bounds, we construct families of hard functions and show that lookups of a local filter on these functions are captured by a combinatorial object that we call a c-connector. Then we present a lower bound on the maximum outdegree of a c-connector and show that it implies the desired bounds on the running time of local filters. Our lower bounds, in particular, imply the same bound on the running time for a class of privacy mechanisms."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12527","fieldValue":"ACM"}