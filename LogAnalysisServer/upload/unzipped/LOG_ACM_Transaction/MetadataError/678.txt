{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13091","fieldValue":"FPGA"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13091","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13091","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13092","fieldValue":" Recent advanced power optimizations deployed in commercial FPGAs, laid out a roadmap towards FPGA devices that can be integrated into ultra low power systems. In this article, we present a high-level design tool to support the process of mapping an application onto a FPGA device with dual supply voltages. Our main contribution in this paper is an algorithm, which creates voltage scaling ready clusters by utilizing the timing slack available in the designs. We propose to first create clusters of CLBs within a given CLB-level netlist. This clustering algorithm intends to group chains of CLBs possessing similar amounts of timing slack along their critical path together. Once these clusters are identified, they are placed onto respective $V_dd partitions on the device. We have evaluated different dual Vdd fabrics and the potential gain in power consumption is explored. When a subset of the logic blocks on the device can be driven by low Vdd levels (either with a dedicated low Vdd supply or with a programmable selection between low and high Vdd$ levels for these blocks) this affects placement and routing. As a result the maximum frequency of the designs may be affected. In order to evaluate the overall impact of creating voltage islands, we measured the Energy-Delay Product for our benchmark designs. We observed that the Energy-Delay product can be decreased by 26.9&percnt; when the placement of the designs into different voltage levels is guided by our clustering algorithm."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13092","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13092","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/2247","fieldValue":" We introduce a new paradigm for querying strings in external memory, suited to the execution of sequences of operations. Formally, given a dictionary of n strings $S_1, â\u20AC¦, Sn, we aim at supporting a search sequence for m not necessarily distinct strings T1, T2, â\u20AC¦, Tm, as well as inserting and deleting individual strings. The dictionary is stored on disk, where each access to a disk page fetches B items, the cost of an operation is the number of pages accessed (I\/Os), and efficiency must be attained on entire sequences of string operations rather than on individual ones. Our approach relies on a novel and conceptually simple self-adjusting data structure (SASL) based on skip lists, that is also interesting per se. The search for the whole sequence T1, T2, â\u20AC¦, Tm can be done in an expected number of I\/Os: $O(âˆ\u2018j&equals;1^m &verbar;Tj&verbar;\/B &plus; âˆ\u2018i&equals;1nn (ni logB m\/ni)), where each Tj may or may not be present in the dictionary, and ni is the number of times Si is queried (i.e., the number of Tjs equal to Si). Moreover, inserting or deleting a string Si takes an expected amortized number O(&verbar;Si&verbar;\/B &plus; logB n) of I\/Os. The term âˆ\u2018j&equals;1m &verbar;Tj&verbar;\/B in the search formula is a lower bound for reading the input, and the term âˆ\u2018i&equals;1n$ ni logB m\/ni$ (entropy of the query sequence) is a standard information-theoretic lower bound. We regard this result as the static optimality theorem for external-memory string access, as compared to Sleator and Tarjan's classical theorem for numerical dictionaries [Sleator and Tarjan 1985]. Finally, we reformulate the search bound if a cache is available, taking advantage of common prefixes among the strings examined in the search."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/2247","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/2247","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13093","fieldValue":" Due to the emergence of portable devices that must run complex dynamic applications there is a need for flexible platforms for embedded systems. Runtime reconfigurable hardware can provide this flexibility but the reconfiguration latency can significantly decrease the performance. When dealing with task graphs, runtime support that schedules the reconfigurations in advance can drastically reduce this overhead. However, executing complex scheduling heuristics at runtime may generate an excessive penalty. Hence, we have developed a hybrid design-time\/runtime reconfiguration scheduling heuristic that generates its final schedule at runtime but carries out most computations at design-time. We have tested our approach in a PowerPC 405 processor embedded on a FPGA demonstrating that it generates a very small runtime penalty while providing almost as good schedules as a full runtime approach."}