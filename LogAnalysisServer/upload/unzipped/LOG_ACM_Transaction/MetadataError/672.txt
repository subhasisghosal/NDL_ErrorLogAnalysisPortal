{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13075","fieldValue":"FPGA"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13075","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13075","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13076","fieldValue":" The Scale vector-thread processor is a complexity-effective solution for embedded computing which flexibly supports both vector and highly multithreaded processing. The 7.1-million transistor chip has 16 decoupled execution clusters, vector load and store units, and a nonblocking 32KB cache. An automated and iterative design and verification flow enabled a performance-, power-, and area-efficient implementation with two person-years of development effort. Scale has a core area of 16.6 $mm^2$ in 180 nm technology, and it consumes 400 mW--1.1 W while running at 260 MHz."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13076","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13076","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13077","fieldValue":" Functional validation is a major bottleneck in pipelined processor design due to the combined effects of increasing design complexity and lack of efficient techniques for directed test generation. Directed test vectors can reduce overall validation effort, since shorter tests can obtain the same coverage goal compared to the random tests. This article presents a specification-driven directed test generation methodology. The proposed methodology makes three important contributions. First, a general graph model is developed that can capture the structure and behavior (instruction set) of a wide variety of pipelined processors. The graph model is generated from the processor specification. Next, we propose a functional fault model that is used to define the functional coverage for pipelined architectures. Finally, we propose two complementary test generation techniques: test generation using model checking, and test generation using template-based procedures. These test generation techniques accept the graph model of the architecture as input and generate test programs to detect all the faults in the functional fault model. Our experimental results on two pipelined processor models demonstrate several orders-of-magnitude reduction in overall validation effort by drastically reducing both test-generation time and number of test programs required to achieve a coverage goal."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13077","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13077","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13078","fieldValue":" Memory devices often consume more energy than microprocessors in current portable embedded systems, but their energy consumption changes significantly with the type of transaction, data values, and access timing, as well as depending on the total number of transactions. These variabilities mean that an innovative tool and framework are required to characterize modern memory devices running in embedded system architectures. We introduce an energy measurement and characterization platform for memory devices, and demonstrate an application to multilevel-cell (MLC) flash memories, in which we discover significant value-dependent programming energy variations. We introduce an energy-aware data compression method that minimizes the flash programming energy, rather than the size of the compressed data, which is formulated as an entropy coding with unequal bit-pattern costs. Deploying a probabilistic approach, we derive energy-optimal bit-pattern probabilities and expected values of the bit-pattern costs which are applicable to the large amounts of compressed data typically found in multimedia applications. Then we develop an energy-optimal prefix coding that uses integer linear programming, and construct a prefix-code table. From a consideration of Pareto-optimal energy consumption, we can make tradeoffs between data size and programming energy, such as a 41&percnt; energy savings for a 52&percnt; area overhead."}