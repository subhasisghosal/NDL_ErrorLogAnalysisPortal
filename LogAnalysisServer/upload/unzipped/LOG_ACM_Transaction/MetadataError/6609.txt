{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7603","fieldValue":" Wikipedia is probably the most commonly used knowledge reference nowadays, and the high quality of its articles is widely acknowledged. Nevertheless, disagreement among editors often causes some articles to become controversial over time. These articles span thousands of popular topics, including religion, history, and politics, to name a few, and are manually tagged as controversial by the editors, which is clearly suboptimal. Moreover, disagreement, bias, and conflict are expressed quite differently in Wikipedia compared to other social media, rendering previous approaches ineffective. On the other hand, the social process of editing Wikipedia is partially captured in the edit history of the articles, opening the door for novel approaches. This article describes a novel controversy model that builds on the interaction history of the editors and not only predicts controversy but also sheds light on the process that leads to controversy. The model considers the collaboration history of pairs of editors to predict their attitude toward one another. This is done in a supervised way, where the votes of Wikipedia administrator elections are used as labels indicating agreement (i.e., support vote) or disagreement (i.e., oppose vote). From each article, a collaboration network is built, capturing the pairwise attitude among editors, allowing the accurate detection of controversy. Extensive experimental results establish the superiority of this approach compared to previous work and very competitive baselines on a wide range of settings."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7603","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7603","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/7604","fieldValue":"Bouchon-Meunier, Bernadette"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7604","fieldValue":" The objective of any tutoring system is to provide resources to learners that are adapted to their current state of knowledge. With the availability of a large variety of online content and the disjunctive nature of results provided by traditional search engines, it becomes crucial to provide learners with adapted learning paths that propose a sequence of resources that match their learning objectives. In an ideal case, the sequence of documents provided to the learner should be such that each new document relies on concepts that have been already defined in previous documents. Thus, the problem of determining an effective learning path from a corpus of web documents depends on the accurate identification of outcome and prerequisite concepts in these documents and on their ordering according to this information. Until now, only a few works have been proposed to distinguish between prerequisite and outcome concepts, and to the best of our knowledge, no method has been introduced so far to benefit from this information to produce a meaningful learning path. To this aim, this article first describes a concept annotation method that relies on machine-learning techniques to predict the class of each conceptâ\u20AC\u201Dprerequisite or outcomeâ\u20AC\u201Don the basis of contextual and local features. Then, this categorization is exploited to produce an automatic resource sequencing on the basis of different representations and scoring functions that transcribe the precedence relation between learning resources. Experiments conducted on a real dataset built from online resources show that our concept annotation approach outperforms the baseline method and that the learning paths automatically generated are consistent with the ground truth provided by the author of the online content."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7604","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7604","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/7605","fieldValue":"Jennings, Nicholas R"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7605","fieldValue":" Minimizing the energy consumed by heating, ventilation, and air conditioning (HVAC) systems of residential buildings without impacting occupantsâ\u20AC™ comfort has been highlighted as an important artificial intelligence (AI) challenge. Typically, approaches that seek to address this challenge use a model that captures the thermal dynamics within a building, also referred to as a thermal model. Among thermal models, gray-box models are a popular choice for modeling the thermal dynamics of buildings. They combine knowledge of the physical structure of a building with various data-driven inputs and are accurate estimators of the state (internal temperature). However, existing gray-box models require a detailed specification of all the physical elements that can affect the thermal dynamics of a building a priori. This limits their applicability, particularly in residential buildings, where additional dynamics can be induced by human activities such as cooking, which contributes additional heat, or opening of windows, which leads to additional leakage of heat. Since the incidence of these additional dynamics is rarely known, their combined effects cannot readily be accommodated within existing models. To overcome this limitation and improve the general applicability of gray-box models, we introduce a novel model, which we refer to as a latent force thermal model of the thermal dynamics of a building, or LFM-TM. Our model is derived from an existing gray-box thermal model, which is augmented with an extra term referred to as the learned residual. This term is capable of modeling the effect of any a priori unknown additional dynamic, which, if not captured, appears as a structure in a thermal modelâ\u20AC™s residual (the error induced by the model). More importantly, the learned residual can also capture the effects of physical elements such as a buildingâ\u20AC™s envelope or the lags in a heating system, leading to a significant reduction in complexity compared to existing models. To evaluate the performance of LFM-TM, we apply it to two independent data sources. The first is an established dataset, referred to as the FlexHouse data, which was previously used for evaluating the efficacy of existing gray-box models [Bacher and Madsen 2011]. The second dataset consists of heating data logged within homes located on the University of Southampton campus, which were specifically instrumented to collect data for our thermal modeling experiments. On both datasets, we show that LFM-TM outperforms existing models in its ability to accurately fit the observed data, generate accurate day-ahead internal temperature predictions, and explain a large amount of the variability in the future observations. This, along with the fact that we also use a corresponding efficient sequential inference scheme for LFM-TM, makes it an ideal candidate for model-based predictive control, where having accurate online predictions of internal temperatures is essential for high-quality solutions."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7605","fieldValue":"HVAC"}