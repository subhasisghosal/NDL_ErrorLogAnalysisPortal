{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/16143","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/16144","fieldValue":"Baranoski, Gladimir V G"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/16144","fieldValue":" We introduce a physiologically-based model for pupil light reflex (PLR) and an image-based model for iridal pattern deformation. Our PLR model expresses the pupil diameter as a function of the lighting of the environment, and is described by a delay-differential equation, naturally adapting the pupil diameter even to abrupt changes in light conditions. Since the parameters of our PLR model were derived from measured data, it correctly simulates the actual behavior of the human pupil. Another contribution of our work is a model for realistic deformation of the iris pattern as a function of pupil dilation and constriction. Our models produce high-fidelity appearance effects and can be used to produce real-time predictive animations of the pupil and iris under variable lighting conditions. We assess the predictability and quality of our simulations through comparisons of modeled results against measured data derived from experiments also described in this work. Combined, our models can bring facial animation to new photorealistic standards."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/16144","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/16144","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/16145","fieldValue":"Cohen-Or, Daniel"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/16145","fieldValue":" Many inhomogeneous real-world textures are non-stationary and exhibit various large scale patterns that are easily perceived by a human observer. Such textures violate the assumptions underlying most state-of-the-art example-based synthesis methods. Consequently, they cannot be properly reproduced by these methods, unless a suitable control map is provided to guide the synthesis process. Such control maps are typically either user specified or generated by a simulation. In this paper, we present an alternative: a method for automatic example-based generation of control maps, geared at synthesis of natural, highly inhomogeneous textures, such as those resulting from natural aging or weathering processes. Our method is based on the observation that an appropriate control map for many of these textures may be modeled as a superposition of several layers, where the visible parts of each layer are occupied by a more homogeneous texture. Thus, given a decomposition of a texture exemplar into a small number of such layers, we employ a novel example-based shape synthesis algorithm to automatically generate a new set of layers. Our shape synthesis algorithm is designed to preserve both local and global characteristics of the exemplar's layer map. This process results in a new control map, which then may be used to guide the subsequent texture synthesis process."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/16145","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/16145","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/16146","fieldValue":"Cohen-Or, Daniel"}