{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25499","fieldValue":"Tang, Lin-Xie"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25499","fieldValue":"Hua, Xian-Sheng"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25499","fieldValue":" The ever increasing volume of video content on the Web has created profound challenges for developing efficient indexing and search techniques to manage video data. Conventional techniques such as video compression and summarization strive for the two commonly conflicting goals of low storage and high visual and semantic fidelity. With the goal of balancing both video compression and summarization, this article presents a novel approach, called Near-Lossless Semantic Summarization (NLSS), to summarize a video stream with the least high-level semantic information loss by using an extremely small piece of metadata. The summary consists of compressed image and audio streams, as well as the metadata for temporal structure and motion information. Although at a very low compression rate (around &frac140; of H.264 baseline, where traditional compression techniques can hardly preserve an acceptable visual fidelity), the proposed NLSS still can be applied to many video-oriented tasks, such as visualization, indexing and browsing, duplicate detection, concept detection, and so on. We evaluate the NLSS on TRECVID and other video collections, and demonstrate that it is a powerful tool for significantly reducing storage consumption, while keeping high-level semantic fidelity."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25499","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25499","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25500","fieldValue":" Enhancing multimedia applications with olfactory sensations is one of the last challenges in the area. While there is evidence, both scientific and anecdotal, that olfactory cues help users in information recall tasks, there is a lack of work when the targeted information is one contained in a multimedia presentation, which is precisely the focus of this article. Accordingly, we present the results of two experimental studies. The first study measured the impact of olfactory media variation on the user's ability to perceive, synthesize, and analyze the informational content of olfactory-enhanced multimedia videos; the second study measured the impact of information content, and an information recall task in respect of user perception of the relevance, sense of reality, and acceptability of the olfactory media content, as well as the overall enjoyment of the experience. Results show that the use of olfactory media content, both pleasant and unpleasant, in multimedia displays does not significantly impact on information assimilation in a negative way. Moreover, the addition of a performance task may enhance the user's understanding of the correlation between the characteristic odor(s) and the scenario under consideration, as well as enable users to consciously learn the odors."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25500","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25500","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25501","fieldValue":"Yeh, Lo-Yao"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/25501","fieldValue":"Huang, Jiun-Long"}