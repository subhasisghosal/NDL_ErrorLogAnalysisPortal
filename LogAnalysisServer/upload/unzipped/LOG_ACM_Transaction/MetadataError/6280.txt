{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6719","fieldValue":" To ensure thermal safety and to avoid performance degradation from temperature regulation in 3D NoC, we propose a new temperature-traffic control framework. The framework contains the vertical throttling-based runtime thermal management (VT-RTM) scheme and the transport-layer assisted routing (TLAR) scheme. VT-RTM scheme increases the cooling speed and maintains high availability. TLAR scheme sustains the throughput of the nonstationary irregular mesh network. In our experiments, VT-RTM scheme reduces cooling time by 84&percnt; and achieves 98&percnt; network availability; the overall performance impact is around 8&percnt; of traditional schemes. TLAR scheme reduces average latency by 35âˆ¼&percnt; and improves sustainable throughput by 76&percnt;"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6719","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6719","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6720","fieldValue":" Many multicore computers are single-user devices, creating the potential to partition by situational usage contexts, similar to how the human brain is organized. Contextual partitioning (CP) permits multiple simplified versions of the same task to exist in parallel, with selection tied to the context in use. We introduce CP for speech recognition, specifically targeted at user interfaces in handheld embedded devices. Contexts are drawn from webpage interactions. CP results in 61&percnt; fewer decoding errors, 97&percnt; less training for vocabulary changes, near-linear scaling potential with increasing core counts, and up to a potential 90&percnt; reduction in power usage."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6720","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6720","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/6721","fieldValue":"Gaudiot, Jean-Luc"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6721","fieldValue":" Network coding is a well-known technique used to enhance network throughput and reliability by applying special coding to data packets. One critical problem in practice, when using the random linear network coding technique, is the high computational overhead. More specifically, using this technique in embedded systems with low computational power might cause serious delays due to the complex Galois field operations and matrix handling. To this end, this article proposes a high-performance decoding logic for random linear network coding using field-programmable gate-array (FPGA) technology. We expect that the inherent reconfigurability of FPGAs will provide sufficient performance as well as programmability to cope with changes in the specification of the coding. The main design motivation was to improve the decoding delay by dividing and parallelizing the entire decoding process. Fast arithmetic operations are achieved by the proposed parallelized GF ALUs, which allow calculations with all the elements of a single row of a matrix to be performed concurrently. To improve the flexibility in the utilization of the FPGA components, two different decoding methods have been designed and compared. The performance of the proposed idea is evaluated by comparing with the performance of the decoding process executed by general-purpose processors through an equivalent software algorithm. Overall, a maximum throughput of 65.98 Mbps is achieved with the proposed FPGA design on an XC5VLX110T Virtex 5 device. In addition, the proposed design provides speedups of up to 13.84 compared to an aggressively parallelized software decoding algorithm run on a quad-core AMD processor. Moreover, the design affords 12 times higher power efficiency in terms of throughput per watt than an ARM Coretex-A9 processor."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6721","fieldValue":"FPGA"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6721","fieldValue":"ACM"}