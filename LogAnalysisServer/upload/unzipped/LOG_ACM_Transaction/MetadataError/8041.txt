{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10899","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10900","fieldValue":" We investigate cascades in networks consisting of strategic agents with interdependent security. We assume that the strategic agents have choices between i) investing in protecting themselves, ii) purchasing insurance to transfer (some) risks, and iii) taking no actions. Using a population game model, we study how various system parameters, such as node degrees, infection propagation rate, and the probability with which infected nodes transmit infection to neighbors, affect nodes' choices at Nash equilibria and the resultant price of anarchy\/stability. In addition, we examine how the probability that a single infected node can spread the infection to a significant portion of the entire network, called cascade probability, behaves with respect to system parameters. In particular, we demonstrate that, at least for some parameter regimes, the cascade probability increases with the average degree of nodes."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10900","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10900","fieldValue":"{\"doi\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/10900","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10900","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1134","fieldValue":" Self-organized multi-agent systems (MAS) are still difficult to engineer, because, to deal with real world problems, a self-organized MAS should exhibit complex adaptive organizations. In this respect the holonic paradigm provides a solution for modelling complex organizational structures. Holons are defined as self-similar entities that are neither parts nor wholes. The organizational structure produced by holons is called a holarchy. A holonic MAS (HMAS) considers agents as holons that are grouped according to holarchies. The goal of this article is to introduce an architecture that allows holons to adapt to their environment. The metaphor is based upon the immune system and considers stimulations\/requests as antigens and selected antibodies as reactions\/answers. Each antibody is activated by specific antigens and stimulated and\/or inhibited by other antibodies. The immune system rewards (respectively penalizes) selected antibodies, which constitutes a good (respectively wrong) answer to a request. This mechanism allows an agent to choose from a set of possible behaviors, the one that seems the best fit for a specific context. In this context, each holon, atomic or composed, encapsulates an immune system in order to select a behavior. For composed holons, each sub-holon is represented by the selected antibody of its immune system. The super-holon's immune system therefore contains one antibody per sub-holon. This recursive architecture corresponds with the recursive nature of the holarchy. This architecture is presented with an example of simulated robot soccer. From experiments under different conditions we show that this architecture has interesting properties."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1134","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1134","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1996","fieldValue":" Modern mainstream powerful computers adopt multisocket multicore CPU architecture and NUMA-based memory architecture. While traditional work-stealing schedulers are designed for single-socket architectures, they incur severe shared cache misses and remote memory accesses in these computers. To solve the problem, we propose a locality-aware work-stealing (LAWS) scheduler, which better utilizes both the shared cache and the memory system. In LAWS, a load-balanced task allocator is used to evenly split and store the dataset of a program to all the memory nodes and allocate a task to the socket where the local memory node stores its data for reducing remote memory accesses. Then, an adaptive DAG packer adopts an auto-tuning approach to optimally pack an execution DAG into cache-friendly subtrees. After cache-friendly subtrees are created, every socket executes cache-friendly subtrees sequentially for optimizing shared cache usage. Meanwhile, a triple-level work-stealing scheduler is applied to schedule the subtrees and the tasks in each subtree. Through theoretical analysis, we show that LAWS has comparable time and space bounds compared with traditional work-stealing schedulers. Experimental results show that LAWS can improve the performance of memory-bound programs up to 54.2&percnt; on AMD-based experimental platforms and up to 48.6&percnt; on Intel-based experimental platforms compared with traditional work-stealing schedulers."}