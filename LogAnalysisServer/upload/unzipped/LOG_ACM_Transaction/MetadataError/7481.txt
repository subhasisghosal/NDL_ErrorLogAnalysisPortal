{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/9770","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/9770","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/9771","fieldValue":" We consider a TCP\/AQM system with large link capacity (NC) shared by many flows. The traditional rule-of-thumb suggests that the buffer size be chosen in proportion to the number of flows (N) for full link utilization, while recent research outcomes show that O(√N) buffer sizing is sufficient for high utilization and O(1) buffer sizing makes the system stable at the cost of reduced link utilization. In this paper, we consider a system where the Active Queue Management (AQM) is scaled as $O(N^α) with a buffer of size O(Nβ$) (0 < α < β < 0.5). By capturing randomness both in packet arrivals and in packet markings, we develop a doubly-stochastic model for a TCP\/AQM system with many flows. We prove that, under such a scale, the system always performs well in the sense that the link utilization goes to 100% and the loss ratio decreases to zero as the system size N increases. Our results assert that the system enjoys benefit of largeness with no tradeoff between full link utilization, zero packet loss, and small buffer size, at least asymptotically. This is in stark contrast to existing results showing that there always exists a tradeoff between full link utilization and the required buffer size. Extensive ns-2 simulation results under various configurations also confirm our theoretical findings. Our study illustrates that blind application of fluid modeling may result in strange results and exemplifies the importance of choosing a right modeling approach for different scaling regimes."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/9771","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/9771","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/9771","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/9772","fieldValue":" This paper presents a methodology for protecting low-priority best-effort (BE) traffic in a network domain that provides both virtual-circuit routing with bandwidth reservation for QoS traffic and datagram routing for BE traffic. When a QoS virtual circuit is established, bandwidths amounting to the traffic's effective bandwidths are reserved along the links. We formulate a new QoS-virtual-circuit admission control and routing policy that sustains a minimum level of BE performance. In response to a QoS connection request, the policy executes a two-stage optimization. The first stage seeks a minimum-net-effective-bandwidth reservation path that satisfies a BE protecting constraint; the second stage is a tie-breaking rule, selecting from tied paths one that least disturbs BE traffic. Our novel policy implementation efficiently executes both optimization stages simultaneously by a single run of Dijkstra's algorithm. According to simulation results, within a practical operating range, the consideration that our proposed policy gives to the BE service does not increase the blocking probability of a QoS connection request."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/9772","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/9772","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/9772","fieldValue":"ACM"}