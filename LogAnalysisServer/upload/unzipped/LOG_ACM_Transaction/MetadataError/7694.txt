{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10198","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1927","fieldValue":" Because of tight power and energy constraints, industry is progressively shifting toward heterogeneous system-on-chip (SoC) architectures composed of a mix of general-purpose cores along with a number of accelerators. However, such SoC architectures can be very challenging to efficiently program for the vast majority of programmers, due to numerous programming approaches and languages. Libraries, on the other hand, provide a simple way to let programmers take advantage of complex architectures, which does not require programmers to acquire new accelerator-specific or domain-specific languages. Increasingly, library-based, also called algorithm-centric, programming approaches propose to generalize the usage of libraries and to compose programs around these libraries, instead of using libraries as mere complements. In this article, we present a software framework for achieving performance portability by leveraging a generalized library-based approach. Inspired by the notion of a component, as employed in software engineering and HW\/SW codesign, we advocate nonexpert programmers to write simple wrapper code around existing libraries to provide simple but necessary semantic information to the runtime. To achieve performance portability, the runtime employs machine learning (simulated annealing) to select the most appropriate accelerator and its parameters for a given algorithm. This selection factors in the possibly complex composition of algorithms used in the application, the communication among the various accelerators, and the tradeoff between different objectives (i.e., accuracy, performance, and energy). Using a set of benchmarks run on a real heterogeneous SoC composed of a multicore processor and a GPU, we show that the runtime overhead is fairly small at 5.1&percnt; for the GPU and 6.4&percnt; for the multi-core. We then apply our accelerator selection approach to a simulated SoC platform containing multiple inexact accelerators. We show that accelerator selection together with hardware parameter tuning achieves an average 46.2&percnt; energy reduction and a speedup of 2.1Ã\u2014 while meeting the desired application error target."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1927","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1927","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10199","fieldValue":" We investigate two quantities of interest in a delay-tolerant mobile ad hoc network: the network capacity region and the minimum energy function. The network capacity region is defined as the set of all input rates that the network can stably support considering all possible scheduling and routing algorithms. Given any input rate vector in this region, the minimum energy function establishes the minimum time-average power required to support it. In this paper, we consider a cell-partitioned model of a delay-tolerant mobile ad hoc network with general Markovian mobility. This simple model incorporates the essential features of locality of wireless transmissions as well as node mobility and enables us to exactly compute the corresponding network capacity and minimum energy function. Furthermore, we propose simple schemes that offer performance guarantees that are arbitrarily close to these bounds at the cost of an increased delay."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10199","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/10199","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10199","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10200","fieldValue":" Outage probabilities in wireless networks depend on various factors: the node distribution, the MAC scheme, and the models for path loss, fading, and transmission success. In prior work on outage characterization for networks with randomly placed nodes, most of the emphasis was put on networks whose nodes are Poisson-distributed and where ALOHA is used as the MAC protocol. In this paper, we provide a general framework for the analysis of outage probabilities in the high-reliability regime. The outage probability characterization is based on two parameters: the intrinsic spatial contention of the network, introduced by Haenggi in a previous work, and the coordination level achieved by the MAC as measured by the interference scaling exponent introduced in this paper. We study outage probabilities under the signal-to-interference ratio (SIR) model, Rayleigh fading, and power-law path loss and explain how the two parameters depend on the network model. The main result is that the outage probability approaches $Î³Î·^Îº$ as the density of interferers Î· goes to zero, and that Îº assumes values in the range 1 â\u2030¤ Îº â\u2030¤ Î±\/2 for all practical MAC protocols, where Î± is the path-loss exponent. This asymptotic expression is valid for all motion-invariant point processes. We suggest a novel and complete taxonomy of MAC protocols based mainly on the value of Îº. Finally, our findings suggest a conjecture that bounds the outage probability for all interferer densities."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10200","fieldValue":"{\"eissn\":\"\"}"}