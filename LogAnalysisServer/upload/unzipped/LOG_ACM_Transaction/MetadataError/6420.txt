{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7062","fieldValue":" This article addresses the problem of parallelizing model block diagrams for real-time embedded applications on multicore architectures. We describe a Mixed Integer Linear Programming formulation for finding a feasible mapping of the blocks to different CPU cores. For single-rate models, we use an objective function that minimizes the overall worst-case execution time. We introduce a set of heuristics to solve the problem for large models in a reasonable time. For multirate models, we solve the feasibility problem for finding a valid mapping. We study the scalability and efficiency of our approach with synthetic benchmarks and an engine controller from Toyota."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7062","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7062","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7063","fieldValue":" Optical networks-on-chip (NoCs) provide a promising answer to address the increasing requirements of ultra-high bandwidth and extremely low power consumption. Designing a photonic interconnect, however, involves a number of challenges that have no equivalent in the electronic domain, particularly the crosstalk noise, which affects the signal-to-noise ratio (SNR) possibly resulting in an inoperable architecture and hence constraining the network scalability. In this article, we point out the implications of application-driven task mapping on crosstalk effects. We motivate the main rationale of our work and provide a formalization of the problem. Then we propose a class of algorithms that automatically map the application tasks onto a generic mesh-based photonic NoC architecture such that the worst-case crosstalk is minimized. We also present a purpose-built experimental setup used for evaluating several architectural solutions in terms of crosstalk noise and SNR. The setup is used to collect extensive results from several real-world applications and case studies. The collected results show that the crosstalk noise can be significantly reduced by adopting our approach, thereby allowing higher network scalability, and can exhibit encouraging improvements over application-oblivious architectures."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7063","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7063","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/7064","fieldValue":" Graphics processing units (GPUs) are increasingly used for high-performance computing. Programming frameworks for general-purpose computing on GPUs (GPGPU), such as CUDA and OpenCL, are also maturing. Driving this trend is the recent proliferation of mobile devices such as smartphones and wearable computers. These devices are increasingly incorporating computationally intensive applications that involve some form of environmental recognition such as augmented reality (AR) or voice recognition. However, devices with low computational power cannot satisfy such demanding computing requirements. The CPU load of these devices could be reduced by offloading computation onto GPUs on the cloud. This paper presents GPUrpc, a remote procedure call (RPC) extension to Gdev, which is a rich set of runtime libraries and device drivers for achieving first-class GPU resource management. GPUrpc allows developers to use CUDA for GPGPU development work. Existing research uses RPCs based on the CUDA application programming interfaces (APIs); hence, all CUDA APIs require communication. To reduce communication overhead, we use an RPC based on a low-level API than CUDA API and reduced API that does not require communication. Our evaluation conducted on Linux and NVIDIA GPUs shows that the basic performance of our prototype implementation is reliable in comparison with the existing method. Evaluation using the Rodinia benchmark suite designed for research in heterogeneous parallel computing showed that GPUrpc is effective for applications such as image processing and data mining. GPUrpc also can improve power consumption to approximately 1\/6 that of CPU processing for performing 512 Ã\u2014 512 matrix multiplication."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7064","fieldValue":"GPU"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/7064","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/7064","fieldValue":"ACM"}