{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/23308","fieldValue":"Lim, Ee-Peng"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/23308","fieldValue":" In e-commerce environments, the trustworthiness of a seller is utterly important to potential buyers, especially when a seller is not known to them. Most existing trust evaluation models compute a single value to reflect the general trustworthiness of a seller without taking any transaction context information into account. With such a result as the indication of reputation, a buyer may be easily deceived by a malicious seller in a transaction where the notorious value imbalance problem is involvedâ\u20AC\u201Din other words, a malicious seller accumulates a high-level reputation by selling cheap products and then deceives buyers by inducing them to purchase more expensive products. In this article, we first present a trust vector consisting of three values for contextual transaction trust (CTT). In the computation of CTT values, three identified important context dimensions, including Product Category, Transaction Amount, and Transaction Time, are taken into account. In the meantime, the computation of each CTT value is based on both past transactions and the forthcoming transaction. In particular, with different parameters specified by a buyer regarding context dimensions, different sets of CTT values can be calculated. As a result, all of these trust values can outline the reputation profile of a seller that indicates the dynamic trustworthiness of a seller in different products, product categories, price ranges, time periods, and any necessary combination of them. We name this new model ReputationPro. Nevertheless, in ReputationPro, the computation of reputation profile requires new data structures for appropriately indexing the precomputation of aggregates over large-scale ratings and transaction data in three context dimensions, as well as novel algorithms for promptly answering buyersâ\u20AC™ CTT queries. In addition, storing precomputed aggregation results consumes a large volume of space, particularly for a system with millions of sellers. Therefore, reducing storage space for aggregation results is also a great demand. To solve these challenging problems, we first propose a new index scheme CMK-tree by extending the two-dimensional K-D-B-tree that indexes spatial data to support efficient computation of CTT values. Then, we further extend the CMK-tree and propose a $CMK-tree^RS approach to reducing the storage space allocated to each seller. The two approaches are not only applicable to three context dimensions that are either linear or hierarchical but also take into account the characteristics of the transaction-time modelâ\u20AC\u201Dthat is, transaction data is inserted in chronological order. Moreover, the proposed data structures can index each specific product traded in a time period to compute the trustworthiness of a seller in selling a product. Finally, the experimental results illustrate that the CMK-tree is superior in efficiency of computing CTT values to all three existing approaches in the literature. In particular, while answering a buyerâ\u20AC™s CTT queries for each brand-based product category, the CMK-tree has almost linear query performance. In addition, with significantly reduced storage space, the CMK-treeRS$ approach can further improve the efficiency in computing CTT values. Therefore, our proposed ReputationPro model is scalable to large-scale e-commerce Web sites in terms of efficiency and storage space consumption."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/23308","fieldValue":"ReputationPro: The Efficient Approaches to Contextual Transaction Trust Computation in E-Commerce Environments"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/23308","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/23308","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/23309","fieldValue":" Learning to rank has become increasingly important for many information retrieval applications. To reduce the labeling cost at training data preparation, many active sampling algorithms have been proposed. In this article, we propose a novel active learning-for-ranking strategy called ranking-based sensitivity sampling (RSS), which is tailored for Gradient Boosting Decision Tree (GBDT), a machine-learned ranking method widely used in practice by major commercial search engines for ranking. We leverage the property of GBDT that samples close to the decision boundary tend to be sensitive to perturbations and design the active learning strategy accordingly. We further theoretically analyze the proposed strategy by exploring the connection between the sensitivity used for sample selection and model regularization to provide a potentially theoretical guarantee w.r.t. the generalization capability. Considering that the performance metrics of ranking overweight the top-ranked items, item rank is incorporated into the selection function. In addition, we generalize the proposed technique to several other base learners to show its potential applicability in a wide variety of applications. Substantial experimental results on both the benchmark dataset and a real-world dataset have demonstrated that our proposed active learning strategy is highly effective in selecting the most informative examples."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/23309","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/23309","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/23310","fieldValue":"Crete-Nishihata, Masashi"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/23310","fieldValue":" In this study, we take another look at 5 years of web censorship data gathered by the OpenNet Initiative in 77 countries using user-based testing with locally relevant content. Prior to our work, this data had been analyzed with little automation, focusing on what content had been blocked, rather than how blocking was carried out. In this study, we use more rigorous automation to obtain a longitudinal, global view of the technical means used for web censorship. We also identify blocking that had been missed in prior analyses. Our results point to considerable variability in the technologies used for web censorship, across countries, time, and types of content, and even across ISPs in the same country. In addition to characterizing web censorship in countries that, thus far, have eluded technical analysis, we also discuss the implications of our observations on the design of future network measurement platforms and circumvention technologies."}