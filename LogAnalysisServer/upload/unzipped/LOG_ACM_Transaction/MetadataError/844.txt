{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13456","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13456","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13457","fieldValue":" An enterprise service-level performance time series is a sequence of data points that quantify demand, throughput, average order-delivery time, quality of service, or end-to-end cost. Analytical and predictive models of such time series can be embedded into an enterprise information system (EIS) in order to provide meaningful insights into potential business problems and generate guidance for appropriate solutions. Time-series analysis includes periodicity detection, decomposition, and correlation analysis. Time-series prediction can be modeled as a regression problem to forecast a sequence of future time-series datapoints based on the given time series. The state-of-the-art (baseline) methods employed in time-series prediction generally apply advanced machine-learning algorithms. In this article, we propose a new univariate method for dealing with midterm time-series prediction. The proposed method first analyzes the hierarchical periodic structure in one time series and decomposes it into trend, season, and noise components. By discarding the noise component, the proposed method only focuses on predicting repetitive season and smoothed trend components. As a result, this method significantly improves upon the performance of baseline methods in midterm time-series prediction. Moreover, we propose a new multivariate method for dealing with short-term time-series prediction. The proposed method utilizes cross-correlation information derived from multiple time series. The amount of data taken from each time series for training the regression model is determined by results from hierarchical cross-correlation analysis. Such a data-filtering strategy leads to improved algorithm efficiency and prediction accuracy. By combining statistical methods with advanced machine-learning algorithms, we have achieved a significantly superior performance in both short-term and midterm time-series predictions compared to state-of-the-art (baseline) methods."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13457","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13457","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13458","fieldValue":" In recent years, dynamic program analysis (DPA) has been widely used in various fields such as profiling, finding bugs, and security. However, existing solutions have their own weaknesses. Software solutions provide flexibility in DPA but they suffer from tremendous performance overhead. In contrast, core-level hardware engines rely on specialized integrated logics and attain extremely fast computation, but they have a limited functional extensibility because the logics are tightly coupled with the host processor. To mend this, a prior system-level approach utilizes an existing channel to integrate their hardware without necessitating the host architecture modification and introduced great potential in performance. Nevertheless, the prior work does not address the detailed design and implementation of the engine, which is quite essential to leverage the deployment on real systems. To address this, in this article, we propose an implementation of programmable DPA hardware engine, called program analysis unit (PAU). PAU is an application-specific instruction-set processor (ASIP) whose instruction set is customized to reflect common features of various DPA methods. With the specialized architecture and programmability of software, our PAU aims at fast computation and sufficient flexibility. In our case studies on several DPA techniques, we show that our ASIP approach can be successfully applicable to complex DPA schemes while providing hardware-backed power in performance and software-based flexibility in analysis. Recent experiments on our FPGA prototype revealed that the performance of PAU is 4.7-13.6 times faster than pure software DPA, and the power\/area consumption is also acceptably small compared to today's mobile processors."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/13458","fieldValue":"Implementing an Application-Specific Instruction-Set Processor for System-Level Dynamic Program Analysis Engines"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13458","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13458","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13459","fieldValue":" Modern mobile processors integrating an increasing number of cores into one single chip demand large-capacity, on-chip, last-level caches (LLCs) in order to achieve scalable performance improvements. However, adopting traditional memory technologies such as SRAM and embedded DRAM (eDRAM) leakage and scalability problems. Spin-transfer torque magnetic RAM (STT-MRAM) is a novel nonvolatile memory technology that has emerged as a promising alternative for constructing on-chip caches in high-end mobile processors. STT-MRAM has many advantages, such as short read latency, zero leakage from the memory cell, and better scalability than eDRAM and SRAM. Multilevel cell (MLC) STT-MRAM further enlarges capacity and reduces per-bit cost by storing more bits in one cell. However, MLC STT-MRAM has long write latency which limits the effectiveness of MLC STT-MRAM-based LLCs. In this article, we address this limitation with three novel designs: line pairing (LP), line swapping (LS), and dynamic LP\/LS enabler (DLE). LP forms fast cache lines by reorganizing MLC soft bits which are faster to write. LS dynamically stores frequently-written data into these fast cache lines. We then propose a dynamic LP\/LS enabler (DLE) to enable LP and LS only if they help to improve the overall cache performance. Our experimental results show that the proposed designs improve system performance by 9--15&percnt; and reduce energy consumption by 14--21&percnt; for various types of mobile processors."}