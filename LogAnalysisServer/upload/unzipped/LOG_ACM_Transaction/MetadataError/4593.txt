{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24872","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24873","fieldValue":" We present a model for representing stationary multivariate time-series input processes with marginal distributions from the Johnson translation system and an autocorrelation structure specified through some finite lag. We then describe how to generate data accurately to drive computer simulations. The central idea is to transform a Gaussian vector autoregressive process into the desired multivariate time-series input process that we presume as having a VARTA (Vector-Autoregressive-To-Anything) distribution. We manipulate the autocorrelation structure of the Gaussian vector autoregressive process so that we achieve the desired autocorrelation structure for the simulation input process. We call this the correlation-matching problem and solve it by an algorithm that incorporates a numerical-search procedure and a numerical-integration technique. An illustrative example is included."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/24873","fieldValue":"Modeling and generating multivariate time-series input processes using a vector autoregressive technique"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24873","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24873","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3405","fieldValue":" Natural body movements arise in the form of temporal sequences of individual actions. During visual action analysis, the human visual system must accomplish a temporal segmentation of the action stream into individual actions. Such temporal segmentation is also essential to build hierarchical models for action synthesis in computer animation. Ideally, such segmentations should be computed automatically in an unsupervised manner. We present an unsupervised segmentation algorithm that is based on Bayesian Binning (BB) and compare it to human segmentations derived from psychophysical data. BB has the advantage that the observation model can be easily exchanged. Moreover, being an exact Bayesian method, BB allows for the automatic determination of the number and positions of segmentation points. We applied this method to motion capture sequences from martial arts and compared the results to segmentations provided by humans from movies that showed characters that were animated with the motion capture data. Human segmentation was then assessed by an interactive adjustment paradigm, where participants had to indicate segmentation points by selection of the relevant frames. Results show a good agreement between automatically generated segmentations and human performance when the trajectory segments between the transition points were modeled by polynomials of at least third order. This result is consistent with theories about differential invariants of human movements."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3405","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3405","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/24874","fieldValue":"Lee, Shing-Hoi"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24874","fieldValue":" We examine different ways of numerically computing the distribution function of conditional expectations where the conditioning element takes values in a finite or countably infinite outcome space. Both the conditional expectation and the distribution function itself are computed via Monte Carlo simulation. Given a limited (and fixed) computer budget, the quality of the estimator is gauged by the inverse of its mean square error. It is a function of the fraction of the budget allocated to estimating the conditional expectation versus the amount of sampling done relative to the \"conditioning variable.\" We will present the asymptotically optimal rates of convergence for different estimators and resolve the trade-off between the bias and variance of the estimators. Moreover, central limit theorems are established for some of the estimators proposed. We will also provide algorithms for the practical implementation of two of the estimators and illustrate how confidence intervals can be formed in each case. Major potential application areas include calculation of Value at Risk (VaR) in the field of mathematical finance and Bayesian performance analysis."}