{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24884","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24885","fieldValue":" This article was motivated by the need to speed up complex network simulation, especially in telecommunications settings, where high bandwidth translates into exorbitant numbers of packets that take inordinate CPU time to simulate. Since the simulation complexity of fluid workload is invariant under bandwidth scaling, flows of discrete units of workload may be replaced by (approximate) fluid streams for savings in CPU time and memory storage.To this end, the article outlines the design of a new hybrid Java simulator, called HNS (Hybrid Network Simulator). HNS simulates the movement of workload in a queueing network, where transactions may be of two types: traditional discrete transactions (e.g., packets) and continuous (fluid) transactions, all of which arrive discretely at the network in traffic flows, and each discrete arrival carries a workload. Arriving transactions only differ in the way their workloads are transported: the user specifies whether the workload should be packetized or fluidized, respectively, for transport across the network. The novel feature of HNS is that it admits models with both discrete and continuous traffic flows, and collects detailed statistics for both, including arrival, loss, buffer contents, departure, and delay statistics. HNS facilitates the fundamental tradeoff between the modeling accuracy of discrete flows and savings in simulation time and storage often afforded by continuous flows by providing a common testbed for both discrete and continuous flows, where the user can readily select transport modes and achieve a good deal of variance reduction in assessing the accuracy and speeds of model versions with different mixtures of flow types. We caution, however, that while HNS is a generic hybrid simulator of discrete and continuous flows, mixed models should be handled with care, since they tend to counteract the advantages of pure-packet or pure-fluid models.In order to achieve a high degree of speedup for fluid-flow models, HNS introduces and utilizes the so-called streamlining methodology to identify and modify algorithms that cause \"turbulent\" fluid flow (namely, scenarios where fluid-flow rates have a large number of minor fluctuations, which are computationally expensive but have a minor impact on simulation statistics). Streamlining removes these fluctuations so as to speed up the simulation at a moderate loss of statistical accuracy. HNS can be extended by writing additional Java classes; in particular, stream behavior can be modified by extending built-in protocol classes. For example, HNS already has dual implementations (packet and fluid) of various telecommunications-specific protocols, such as ATM (Asynchronous Transfer Mode), User Datagram Protocol (UDP), and TCP (Transport Control Protocol), the latter with a streamlined fluid protocol approximation.In this article, we describe the architecture of HNS and its operational features, including traffic injection at network sources, generic workload transport, some telecommunications-specific protocols, and statistics collection and display via a graphic user interface (GUI). We then use HNS to validate the streamlining methodology and to study appropriate tradeoffs of simulation speed and accuracy in telecommunications networks by comparing pure-packet, pure-fluid, and mixed versions of the same network model."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24885","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24885","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24886","fieldValue":" It is often not feasible to simulate high-speed networks at the packet level. One common technique for simulation speedup is to model traffic at coarser timescales, which we refer to as the abstract simulation. In this article, we analyze the sources for the accuracy degradation in abstract simulation. Specifically, we consider burst level modeling of active-idle sources and study a queue fed by such sources. The arrival rates vary during active periods. The burst level model assumes constant rates during each active period. Therefore, it can not track queue-length variations within an active period, which leads to the queue-length evaluation error. We study two scenarios. In the first scenario, the queue is always busy whenever the source is on. During each active period, the evolution of the queue length can be viewed as an integration process of the arrival rate. In this case, the error in the mean queue length shows nice properties. It is only determined by the traffic characteristics and does not change with the utilization. In the multiple-flow case, the error is the sum of the errors caused by abstraction on individual flows. We also show that the error does not propagate for tree-like networks or networks with probabilistic routing. In the first scenario, under very general conditions, burst level modeling does not cause significant underevaluation of the queue length. In the second scenario, the queue may empty during on periods of the source. We call these empty periods E intervals. We quantify the error in the mean queue length, which depends on the numbers, lengths, and positions of the E intervals. The burst level model significantly underevaluates the queue length if such intervals occur often. High utilizations, strong traffic burstiness at the active-idle level, and small arrival granularity tend to reduce such occurrences and the error in the mean queue length. This explains why these conditions favor traffic modeling at coarser timescales. Our findings are not limited to the specific traffic sources and the time-abstraction techniques. Instead, they shed light on the conditions needed for abstract models to deliver evaluation fidelity in a general context."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24886","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24886","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24887","fieldValue":" In this article we present a scalable model of a network of Active Queue Management (AQM) routers serving a large population of Transport Control Protocol (TCP) flows. We present efficient solution techniques that allow one to obtain the transient behavior of the average queue lengths and packet loss\/mark probabilities of AQM routers, and average end-to-end throughput and latencies of TCP users. We model different versions of TCP as well as different implementations of RED Random Early Detection (RED), the most popular AQM scheme currently in use. Comparisons between the models and ns simulation show our models to be quite accurate while at the same time requiring substantially less time to solve than packet level simulations, especially when workloads and bandwidths are high."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24887","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24887","fieldValue":"ACM"}