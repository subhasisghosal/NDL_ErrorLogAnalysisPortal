{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/2836","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/18986","fieldValue":" In this article we discuss a small modification of the bisection routines in EISPACK and LAPACK for finding a few of the eigenvalues of a symmetric tridiagonal matrix A. When the principal minors of the matrix A yield good approximations to the desired eigenvalues, these modifications can yield about 30% reduction in the computation times."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/18986","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/18986","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/18987","fieldValue":" Many computationally intensive problems in engineering and science give rise to the solution of large, sparse, linear systems of equations. Fast and efficient methods for their soltion are very important because these systems usually occur in the innermost loop of the computational scheme. Parallelization is often necessary to achieve an acceptable level of performance. This paper presents the design, implementation, and interface of a library of Basic Linear Algebra Subroutines for sparse matrices (PSBLAS) which is specifically tailored to distributed-memory computers. PSBLAS enables easy, efficient, and portable implementations of parallel iterative solvers for linear systems. The interface keeps in view a Single Program Multiple Data programming model on distributed-memory machines. However, the architecture of the library does not exclude an implementation in different paradigms, such as those based on the shared-memory model."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/18987","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/18987","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/18988","fieldValue":" In this paper we explain some of the changes that have been incorporated in the latest version of the LAPACK subroutine for reducing a symmetric banded matrix to tridiagonal form. These modifications improve the performance for larger-bandwidth problems and reduce the number of operations when accumulating the transformations onto the identity matrix, by taking advantage of the structure of the initial matrix. We show that similar modifications can be made to the LAPACK subroutines for reducing a symmetric positive definite generalized eigenvalue problem to a standard symmetric banded eigenvalue problem and for reducing a general banded matrix to bidiagonal form to facilitate the computation of the singular values of the matrix."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/18988","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/18988","fieldValue":"ACM"}