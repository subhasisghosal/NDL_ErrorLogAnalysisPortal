{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17260","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/2633","fieldValue":" In parameterized complexity, each problem instance comes with a parameter k, and a parameterized problem is said to admit a polynomial kernel if there are polynomial time preprocessing rules that reduce the input instance to an instance with size polynomial in k. Many problems have been shown to admit polynomial kernels, but it is only recently that a framework for showing the nonexistence of polynomial kernels for specific problems has been developed by Bodlaender et al. [2009] and Fortnow and Santhanam [2008]. With few exceptions, all known kernelization lower bounds results have been obtained by directly applying this framework. In this article, we show how to combine these results with combinatorial reductions that use colors and IDs in order to prove kernelization lower bounds for a variety of basic problems. To follow we give a summary of our main results. All results are under the assumption that the polynomial hierarchy does not collapse to the third level. â\u20AC\u201DWe show that the Steiner Tree problem parameterized by the number of terminals and solution size k, and the Connected Vertex Cover and Capacitated Vertex Cover problems do not admit a polynomial kernel. The two latter results are surprising because the closely related Vertex Cover problem admits a kernel with at most 2k vertices. â\u20AC\u201DAlon and Gutner [2008] obtain a $k^poly(h) kernel for Dominating Set in H-Minor Free Graphs parameterized by h &equals; &verbar;H&verbar; and solution size k, and ask whether kernels of smaller size exist. We partially resolve this question by showing that Dominating Set in H-Minor Free Graphs does not admit a kernel with size polynomial in k &plus; h. â\u20AC\u201DHarnik and Naor [2007] obtain a â\u20ACœcompression algorithmâ\u20AC? for the Sparse Subset Sum problem. We show that their algorithm is essentially optimal by showing that the instances cannot be compressed further. â\u20AC\u201DThe Hitting Set and Set Cover problems are among the most-studied problems in algorithmics. Both problems admit a kernel of size kO(d)$ when parameterized by solution size k and maximum set size d. We show that neither of them, along with the Unique Coverage and Bounded Rank Disjoint Sets problems, admits a polynomial kernel. The existence of polynomial kernels for several of the problems mentioned previously was an open problem explicitly stated in the literature [Alon and Gutner 2008; Betzler 2006; Guo and Niedermeier 2007; Guo et al. 2007; Moser et al. 2007]. Many of our results also rule out the existence of compression algorithms, a notion similar to kernelization defined by Harnik and Naor [2007], for the problems in question."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/2633","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/2633","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17261","fieldValue":" Photographs of hazy scenes typically suffer having low contrast and offer a limited visibility of the scene. This article describes a new method for single-image dehazing that relies on a generic regularity in natural images where pixels of small image patches typically exhibit a 1D distribution in RGB color space, known as color-lines. We derive a local formation model that explains the color-lines in the context of hazy scenes and use it for recovering the scene transmission based on the lines' offset from the origin. The lack of a dominant color-line inside a patch or its lack of consistency with the formation model allows us to identify and avoid false predictions. Thus, unlike existing approaches that follow their assumptions across the entire image, our algorithm validates its hypotheses and obtains more reliable estimates where possible. In addition, we describe a Markov random field model dedicated to producing complete and regularized transmission maps given noisy and scattered estimates. Unlike traditional field models that consist of local coupling, the new model is augmented with long-range connections between pixels of similar attributes. These connections allow our algorithm to properly resolve the transmission in isolated regions where nearby pixels do not offer relevant information. An extensive evaluation of our method over different types of images and its comparison to state-of-the-art methods over established benchmark images show a consistent improvement in the accuracy of the estimated scene transmission and recovered haze-free radiances."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17261","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17261","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17262","fieldValue":"Boissonnat, Jean-Daniel"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17262","fieldValue":"Shi, Kan-Le"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17262","fieldValue":" Anisotropic simplicial meshes are triangulations with elements elongated along prescribed directions. Anisotropic meshes have been shown well suited for interpolation of functions or solving PDEs. They can also significantly enhance the accuracy of a surface representation. Given a surface S endowed with a metric tensor field, we propose a new approach to generate an anisotropic mesh that approximates S with elements shaped according to the metric field. The algorithm relies on the well-established concepts of restricted Delaunay triangulation and Delaunay refinement and comes with theoretical guarantees. The star of each vertex in the output mesh is Delaunay for the metric attached to this vertex. Each facet has a good aspect ratio with respect to the metric specified at any of its vertices. The algorithm is easy to implement. It can mesh various types of surfaces like implicit surfaces, polyhedra, or isosurfaces in 3D images. It can handle complicated geometries and topologies, and very anisotropic metric fields."}