{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17139","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17140","fieldValue":" The same physical scene seen in bright sunlight and in dusky conditions does not appear identical to the human eye. Similarly, images shown on an 8000 $cd\/m^2 high-dynamic-range (HDR) display and in a 50 cd\/m2$ peak luminance cinema screen also differ significantly in their appearance. We propose a luminance retargeting method that alters the perceived contrast and colors of an image to match the appearance under different luminance levels. The method relies on psychophysical models of matching contrast, models of rod-contribution to vision, and our own measurements. The retargeting involves finding an optimal tone-curve, spatial contrast processing, and modeling of hue and saturation shifts. This lets us reliably simulate night vision in bright conditions, or compensate for a bright image shown on a darker display so that it reveals details and colors that would otherwise be invisible."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17140","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17140","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17141","fieldValue":"Shih, YiChang"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17141","fieldValue":" Headshot portraits are a popular subject in photography but to achieve a compelling visual style requires advanced skills that a casual photographer will not have. Further, algorithms that automate or assist the stylization of generic photographs do not perform well on headshots due to the feature-specific, local retouching that a professional photographer typically applies to generate such portraits. We introduce a technique to transfer the style of an example headshot photo onto a new one. This can allow one to easily reproduce the look of renowned artists. At the core of our approach is a new multiscale technique to robustly transfer the local statistics of an example portrait onto a new one. This technique matches properties such as the local contrast and the overall lighting direction while being tolerant to the unavoidable differences between the faces of two different people. Additionally, because artists sometimes produce entire headshot collections in a common style, we show how to automatically find a good example to use as a reference for a given portrait, enabling style transfer without the user having to search for a suitable example for each input. We demonstrate our approach on data taken in a controlled environment as well as on a large set of photos downloaded from the Internet. We show that we can successfully handle styles by a variety of different artists."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17141","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17141","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17142","fieldValue":"Laffont, Pierre-Yves"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17142","fieldValue":" We live in a dynamic visual world where the appearance of scenes changes dramatically from hour to hour or season to season. In this work we study \"transient scene attributes\" -- high level properties which affect scene appearance, such as \"snow\", \"autumn\", \"dusk\", \"fog\". We define 40 transient attributes and use crowdsourcing to annotate thousands of images from 101 webcams. We use this \"transient attribute database\" to train regressors that can predict the presence of attributes in novel images. We demonstrate a photo organization method based on predicted attributes. Finally we propose a high-level image editing method which allows a user to adjust the attributes of a scene, e.g. change a scene to be \"snowy\" or \"sunset\". To support attribute manipulation we introduce a novel appearance transfer technique which is simple and fast yet competitive with the state-of-the-art. We show that we can convincingly modify many transient attributes in outdoor scenes."}