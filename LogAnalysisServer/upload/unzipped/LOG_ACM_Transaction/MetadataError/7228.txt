{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/9273","fieldValue":" This paper focuses on the problem of dynamic survivable routing for segment shared protection (SSP) in mesh communication networks provisioning bandwidth guaranteed tunnels. With SSP, a connection is settled by concatenating a series of protection domains, each of which contains a working and protection segment pair behaving as a self-healing unit for performing local restoration whenever the working segment is subject to any unexpected interruption. We first discuss the advantages of using SSP--the ability to shorten the restoration time as well as achieve a higher throughput by saving spare capacity required for 100% restorability; then the survivable routing problem is formulated into an Integer Linear Programming (ILP), where the switching\/merging node pair of each protection domain along with the corresponding least-cost working and protection segment pair can be jointly determined for a dynamically arrived connection request. A novel approach of arc-reversal transformation is devised to deal with the situation that the working segments of two neighbor protection domains may overlap with each other by more than a single node. Due to a very high computation complexity induced in solving the ILP, a novel heuristic algorithm is proposed, named Cascaded Diverse Routing (CDR), to allocate protection domains for a connection request by performing diverse routing across a set of predefined candidate switching\/merging node pairs. Experiments are conducted on five two-connected network topologies to verify the ILP and the CDR algorithm. We first determine the best diameter of protection domains for the CDR scheme in each network topology. Using the results of best diameters, CDR is compared with two reported schemes, namely PROMISE and OPDA. We demonstrate in the simulation results that the path-shared protection schemes are outperformed by the SSP schemes in terms of blocking probability under all possible arrangements in the experiment and that CDR yields better performance than PROMISE and OPDA due to the extra efforts in manipulating the location of working segments at the expense of longer computation time."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/9273","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/9273","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/9273","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/9274","fieldValue":"Choi, Hyeong-Ah"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/9274","fieldValue":" Network survivability is a crucial requirement in high-speed optical networks. Typical approaches of providing survivability have considered the failure of a single component such as a link or a node. In this paper, we motivate the need for considering double-link failures and present three loopback methods for handling such failures. In the first two methods, two edge-disjoint backup paths are computed for each link for rerouting traffic when a pair of links fails. These methods require the identification of the failed links before recovery can be completed. The third method requires the precomputation of a single backup path and does not require link identification before recovery. An algorithm that precomputes backup paths for links in order to tolerate double-link failures is then presented. Numerical results comparing the performance of our algorithm with other approaches suggest that it is possible to achieve almost 100% recovery from double-link failures with a moderate increase in backup capacity. A remarkable feature of our approach is that it is possible to trade off capacity for restorability by choosing a subset of double-link failures and designing backup paths using our algorithm for only those failure scenarios."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/9274","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/9274","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/9274","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/9275","fieldValue":" Instability in packet-switching networks is normally associated with overload conditions, since queueing network models show that, in simple configurations, only overload generates instability. However, some results showing that instability can happen also in underloaded queueing networks began to appear about a decade ago. Underload instabilities can be produced by: 1) customer routes that visit the same queues several times; 2) variations of the customer service times at the different queues; and 3) complex scheduling algorithms. In this paper, we study, using fluid models and adversarial queueing theory, possible underload instabilities due to flow schedulers in packet networks, focusing on output queued switches with strict priority (SP) schedulers and Generalized Processor Sharing (GPS) schedulers. The considered scenarios always refer to acyclic packet routes and consider customer service times that vary only according to channel capacities, thus resembling the approaches being currently considered to provide QoS in the Internet. Our (in)stability results are rather surprising: SP schedulers appear to be more robust than GPS schedulers whenever exact information on the effective average packet flow rates is not available."}