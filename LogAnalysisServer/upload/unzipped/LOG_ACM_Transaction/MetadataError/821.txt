{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13407","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1155","fieldValue":" Connectivity, primarily a graph-theoretic concept, helps define the fault tolerance of wireless sensor networks (WSNs) in the sense that it enables the sensors to communicate with each other so their sensed data can reach the sink. On the other hand, sensing coverage, an intrinsic architectural feature of WSNs plays an important role in meeting application-specific requirements, for example, to reliably extract relevant data about a sensed field. Sensing coverage and network connectivity are not quite orthogonal concepts. In fact, it has been proven that connectivity strongly depends on coverage and hence considerable attention has been paid to establish tighter connection between them although only loose lower bound on network connectivity of WSNs is known. In this article, we investigate connectivity based on the degree of sensing coverage by studying k-covered WSNs, where every location in the field is simultaneously covered (or sensed) by at least k sensors (property known as k-coverage, where k is the degree of coverage). We observe that to derive network connectivity of k-covered WSNs, it is necessary to compute the sensor spatial density required to guarantee k-coverage. More precisely, we propose to use a model, called the Reuleaux Triangle, to characterize k-coverage with the help of Helly's Theorem and the analysis of the intersection of sensing disks of k sensors. Using a deterministic approach, we show that the sensor spatial density to guarantee k-coverage of a convex field is proportional to k and inversely proportional to the sensing range of the sensors. We also prove that network connectivity of k-covered WSNs is higher than their sensing coverage k. Furthermore, we propose a new measure of fault tolerance for k-covered WSNs, called conditional fault tolerance, based on the concepts of conditional connectivity and forbidden faulty sensor set that includes all the neighbors of a given sensor. We prove that k-covered WSNs can sustain a large number of sensor failures provided that the faulty sensor set does not include a forbidden faulty sensor set."}{"fieldName":"dc.subject","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/1155","fieldValue":"<i>k<\/i>-covered wireless sensor networks"}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_LOWER","handle":"12345678_acm\/1155","fieldValue":"<i>k<\/i>-covered wireless sensor networks"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1155","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1155","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/2278","fieldValue":" Skip graphs are a novel distributed data structure, based on skip lists, that provide the full functionality of a balanced tree in a distributed system where resources are stored in separate nodes that may fail at any time. They are designed for use in searching peer-to-peer systems, and by providing the ability to perform queries based on key ordering, they improve on existing search tools that provide only hash table functionality. Unlike skip lists or other tree data structures, skip graphs are highly resilient, tolerating a large fraction of failed nodes without losing connectivity. In addition, simple and straightforward algorithms can be used to construct a skip graph, insert new nodes into it, search it, and detect and repair errors within it introduced due to node failures."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/2278","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/2278","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13408","fieldValue":" The last few years have witnessed the emergence of a promising new memory technology, namely Phase-Change Memory (PCM). Due to its inherent ability to scale deeply into the nanoscale regime and its low power consumption, PCM is increasingly viewed as an attractive alternative for the memory subsystem of future microprocessor architectures. However, PCM is marred by a duo of potentially show-stopping deficiencies, that is, poor write performance (especially when compared to the prevalent and ubiquitous DRAM technology) and limited durability. These weaknesses have urged designers to develop various supporting architectural techniques to aid and complement the operation of the PCM while mitigating its innate flaws. One promising such solution is the deployment of hybridized memory architectures that fuse DRAM and PCM, in order to combine the best attributes of each technology. In this article, we introduce a novel Dual-Phase Compression (DPC) scheme and its architectural design aimed at DRAM\/PCM hybrids, which caters to the limitations of PCM technology while optimizing memory performance. The DPC technique is specifically optimized for PCM-based environments and is transparent to the operation of the remaining components of the memory subsystem. Furthermore, the proposed architecture is imbued with a multifaceted wear-leveling technique to enhance the durability and prolong the lifetime of the PCM. Extensive simulations with traces from real applications running on a full-system simulator demonstrate 20.4&percnt; performance improvement and 46.9&percnt; energy reduction, on average, as compared to a baseline DRAM\/PCM hybrid implementation. Additionally, the multifaceted wear-leveling technique is shown to significantly prolong the lifetime of the PCM."}