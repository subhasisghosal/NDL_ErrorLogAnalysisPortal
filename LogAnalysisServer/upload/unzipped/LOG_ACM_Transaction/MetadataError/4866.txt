{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25628","fieldValue":"PMHT"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25628","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25628","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25629","fieldValue":" The rapid growth of the number of videos on the Internet provides enormous potential for users to find content of interest. However, the vast quantity of videos also turns the finding process into a difficult task. In this article, we address the problem of providing personalized video recommendation for users. Rather than only exploring the user-video bipartite graph that is formulated using click information, we first combine the clicks and queries information to build a tripartite graph. In the tripartite graph, the query nodes act as bridges to connect user nodes and video nodes. Then, to further enrich the connections between users and videos, three subgraphs between the same kinds of nodes are added to the tripartite graph by exploring content-based information (video tags and textual queries). We propose an iterative propagation algorithm over the enhanced graph to compute the preference information of each user. Experiments conducted on a dataset with 1,369 users, 8,765 queries, and 17,712 videos collected from a commercial video search engine demonstrate the effectiveness of the proposed method."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25629","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25629","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25630","fieldValue":" Modern online social networking has drastically changed the information distribution landscape. Recently, video has become one of the most important types of objects spreading among social networking service users. The sheer and ever-increasing data volume, the broader coverage, and the longer access durations of video objects, however, present significantly more challenges than other types of objects. This article takes an initial step toward understanding the unique characteristics of video sharing propagation in social networks. Based on realworld data traces from a large-scale online social network, we examine the user behavior from diverse aspects and identify different types of users involved in video propagation. We closely investigate the temporal distribution during propagation as well as the typical propagation structures, revealing more details beyond stationary coverage. We further extend the conventional epidemic models to accommodate diverse types of users and their probabilistic viewing and sharing behaviors. The model, effectively capturing the essentials of the propagation process, serves as a valuable basis for such applications as workload synthesis, traffic prediction, and resource provision of video servers."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/25630","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/25630","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/25631","fieldValue":" Nowadays, the amount of multimedia contents in microblogs is growing significantly. More than 20&percnt; of microblogs link to a picture or video in certain large systems. The rich semantics in microblogs provides an opportunity to endow images with higher-level semantics beyond object labels. However, this raises new challenges for understanding the association between multimodal multimedia contents in multimedia-rich microblogs. Disobeying the fundamental assumptions of traditional annotation, tagging, and retrieval systems, pictures and words in multimedia-rich microblogs are loosely associated and a correspondence between pictures and words cannot be established. To address the aforementioned challenges, we present the first study analyzing and modeling the associations between multimodal contents in microblog streams, aiming to discover multimodal topics from microblogs by establishing correspondences between pictures and words in microblogs. We first use a data-driven approach to analyze the new characteristics of the words, pictures, and their association types in microblogs. We then propose a novel generative model called the Bilateral Correspondence Latent Dirichlet Allocation (BC-LDA) model. Our BC-LDA model can assign flexible associations between pictures and words and is able to not only allow picture-word co-occurrence with bilateral directions, but also single modal association. This flexible association can best fit the data distribution, so that the model can discover various types of joint topics and generate pictures and words with the topics accordingly. We evaluate this model extensively on a large-scale real multimedia-rich microblogs dataset. We demonstrate the advantages of the proposed model in several application scenarios, including image tagging, text illustration, and topic discovery. The experimental results demonstrate that our proposed model can significantly and consistently outperform traditional approaches."}