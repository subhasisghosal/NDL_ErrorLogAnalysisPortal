{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10831","fieldValue":" We present an argument in favor of forming coalitions of peers in a data swarming system consisting of peers with heterogeneous upload capacities. In this paper, a coalition refers to a set of peers that explicitly cooperate with other peers inside the coalition via choking, piece selection, and capacity allocation strategies. Furthermore, each peer in a coalition exchanges data with peers outside its coalition via distinct choking, piece selection, and capacity allocation strategies. We first propose a simple Random Choking strategy for peers inside a coalition and develop an analytical model for studying its performance. Our model accurately predicts a coalition's performance and shows that the proposed strategy helps a coalition achieve near-optimal performance. Furthermore, our model can be easily adapted to model a BitTorrent-like swarm. We show that our Random Choking strategy significantly outperforms Tit-for-Tat and Unchoke-All strategies proposed in prior work. We also introduce a simple piece selection strategy, which significantly improves data availability within a coalition as compared to Rarest-First strategy employed in BitTorrent systems. Using cooperative game theory, we prove the existence of stable coalitions when peer population is fixed and each peer has complete information of other peers' actions and payoffs. When peers are allowed to freely join or leave coalitions, we propose a Cooperation-Aware Better Response strategy that achieves convergence of the dynamic coalition formation process. Finally, using extensive simulations, we demonstrate that forming coalitions results in significant improvements in the overall performance of a data swarm."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10831","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/10831","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10831","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/10832","fieldValue":" This paper considers a hybrid peer-to-peer (p2p) system, a dynamic distributed caching system with an authoritative server dispensing contents only if the contents fail to be found by searching an unstructured p2p system. We study the case when some peers may not be fully cooperative in the search process and examine the impact of various noncooperative behaviors in the aspect of scalability, more specifically average server load and average peer load as the peer population size increases. We categorize selfish peers into three classes: impatient peers that directly query the server without searching the p2p system, non-forwarders that refuse to forward query requests, and non-resolvers that refuse to share contents. It is shown that in the hybrid p2p system, impatient and\/or non-forwarding behaviors prevent the system from scaling well because of the high server load, while the system scales well under the non-resolving selfish peers. Our study implies that the hybrid p2p system does not mandate an incentive mechanism for content sharing, which is in stark contrast to unstructured p2p systems, where incentivizing peers to share contents is known to be a key factor for the system's scalability."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/10832","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/10832","fieldValue":"Impacts of selfish behaviors on the scalability of hybrid client: server and peer-to-peer caching systems"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/10832","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/10832","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1989","fieldValue":" Iterative optimization is a simple but powerful approach that searches the best possible combination of compiler optimizations for a given workload. However, iterative optimization is plagued by several practical issues that prevent it from being widely used in practice: a large number of runs are required to find the best combination, the optimum combination is dataset dependent, and the exploration process incurs significant overhead that needs to be compensated for by performance benefits. Therefore, although iterative optimization has been shown to have a significant performance potential, it seldom is used in production compilers. In this article, we propose iterative optimization for the data center (IODC): we show that the data center offers a context in which all of the preceding hurdles can be overcome. The basic idea is to spawn different combinations across workers and recollect performance statistics at the master, which then evolves to the optimum combination of compiler optimizations. IODC carefully manages costs and benefits, and it is transparent to the end user. To bring IODC to practice, we evaluate it in the presence of co-runners to better reflect real-life data center operation with multiple applications co-running per server. We enhance IODC with the capability to find compatible co-runners along with a mechanism to dynamically adjust the level of aggressiveness to improve its robustness in the presence of co-running applications. We evaluate IODC using both MapReduce and compute-intensive throughput server applications. To reflect the large number of users interacting with the system, we gather a very large collection of datasets (up to hundreds of millions of unique datasets per program), for a total storage of 16.4TB and 850 days of CPU time. We report an average performance improvement of 1.48 Ã\u2014 and up to 2.08 Ã\u2014 for five MapReduce applications, and 1.12 Ã\u2014 and up to 1.39 Ã\u2014 for nine server applications. Furthermore, our experiments demonstrate that IODC is effective in the presence of co-runners, improving performance by greater than 13&percnt; compared to the worst possible co-runner schedule."}