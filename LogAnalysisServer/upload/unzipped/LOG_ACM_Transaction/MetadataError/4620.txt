{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24941","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24942","fieldValue":" In this article, we propose state-dependent importance sampling heuristics to estimate the probability of population overflow in Jackson queueing networks. These heuristics capture state-dependence along the boundaries (when one or more queues are empty), which is crucial for the asymptotic efficiency of the change of measure. The approach does not require difficult (and often intractable) mathematical analysis and is not limited by storage and computational requirements involved in adaptive importance sampling methodologies, particularly for a large state space. Experimental results on tandem, parallel, feed-forward, and feedback networks with a moderate number of nodes suggest that the proposed heuristics may yield asymptotically efficient estimators, possibly with bounded relative error, when applied to queueing networks wherein no other state-independent importance sampling techniques are known to be efficient. The heuristics are robust and remain effective for larger networks. Moreover, insights drawn from the basic networks considered in this article help understand sample path behavior along the boundaries, conditional on reaching the rare event of interest. This is key to the application of the methodology to networks of more general topologies. It is hoped that empirical findings and insights in this paper will encourage more research on related practical and theoretical issues."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/24942","fieldValue":"Efficient importance sampling heuristics for the simulation of population overflow in Jackson networks"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24942","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24942","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24943","fieldValue":" In this article we describe HLA_AGENT, a tool for the distributed simulation of agent-based systems, which integrates the SIM_AGENT agent toolkit and the High Level Architecture (HLA) simulator interoperability framework. HLA_AGENT offers enhanced simulation scalability and allows interoperation with other HLA-compliant simulators, promoting simulation reuse. Using a simple Tileworld example, we show how HLA_AGENT can be used to flexibly distribute a SIM_AGENT simulation so as to exploit available computing resources. We present experimental results that illustrate the performance of HLA_AGENT on a Linux cluster running a distributed version of Tileworld and compare this with the original nondistributed SIM_AGENT version."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24943","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24943","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24944","fieldValue":" We present a multivariate analysis technique called Co-Plot that is especially suitable for few samples of many variables. Co-Plot embeds the multidimensional samples in two dimensions, in a way that allows key variables to be identified, and relations between both variables and observations to be analyzed together. When applied to the workloads on parallel supercomputers, we find two stable perpendicular axes of highly correlated variables, one representing individual job attributes and the other representing multijob attributes. The different workloads, on the other hand, are rather different from one another, and may also change over time. Synthetic models for workload generation are also analyzed, and found to be reasonable in the sense that they span the same range of variable combinations as the real workloads. However, the spread of real workloads implies that a single model cannot be similar to all of them. This leads us to construct a parameterized model, with parameters that correspond to the two axes identified above. We also find that existing models do not model the temporal structure of the workload well, and hence are wanting for tasks such as comparing schedulers, and that the common methodology for load manipulation of workloads is problematic."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24944","fieldValue":"ACM"}