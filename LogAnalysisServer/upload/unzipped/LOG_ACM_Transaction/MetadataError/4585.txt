{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24851","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24851","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24852","fieldValue":" Generating a single order statistic without generating the full sample can be an important task for simulations. If the density and the CDF of the distribution are given, then it is no problem to compute the density of the order statistic. In the main theorem it is shown that the concavity properties of that density depend directly on the distribution itself. Especially for log-concave distributions, all order statistics have log-concave distributions themselves. So recently suggested automatic transformed density rejection algorithms can be used to generate single order statistics. This idea leads to very fast generators. For example for the normal and gamma distributions, the suggested new algorithms are between 10 and 60 times faster than the algorithms suggested in the literature."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24852","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24852","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24853","fieldValue":" Consider the problem of estimating the small probability that the maximum of a random walk exceeds a large threshold, when the process has a negative drift and the underlying random variables may have heavy tailed distributions, that is, their tail distribution decays at a subexponential rate. We consider one class of such problems that has applications in estimating the ruin probability associated with insurance claim processes with subexponentially distributed claim sizes, and in estimating the probability of large delays in an M\/G\/1 queue with subexponentially distributed service times. Significant work has been done on analogous problems for the light tailed case (when the tail distribution decreases at an exponential rate or faster) that involve importance sampling methods using appropriate exponential twisting. However, for the subexponential case, such exponential twisting is infeasible and alternative techniques are needed. In this paper we introduce importance sampling techniques where the new probability measure is obtained by twisting the hazard rate of the original distribution. For subexponential distributions this amounts to subexponential twisting---twisting at a subexponential rate. In addition, we introduce the technique of \"delaying\" the twisting and show that the combination of the two techniques produces asymptotically optimal estimates of the small probability mentioned above."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24853","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24853","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24854","fieldValue":" The two-node tandem Jackson network serves as a convenient reference model for the analysis and testing of different methodologies and techniques in rare event simulation. In this paper we consider a new approach to efficiently estimate the probability that the content of the second buffer exceeds some high level L before it becomes empty, starting from a given state. The approach is based on a Markov additive process representation of the buffer processes, leading to an exponential change of measure to be used in an importance sampling procedure. Unlike changes of measures proposed and studied in recent literature, the one derived here is a function of the content of the first buffer. We prove that when the first buffer is finite, this method yields asymptotically efficient simulation for any set of arrival and service rates. In fact, the relative error is bounded independent of the level L; a new result which is not established for any other known method. When the first buffer is infinite, we propose a natural extension of the exponential change of measure for the finite buffer case. In this case, the relative error is shown to be bounded (independent of L) only when the second server is the bottleneck; a result which is known to hold for some other methods derived through large deviations analysis. When the first server is the bottleneck, experimental results using our method seem to suggest that the relative error is bounded linearly in L."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24854","fieldValue":"ACM"}