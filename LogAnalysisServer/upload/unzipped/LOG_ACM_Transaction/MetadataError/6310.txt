{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/6792","fieldValue":"Dutt, Nikil D"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6792","fieldValue":" The dual effects of larger die sizes and technology scaling, combined with aggressive voltage scaling for power reduction, increase the error rates for on-chip memories. Traditional on-chip memory reliability techniques (e.g., ECC) incur significant power and performance overheads. In this article, we propose a low-power-and-performance-overhead Embedded RAID (E-RAID) strategy and present Embedded RAIDs-on-Chip (E-RoC), a distributed dynamically managed reliable memory subsystem for bus-based Chip-Multiprocessors. E-RoC achieves reliability through redundancy by optimizing RAID-like policies tuned for on-chip distributed memories. We achieve on-chip reliability of memories through the use of Distributed Dynamic ScratchPad Allocatable Memories (DSPAMs) and their allocation policies. We exploit aggressive voltage scaling to reduce power consumption overheads due to parallel DSPAM accesses, and rely on the E-RoC Manager to automatically handle any resulting voltage-scaling-induced errors. We demonstrate how E-RAIDs can further enhance the fault tolerance of traditional memory reliability approaches by designing E-RAID levels that exploit ECC. Finally, we show the power and flexibility of the E-RoC concept by showing the benefits of having a heterogeneous E-RAID levels that fit each application's needs (fault tolerance, power\/energy, performance). Our experimental results on CHStone\/Mediabench II benchmarks show that our E-RAID levels converge to 100&percnt; error-free data rates much faster than traditional ECC approaches. Moreover, E-RAID levels that exploit ECC can guarantee 99.9&percnt; error-free data rates at ultra low Vdd on average, where as traditional ECC approaches were able to attain at most 99.1&percnt; error-free data rates. We observe an average of 22&percnt; dynamic power consumption increase by using traditional ECC approaches with respect to the baseline (non-voltage scaled SPMs), whereas our E-RAID levels are able to save dynamic power consumption by an average of 27&percnt; (w.r.t. the same non-voltage scaled SPMs baseline), while incurring worst-case 2&percnt; higher performance overheads than traditional ECC approaches. By voltage scaling the memories, we see that traditional ECC approaches are able to save static energy by 6.4&percnt; (average), where as our E-RAID approaches achieve 23.4&percnt; static energy savings (average). Finally, we observe that mixing E-RAID levels allows us to further reduce the dynamic power consumption by up to 55.5&percnt; at the cost of an average 5.6&percnt; increase in execution time over traditional approaches."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6792","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6792","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1622","fieldValue":" Applications in embedded systems often need to meet specified timing constraints. It is advantageous to not only calculate the worst-case execution time (WCET) of an application, but to also perform transformation, which reduce the WCET, since an application with a lower WCET will be less likely to violate its timing constraints. Some processors incur a pipeline delay whenever an instruction transfers control to a target that is not the next sequential instruction. Code-positioning optimizations attempt to reduce these delays by positioning the basic blocks to minimize the number of unconditional jumps and taken conditional branches that occur. Traditional code-positioning algorithms use profile data to find the frequently executed edges between basic blocks, then minimize the transfers of control along these edges to reduce the average case execution time (ACET). This paper introduces a WCET code-positioning optimization, driven by the worst-case (WC) path information from a timing analyzer, to reduce the WCET instead of ACET. This WCET optimization changes the layout of the code in memory to reduce the branch penalties along the WC paths. Unlike the frequency of edges in traditional profile-driven code positioning, the WC path may change after code-positioning decisions are made. Thus, WCET code positioning is inherently more challenging than ACET code positioning. The experimental results show that this optimization typically finds the optimal layout of the basic blocks with the minimal WCET. The results show over a 7&percnt; reduction in WCET is achieved after code positioning is performed."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1622","fieldValue":"WCET"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1622","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1622","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6793","fieldValue":" We present SysPy (System Python) a tool which exploits the strengths of the popular Python scripting language to boost design productivity of embedded System on Chips for FPGAs. SysPy acts as a â\u20ACœglueâ\u20AC? software between mature HDLs, ready-to-use VHDL components and programmable processor soft IP cores. SysPy can be used to: (i) automatically translate hardware components described in Python into synthesizable VHDL, (ii) capture top-level structural descriptions of processor-centric SoCs in Python, (iii) implement all the steps necessary to compile the user's C code for an instruction set processor core and generate processor specific Tcl scripts that import to the design project all the necessary HDL files of the processor's description and instantiate\/connect the core to other blocks in a synthesizable top-level Python description. Moreover, we have developed a Hardware Abstraction Layer (HAL) in Python which allows user applications running in a host PC to utilize effortlessly the SoC's resources in the FPGA. SysPy's design capabilities, when complemented with the developed HAL software API, provide all the necessary tools for hw\/sw partitioning and iterative design for efficient SoC's performance tuning. We demonstrate how SysPy's design flow and functionalities can be used by building a processor-centric embedded SoC for computational systems biology. The designed SoC, implemented using a Xilinx Virtex-5 FPGA, combines the flexibility of a programmable soft processor core (Leon3) with the high performance of an application specific core to simulate flexibly and efficiently the stochastic behavior of large size biomolecular reaction networks. Such networks are essential for studying the dynamics of complex biological systems consisting of multiple interacting pathways."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6793","fieldValue":"FPGA"}