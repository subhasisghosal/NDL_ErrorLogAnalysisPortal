{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12277","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12277","fieldValue":"ACM"}{"fieldName":"dc.relation.haspart","informationCode":"ERR_FORMAT_HASPART","handle":"12345678_acm\/2122","fieldValue":"[{\"visible\":false,\"sortKey\":\"13\",\"expandable\":true,\"handle\":\"12345678_acm\/2135\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 13\"},{\"visible\":false,\"sortKey\":\"12\",\"expandable\":true,\"handle\":\"12345678_acm\/2134\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 12\"},{\"visible\":false,\"sortKey\":\"11\",\"expandable\":true,\"handle\":\"12345678_acm\/2133\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 11\"},{\"visible\":false,\"sortKey\":\"10\",\"expandable\":true,\"handle\":\"12345678_acm\/2132\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 10\"},{\"visible\":false,\"sortKey\":\"9\",\"expandable\":true,\"handle\":\"12345678_acm\/2131\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 9\"},{\"visible\":false,\"sortKey\":\"8\",\"expandable\":true,\"handle\":\"12345678_acm\/2130\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 8\"},{\"visible\":false,\"sortKey\":\"7\",\"expandable\":true,\"handle\":\"12345678_acm\/2129\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 7\"},{\"visible\":false,\"sortKey\":\"6\",\"expandable\":true,\"handle\":\"12345678_acm\/2128\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 6\"},{\"visible\":false,\"sortKey\":\"5\",\"expandable\":true,\"handle\":\"12345678_acm\/2127\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 5\"},{\"visible\":false,\"sortKey\":\"4\",\"expandable\":true,\"handle\":\"12345678_acm\/2126\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 4\"},{\"visible\":false,\"sortKey\":\"3\",\"expandable\":true,\"handle\":\"12345678_acm\/2125\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 3\"},{\"visible\":false,\"sortKey\":\"2\",\"expandable\":true,\"handle\":\"12345678_acm\/2124\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 2\"},{\"visible\":false,\"sortKey\":\"1\",\"expandable\":true,\"handle\":\"12345678_acm\/2123\",\"title\":\"ACM Transactions on Algorithms (TALG) : Volume 1\"}]"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12278","fieldValue":" We demonstrate that a collaborative relationship between the operating system and applications can be used to meet user-specified goals for battery duration. We first describe a novel profiling-based approach for accurately measuring application and system energy consumption. We then show how applications can dynamically modify their behavior to conserve energy. We extend the Linux operating system to yield battery lifetimes of user-specified duration. By monitoring energy supply and demand and by maintaining a history of application energy use, the approach can dynamically balance energy conservation and application quality. Our evaluation shows that this approach can meet goals that extend battery life by as much as 30&percnt;."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12278","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12278","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12279","fieldValue":" This article presents Cool-Mem, a family of memory system architectures that integrate conventional memory system mechanisms, energy-aware address translation, and compiler-enabled cache disambiguation techniques, to reduce energy consumption in general-purpose architectures. The solutions provided in this article leverage on interlayer tradeoffs between architecture, compiler, and operating system layers. Cool-Mem achieves power reduction by statically matching memory operations with energy-efficient cache and virtual memory access mechanisms. It combines statically speculative cache access modes, a dynamic content addressable memory-based (CAM-based) Tag-Cache used as backup for statically mispredicted accesses, different conventional multilevel associative cache organizations, embedded protection checking along all cache access mechanisms, as well as architectural organizations to reduce the power consumed by address translation in virtual memory. Because it is based on speculative static information, a superset of the predictable program information available at compile-time, our approach removes the burden of provable correctness in compiler analysis passes that extract static information. This makes Cool-Mem highly practical, applicable for large and complex applications, without having any limitations due to complexity issues in our compiler passes or the presence of precompiled static libraries. Based on extensive evaluation, for both SPEC2000 and Mediabench applications, we obtain from 6&percnt; to 19&percnt; total energy savings in the processor, with performance ranging from 1.5&percnt; degradation to 6&percnt; improvement, for the applications studied. We have also compared Cool-Mem to several prior arts and have found Cool-Mem to perform better in almost all cases."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/12279","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/12279","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/12280","fieldValue":" Pointer-chasing applications tend to traverse composite data structures consisting of multiple independent pointer chains. While the traversal of any single pointer chain leads to the serialization of memory operations, the traversal of independent pointer chains provides a source of memory parallelism. This article investigates exploiting such interchain memory parallelism for the purpose of memory latency tolerance, using a technique called multi--chain prefetching. Previous works [Roth et al. 1998;Roth and Sohi 1999] have proposed prefetching simple pointer-based structures in a multi--chain fashion. However, our work enables multi--chain prefetching for arbitrary data structures composed of lists, trees, and arrays.This article makes five contributions in the context of multi--chain prefetching. First, we introduce a framework for compactly describing linked data structure (LDS) traversals, providing the data layout and traversal code work information necessary for prefetching. Second, we present an off-line scheduling algorithm for computing a prefetch schedule from the LDS descriptors that overlaps serialized cache misses across separate pointer-chain traversals. Our analysis focuses on static traversals. We also propose using speculation to identify independent pointer chains in dynamic traversals. Third, we propose a hardware prefetch engine that traverses pointer-based data structures and overlaps multiple pointer chains according to the computed prefetch schedule. Fourth, we present a compiler that extracts LDS descriptors via static analysis of the application source code, thus automating multi--chain prefetching. Finally, we conduct an experimental evaluation of compiler-instrumented multi--chain prefetching and compare it against jump pointer prefetching [Luk and Mowry 1996], prefetch arrays [Karlsson et al. 2000], and predictor-directed stream buffers (PSB) [Sherwood et al. 2000].Our results show compiler-instrumented multi--chain prefetching improves execution time by 40&percnt; across six pointer-chasing kernels from the Olden benchmark suite [Rogers et al. 1995], and by 3&percnt; across four SPECint2000 benchmarks. Compared to jump pointer prefetching and prefetch arrays, multi--chain prefetching achieves 34&percnt; and 11&percnt; higher performance for the selected Olden and SPECint2000 benchmarks, respectively. Compared to PSB, multi--chain prefetching achieves 27&percnt; higher performance for the selected Olden benchmarks, but PSB outperforms multi--chain prefetching by 0.2&percnt; for the selected SPECint2000 benchmarks. An ideal PSB with an infinite Markov predictor achieves comparable performance to multi--chain prefetching, coming within 6&percnt; across all benchmarks. Finally, speculation can enable multi--chain prefetching for some dynamic traversal codes, but our technique loses its effectiveness when the pointer-chain traversal order is highly dynamic."}