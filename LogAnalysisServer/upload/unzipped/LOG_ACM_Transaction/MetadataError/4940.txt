{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/3504","fieldValue":"Allison, Robert S"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/3504","fieldValue":"Wilcox, Laurie M"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3504","fieldValue":" An intriguing aspect of picture perception is the viewerâ\u20AC™s tolerance to variation in viewing position, perspective, and display size. These factors are also present in stereoscopic media, where there are additional parameters associated with the camera arrangement (e.g., separation, orientation). The predicted amount of depth from disparity can be obtained trigonometrically; however, perceived depth in complex scenes often differs from geometric predictions based on binocular disparity alone. To evaluate the extent and the cause of deviations from geometric predictions of depth from disparity in naturalistic scenes, we recorded stereoscopic footage of an indoor scene with a range of camera separations (camera interaxial (IA) ranged from 3 to 95 mm) and displayed them on a range of screen sizes. In a series of experiments participants estimated 3D distances in the scene relative to a reference scene, compared depth between shots with different parameters, or reproduced the depth between pairs of objects in the scene using reaching or blind walking. The effects of IA and screen size were consistently and markedly smaller than predicted from the binocular viewing geometry, suggesting that observers are able to compensate for the predicted distortions. We conclude that the presence of multiple realistic monocular depth cues drives normalization of perceived depth from binocular disparity. It is not clear to what extent these differences are due to cognitive as opposed to perceptual factors. However, it is notable that these normalization processes are not task specific; they are evident in both perception- and action-oriented tasks."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3504","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3504","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3505","fieldValue":" In this article, we investigate the perception of gender from the motion of virtual humans under different emotional conditions and explore the effect of emotional bias on gender perception (e.g., anger being attributed to males more than females). As motion types can present different levels of physiological cues, we also explore how two types of motion (walking and conversations) are affected by emotional bias. Walking typically displays more physiological cues about gender (e.g., hip sway) and therefore is expected to be less affected by emotional bias. To investigate these effects, we used a corpus of captured facial and body motions from four male and four female actors, performing basic emotions through conversation and walk. We expected that the appearance of the model would also influence gender perception; therefore, we displayed both male and female motions on two virtual models of different sex. Two experiments were then conducted to assess gender judgments from these motions. In both experiments, participants were asked to rate how male or female they considered the motions to be under different emotional states, then classified the emotions to determine how accurately they were portrayed by actors. Overall, both experiments showed that gender ratings were affected by the displayed emotion. However, we found that conversations were influenced by gender stereotypes to a greater extent than walking motions. This was particularly true for anger, which was perceived as male on both male and female motions, and sadness, which was perceived as less male when portrayed by male actors. We also found a slight effect of the model when observing gender on different types of virtual models. These results have implications for the design and animation of virtual humans."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3505","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3505","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1026","fieldValue":" Data dependence distance is widely used to characterize data dependences in advance optimizing compilers. The standard definition of dependence distance assumes that loops are normalized (have constant lower bounds and a step of 1); there is not a commonly accepted definition for unnormalized loops. We have identified several potential definitions, all of which give the same answer for normalized loops. There are a number of subtleties involved in choosing between these definitions, and no one definition is suitable for all applications."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1026","fieldValue":"ACM"}