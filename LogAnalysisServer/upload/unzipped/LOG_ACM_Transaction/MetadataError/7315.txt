{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/9448","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/9448","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/9449","fieldValue":" The expedited forwarding per-hop behavior (EF PHB) was recently replaced by a new definition, called packet scale rate guarantee (PSRG), under the Differentiated Services (DiffServ) framework. This replacement raises two challenges. One is the implementation of a PSRG server. Another is the provision of per-domain PSRG. Specifically, for the former, an open issue is whether hierarchical schedulers can provide PSRG; for the latter, it is not clear whether and how per-domain PSRG can be provided in the presence of flow aggregation. Since, in DiffServ networks, flow aggregation is a natural phenomenon and hierarchical scheduling is high-likely desired, these two challenges become even more critical. To address the first challenge, we introduce a new concept called latency-rate worst-case service guarantee (LR-WSG). We prove that, if a server provides LR-WSG, it also provides PSRG. We show that many well-known schedulers support LR-WSG, which include not only one-level schedulers but also their hierarchical versions. To address the second challenge, we first prove that PSRG can be extended from per-node to per-domain if no flow aggregation is performed. The proof is notable in that it depends solely on the concept of PSRG itself. We then investigate the provision of per-domain PSRG in presence of flow aggregation. We propose to use packet scale fair aggregator (PSFA) to aggregate flows. We show that, with PSFA, per-domain PSRG can be provided in spite of flow aggregation. We finally provide a brief discuss on the viability of using PSFA in DiffServ networks and define an expedited forwarding per-domain behavior (EF PDB)."}{"fieldName":"dc.identifier.other","informationCode":"ERR_NULL_VALUE","handle":"12345678_acm\/9449","fieldValue":"{\"eissn\":\"\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/9449","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/9449","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/9450","fieldValue":"Chang, Cheng-Shang"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/9450","fieldValue":"Lee, Duan-Shin"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/9450","fieldValue":"Yue, Chi-Yao"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/9450","fieldValue":" In this paper, we propose two schemes for the load balanced Birkhoff-von Neumann switches to provide guaranteed rate services. The first scheme is based on an earliest eligible time first (EETF) policy. In such a scheme, we assign every packet of a guaranteed rate flow a targeted departure time that is the departure time from the corresponding work conserving link with capacity equal to the guaranteed rate. By implementing the EETF policy with jitter control mechanisms and first come first serve (FCFS) queues, we show that the end-to-end delay for every packet of a guaranteed rate flow is bounded by the sum of its targeted departure time and a constant that only depends on the number of flows and the size of the switch.Our second scheme is a frame based scheme as in Keslassy and McKeown, 2002. There, time slots are grouped into fixed size frames. Packets are placed in appropriate bins (buffers) according to their arrival times and their flows. We show that if the incoming traffic satisfies certain rate assumptions, then the end-to-end delay for every packet and the size of the central buffers are both bounded by constants that only depend on the size of the switches and the frame size. The second scheme is much simpler than the first one in many aspects: 1) the on-line complexity is O(1) as there is no need for complicated scheduling; 2) central buffers are finite and thus can be built into a single chip; 3) connection patterns of the two switch fabrics are changed less frequently; 4) there is no need for resequencing-and-output buffer after the second stage; and 5) variable length packets may be handled without segmentation and reassembly."}