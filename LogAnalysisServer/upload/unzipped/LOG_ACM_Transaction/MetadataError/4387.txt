{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24142","fieldValue":" If a piece of information is released from a set of media sites, can it spread, in 1 month, to a million web pages? Can we efficiently find a small set of media sites among millions that can maximize the spread of the information, in 1 month? The two problems are called influence estimation and maximization problems respectively, which are very challenging since both the time-sensitive nature of the problems and the issue of scalability need to be addressed simultaneously. In this article, we propose two algorithms for influence estimation in continuous-time diffusion networks. The first one uses continuous-time Markov chains to estimate influence exactly on networks with exponential, or, more generally, phase-type transmission functions, but does not scale to large-scale networks, and the second one is a highly efficient randomized algorithm, which estimates the influence of every node in a network with general transmission functions, &verbar;Î½&verbar; nodes and &verbar;&epsiv;&verbar; edges to an accuracy of &epsi; using n &equals; $O(1\/&epsi;^2$) randomizations and up to logarithmic factors O(n&verbar;&epsiv;&verbar;+n&verbar;Î½&verbar; computations. We then show that finding the set of most influential source nodes in a continuous time diffusion network is an NP-hard problem and develop an efficient greedy algorithm with provable near-optimal performance. When used as subroutines in the influence maximization algorithm, the exact influence estimation algorithm is guaranteed to find a set of C nodes with an influence of at least (1 âˆ\u2019 1\/e)OPT and the randomized algorithm is guaranteed to find a set with an influence of at least 1 âˆ\u2019 1\/e)OPT âˆ\u2019 2C&epsiv;, where OPT is the optimal value. Experiments on both synthetic and real-world data show that the proposed algorithms significantly improve over previous state-of-the-art methods in terms of the accuracy of the estimated influence and the quality of the selected nodes to maximize the influence, and the randomized algorithm can easily scale up to networks of millions of nodes."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24142","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24142","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/24143","fieldValue":"Ming, Zhao-Yan"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/24143","fieldValue":"Zhao, Yi-Liang"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/24143","fieldValue":"Chua, Tat-Seng"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/24143","fieldValue":" Volunteers have always been extremely crucial and in urgent need for nonprofit organizations (NPOs) to sustain their continuing operations. However, it is expensive and time-consuming to recruit volunteers using traditional approaches. In the Web 2.0 era, abundant and ubiquitous social media data opens a door to the possibility of automatic volunteer identification. In this article, we aim to fully explore this possibility by proposing a scheme that is able to predict usersâ\u20AC™ volunteerism tendency from user-generated contents collected from multiple social networks based on a conceptual volunteering decision model. We conducted comprehensive experiments to investigate the effectiveness of our proposed scheme and further discussed its generalizibility and extendability. This novel interdisciplinary research will potentially inspire more promising and important human-centered applications."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/24143","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/24143","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3346","fieldValue":" The visual complexity of Web pages is much talked about; â\u20ACœcomplex Web pages are difficult to use,â\u20AC? but often regarded as a subjective decision by the user. This subjective decision is of limited use if we wish to understand the importance of visual complexity, what it means, and how it can be used. We theorize that by understanding a user's visual perception of Web page complexity, we can understand the cognitive effort required for interaction with that page. This is important because by using an easily identifiable measure, such as visual complexity, as an implicit marker of cognitive load, we can design Web pages which are easier to interact with. We have devised an initial empirical experiment, using card sorting and triadic elicitation, to test our theories and assumptions, and have built an initial baseline sequence of 20 Web pages along with a library of qualitative and anecdotal feedback. Using this library, we define visual complexity, ergo perceived interaction complexity, and by taking these pages as â\u20ACœprototypesâ\u20AC? and ranking them into a sequence of complexity, we are able to group them into: simple, neutral, and complex. This means we can now work toward a definition of visual complexity as an implicit measure of cognitive load."}