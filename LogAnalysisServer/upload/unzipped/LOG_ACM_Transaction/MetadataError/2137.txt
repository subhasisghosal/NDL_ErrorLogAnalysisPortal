{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17196","fieldValue":" We present \"appearance-from-motion\", a novel method for recovering the spatially varying isotropic surface reflectance from a video of a rotating subject, with known geometry, under unknown natural illumination. We formulate the appearance recovery as an iterative process that alternates between estimating surface reflectance and estimating incident lighting. We characterize the surface reflectance by a data-driven microfacet model, and recover the microfacet normal distribution for each surface point separately from temporal changes in the observed radiance. To regularize the recovery of the incident lighting, we rely on the observation that natural lighting is sparse in the gradient domain. Furthermore, we exploit the sparsity of strong edges in the incident lighting to improve the robustness of the surface reflectance estimation. We demonstrate robust recovery of spatially varying isotropic reflectance from captured video as well as an internet video sequence for a wide variety of materials and natural lighting conditions."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17196","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17196","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17197","fieldValue":"Di Renzo, Francesco"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17197","fieldValue":" Editing spatially-varying appearance is commonplace in most graphics applications. In this paper, we focus on materials whose appearance is described by BRDFs or BSSRDFs, with parameters specified by textures, and with local frame perturbations, namely bump, normal and tangent maps. Editing these materials amounts to editing the textures that encode the spatial variation. To perform these edits, artists commonly adopt imaging softwares since they have rich toolsets and well-understood user interfaces. But editing material parameters as images does not produce consistent results since the parameters' behaviours in their relative spaces are not taken in account. Our goal is to address this issue with a solution that is practical, in that we do not want to change material representation or editing workflow to ensure adoption. We observe that most image editing operations can be written as linear combination of colors. We thus define editing spaces for material parameters such that linear operations in these spaces respect their inherent meaning of the parameters. Transformations to and from editing spaces are non-linear to capture the non-linear behaviour of the parameters. Since GPUs are particularly efficient when executing linear operations, they can be used well with editing spaces. We demonstrate the use of editing spaces to edit microfacet BRDFs and SubEdit BSSRDFs by performing various imaging operations such as layering, linear and non-linear filtering, local and global contrast enhancements, and hardware-accelerated painting."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17197","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17197","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17198","fieldValue":"Dischler, Jean-Michel"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17198","fieldValue":" Local random-phase noise is a noise model for procedural texturing. It is defined on a regular spatial grid by local noises, which are sums of cosines with random phase. Our model is versatile thanks to separate sampling in the spatial and spectral domains. Therefore, it encompasses Gabor noise and noise by Fourier series. A stratified spectral sampling allows for a faithful yet compact and efficient reproduction of an arbitrary power spectrum. Noise by example is therefore obtained faster than state-of-the-art techniques. As a second contribution we address texture by example and generate not only Gaussian patterns but also structured features present in the input. This is achieved by fixing the phase on some part of the spectrum. Generated textures are continuous and non-repetitive. Results show unprecedented framerates and a flexible visual result: users can control with one parameter the blending between noise by example and structured texture synthesis."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17198","fieldValue":"ACM"}