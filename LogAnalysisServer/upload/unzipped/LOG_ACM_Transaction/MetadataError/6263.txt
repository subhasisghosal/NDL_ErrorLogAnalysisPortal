{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6679","fieldValue":" Hierarchical SDF models are not compositional: a composite SDF actor cannot be represented as an atomic SDF actor without loss of information that can lead to rate inconsistency or deadlock. Motivated by the need for incremental and modular code generation from hierarchical SDF models, we introduce in this paper DSSF profiles. DSSF (Deterministic SDF with Shared FIFOs) forms a compositional abstraction of composite actors that can be used for modular compilation. We provide algorithms for automatic synthesis of non-monolithic DSSF profiles of composite actors given DSSF profiles of their sub-actors. We show how different trade-offs can be explored when synthesizing such profiles, in terms of compactness (keeping the size of the generated DSSF profile small) versus reusability (maintaining necessary information to preserve rate consistency and deadlock-absence) as well as algorithmic complexity. We show that our method guarantees maximal reusability and report on a prototype implementation."}{"fieldName":"dc.identifier.other","informationCode":"ERR_FORMAT_DOI","handle":"12345678_acm\/6679","fieldValue":"{\"doi\":\"http:\/\/dx.doi.org\/10.1145\/2442116.2442133\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6679","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6679","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6680","fieldValue":" In recent years, improved wireless technologies have enabled the low-cost deployment of large numbers of sensors for a wide range of monitoring applications. Because of the computational resources (processing capability, storage capacity, etc.) collocated with each sensor in a wireless network, it is often possible to perform advanced data analysis tasks autonomously and in-network, eliminating the need for the post-processing of sensor data. With new parallel algorithms being developed for in-network computation, it has become necessary to create a framework in which all of a wireless network's scarce resources (CPU time, wireless bandwidth, storage capacity, battery power, etc.) can be best utilized in the midst of competing computational requirements. In this study, a market-based method is developed to autonomously distribute these scarce network resources across various computational tasks with competing objectives and\/or resource demands. This method is experimentally validated on a network of wireless sensing prototypes, where it is shown to be capable of Pareto-optimally allocating scarce network resources. Then, it is applied to the real-world problem of rupture detection in shipboard chilled water systems."}{"fieldName":"dc.identifier.other","informationCode":"ERR_FORMAT_DOI","handle":"12345678_acm\/6680","fieldValue":"{\"doi\":\"http:\/\/dx.doi.org\/10.1145\/2442116.2442134\"}"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6680","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6680","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/1613","fieldValue":" To reduce the cost of cycle-accurate software simulation of microarchitectures, many researchers use statistical sampling: by simulating only a small, representative subset of the end-to-end dynamic instruction stream in cycle-accurate detail, simulation results complete in much less time than simulating the cycle-by-cycle progress of an entire benchmark. In order for sampled simulation results to accurately reflect the nature the full dynamic instruction stream, however, state in the simulated cache and branch predictor must match or closely approximate state as it would have appeared had cycle-accurate simulation been used for the entire simulation. Researchers typically address this issue by prefixing a period of warmup---in which cache and branch predictor state are modeled in addition to programmer-visible architected state---to each cluster of contiguous instructions in the sample.One conservative, but slow approach is to always simulate cache and branch predictor state, whether among the cycle-accurate clusters, or among the instructions preceding each cluster. To save time, warmup heuristics have been proposed, but there is no one-size-fits-all heuristic for any benchmark. More rigorous, analytical warmup approaches are necessary in order to balance the requirements of high accuracy and rapidity from sampled simulations. This paper explores this issue and in particular demonstrates the merits of memory reference reuse latency (MRRL).Relative to the IPC measured by modeling all precluster cache and branch predictor activity, MRRL generated an average error in IPC of less than 1&percnt; and simultaneously reduced simulation running times by an average of approximately 50&percnt; (or 95&percnt; of the maximum potential speedup)."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1613","fieldValue":"ACM"}