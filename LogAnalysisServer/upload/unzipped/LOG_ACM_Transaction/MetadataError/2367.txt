{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17772","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17773","fieldValue":" We propose a unified methodology to analyze the performance of caches (both isolated and interconnected), by extending and generalizing a decoupling technique originally known as Cheâ\u20AC™s approximation, which provides very accurate results at low computational cost. We consider several caching policies (including a very attractive one, called k-LRU), taking into account the effects of temporal locality. In the case of interconnected caches, our approach allows us to do better than the Poisson approximation commonly adopted in prior work. Our results, validated against simulations and trace-driven experiments, provide interesting insights into the performance of caching systems."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17773","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17773","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/17774","fieldValue":"Lui, John C S"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17774","fieldValue":" Today, online crowdsourcing services like Amazon Mechanical Turk, UpWork, and Yahoo&excl; Answers are gaining in popularity. For such online services, it is important to attract â\u20ACœworkersâ\u20AC? to provide high-quality solutions to the â\u20ACœtasksâ\u20AC? outsourced by â\u20ACœrequesters.â\u20AC? The challenge is that workers have different skill sets and can provide different amounts of effort. In this article, we design a class of incentive and reputation mechanisms to solicit high-quality solutions from workers. Our incentive mechanism allows multiple workers to solve a task, splits the reward among workers based on requester evaluations of the solution quality, and guarantees that high-skilled workers provide high-quality solutions. However, our incentive mechanism suffers the potential risk that a requester will eventually collects low-quality solutions due to fundamental limitations in task assigning accuracy. Our reputation mechanism ensures that low-skilled workers do not provide low-quality solutions by tracking workersâ\u20AC™ historical contributions and penalizing those workers having poor reputations. We show that by coupling our reputation mechanism with our incentive mechanism, a requester can collect at least one high-quality solution. We present an optimization framework to select parameters for our reputation mechanism. We show that there is a trade-off between system efficiency (i.e., the number of tasks that can be solved for a given reward) and revenue (i.e., the amount of transaction fees), and we present the optimal trade-off curve between system efficiency and revenue. We demonstrate the applicability and effectiveness of our mechanisms through experiments using a real-world dataset from UpWork. We infer model parameters from this data, use them to determine proper rewards, and select the parameters of our incentive and reputation mechanisms for UpWork. Experimental results show that our incentive and reputation mechanisms achieve 98.82&percnt; of the maximum system efficiency while only sacrificing 4&percnt; of revenue."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17774","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/17774","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/17775","fieldValue":" Motivated by emerging big streaming data processing paradigms (e.g., Twitter Storm, Streaming MapReduce), we investigate the problem of scheduling graphs over a large cluster of servers. Each graph is a job, where nodes represent compute tasks and edges indicate data flows between these compute tasks. Jobs (graphs) arrive randomly over time and, upon completion, leave the system. When a job arrives, the scheduler needs to partition the graph and distribute it over the servers to satisfy load balancing and cost considerations. Specifically, neighboring compute tasks in the graph that are mapped to different servers incur load on the network; thus a mapping of the jobs among the servers incurs a cost that is proportional to the number of â\u20ACœbroken edges.â\u20AC? We propose a low-complexity randomized scheduling algorithm that, without service preemptions, stabilizes the system with graph arrivals\/departures; more importantly, it allows a smooth tradeoff between minimizing average partitioning cost and average queue lengths. Interestingly, to avoid service preemptions, our approach does not rely on a Gibbs sampler; instead, we show that the corresponding limiting invariant measure has an interpretation stemming from a loss system."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/17775","fieldValue":"ACM"}