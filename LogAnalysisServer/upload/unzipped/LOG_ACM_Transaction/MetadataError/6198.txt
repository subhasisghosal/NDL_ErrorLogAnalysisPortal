{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/6531","fieldValue":"OBoyle, Michael F P"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6531","fieldValue":" Embedded processor performance is dependent on both the underlying architecture and the compiler optimizations applied. However, designing both simultaneously is extremely difficult to achieve due to the time constraints designers must work under. Therefore, current methodology involves designing compiler and architecture in isolation, leading to suboptimal performance of the final product. This article develops a novel approach to this codesign space problem. For our specific design space, we demonstrate that we can automatically predict the performance that an optimizing compiler would achieve without actually tuning it for any of the microarchitecture configurations considered. Once trained, a single run of the program compiled with the standard optimization setting is enough to make a prediction on the new microarchitecture with just a 3.2&percnt; error rate on average. This allows the designer to accurately choose an architectural configuration with knowledge of how an optimizing compiler will perform on it. We use this to find the best optimizing compiler\/architectural configuration in our codesign space and demonstrate that it achieves an average 19&percnt; performance improvement and energy savings of 16&percnt; compared to the baseline, nearly doubling the energy-efficiency measured as the energy-delay-squared product (EDD)."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/6531","fieldValue":"Exploring and Predicting the Effects of Microarchitectural Parameters and Compiler Optimizations on Performance and Energy"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6531","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6531","fieldValue":"ACM"}{"fieldName":"dc.contributor.author","informationCode":"WARN_INVALID_PERSON","handle":"12345678_acm\/6532","fieldValue":"TECS Staff"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6532","fieldValue":" In order to speed up the publication process, we have begun to publish supplemental online-only issues. The following abstracts describe the articles in the first such issue, Vol. 11S(1). These articles are available in the Digital Library."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/6532","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/6532","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/6533","fieldValue":" Processor Idle Cycle Aggregation (PICA) is a promising approach for low-power execution of processors, in which small memory stalls are aggregated to create large ones, enabling profitable switch of the processor into low-power mode. We extend the previous approach in three dimensions. First we develop static analysis for the PICA technique and present optimal parameters for five common types of loops based on steady-state analysis. Second, to remedy the weakness of software-only control in varying environment, we enhance PICA with minimal hardware extension that ensures correct execution for any loops and parameters, thus greatly facilitating exploration-based parameter tuning. Third, we demonstrate that our PICA technique can be applied to certain types of nested loops with variable bounds, thus enhancing the applicability of PICA. We validate our analytical model against simulation-based optimization and also show, through our experiments on embedded application benchmarks, that our technique can be applied to a wide range of loops with average 20&percnt; energy reductions, compared to executions without PICA."}