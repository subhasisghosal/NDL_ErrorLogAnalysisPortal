{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13231","fieldValue":"GALS"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13231","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13231","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13232","fieldValue":" Due to technological scaling, process variations have increased significantly, resulting in large variations in the delay of the functional units. Hence, the worst-case approach is becoming increasingly pessimistic in meeting a certain performance yield. The problem therefore is to increase the performance as much as possible while maintaining the desired yield. In this work, we introduce an integer linear programming (ILP) formulation for scheduling and resource binding in high-level synthesis (HLS) which tries to mitigate the effect of timing variations. In the presence of delay variations of resources, as chained resources can give a better latency and performance yield trade-off, instead of considering them independently, we consider external chaining of resources, that is, two or more resources are connected by external wiring, and exploit operation chaining. Without violating the yield constraints, the proposed ILP formulation chains two consecutive operations and binds these chained operations to chained resources for minimizing the overall latency of the schedule. Our ILP formulation also makes sure that two consecutive operations can be chained over multiple clock cycles so that it becomes possible to access the data in the middle of the chained operations at the start of the clock steps over which the operations are chained. By solving our ILP formulation using ILOG CPLEX, we show that our mechanism achieves lesser latency in most cases, compared to the no-chaining case. Significant performance improvement is achieved even for the 100&percnt; yield case, which has never been demonstrated in any published work, to the best of our knowledge."}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13232","fieldValue":"HLS"}{"fieldName":"dc.subject","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13232","fieldValue":"ILP"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13232","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/13232","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/13233","fieldValue":" Although state-of-the-art field-programmable gate arrays offer exciting new opportunities in exploring low-cost high-performance architectures for data-intensive scientific applications, they also present serious challenges. Multiprocessor-on-programmable-chip, which integrates software programmability and hardware reconfiguration, provides substantial flexibility that results in shorter design cycles, higher performance, and lower cost. In this article, we present an application-specific design methodology for multiprocessor-on-programmable-chip architectures that target applications involving large matrices and floating-point operations. Given an application with specific energy-performance and resource constraints, our methodology aims to customize the architecture to match the diverse computation and communication requirements of the application tasks. Graph-based analysis of the application drives system synthesis that employs a precharacterized, parameterized hardware component library of functional units. Extensive experimental results for three diverse applications are presented to demonstrate the efficacy of our design methodology."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/13233","fieldValue":"ACM"}