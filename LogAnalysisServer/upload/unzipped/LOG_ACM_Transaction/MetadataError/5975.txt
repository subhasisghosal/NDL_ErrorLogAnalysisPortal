{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5856","fieldValue":" Designing computer-human interfaces for multiple-goal environments is challenging because people pursue multiple goals with conflicting priorities. Safety-critical environments, such as driving, aggravate the need for a more nuanced understanding of interfaces that may reconcile conflicting tasks. Speech interfaces are prime examples of such interfaces. In this article, we investigate how design variations of an in-vehicle speech interface influence performance of a primary task (driving safely) and a secondary task (e-mailing). In a controlled experiment, we test the performance implications of using single computer-generated Text-To-Speech (TTS) voice and multiple matching TTS voices while users respond to e-mails with varying levels of complexity during driving. Our results indicate that the number of voices used has a significant effect on both driving performance and handling e-mail--related activities. We discuss potentially unintended consequences of making the interface too naturalistic and too engaging for the driver and conclude with theoretical and practical implications."}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/5856","fieldValue":"Designing interfaces for multiple-goal environments: Experimental insights from in-vehicle speech interfaces"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/5856","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/5856","fieldValue":"ACM"}{"fieldName":"dc.title","informationCode":"WARN_TEXT_LENGTH_LARGE","handle":"12345678_acm\/1492","fieldValue":"Perspectives on Speech and Language Interaction for Daily Assistive Technology: Overall Introduction to the Special Issue Part 3"}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/1492","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/1492","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/5857","fieldValue":" A common methodology for evaluating text entry methods is to ask participants to transcribe a predefined set of memorable sentences or phrases. In this article, we explore if we can complement the conventional transcription task with a more externally valid composition task. In a series of large-scale crowdsourced experiments, we found that participants could consistently and rapidly invent high quality and creative compositions with only modest reductions in entry rates. Based on our series of experiments, we provide a best-practice procedure for using composition tasks in text entry evaluations. This includes a judging protocol which can be performed either by the experimenters or by crowdsourced workers on a microtask market. We evaluated our composition task procedure using a text entry method unfamiliar to participants. Our empirical results show that the composition task can serve as a valid complementary text entry evaluation method."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/5857","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/5857","fieldValue":"ACM"}