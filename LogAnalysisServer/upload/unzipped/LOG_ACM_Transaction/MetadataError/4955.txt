{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3541","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3541","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3542","fieldValue":" Material categorization from natural texture images proceeds quickly and accurately, supporting a number of visual and motor behaviors. In real-world settings, mechanisms for material categorization must function effectively based on the input from foveal vision, where image representation is high fidelity, and the input from peripheral vision, which is comparatively impoverished. What features support successful material categorization in the visual periphery, given the known reductions in acuity, contrast sensitivity, and other lossy transforms that reduce the fidelity of image representations? In general, the visual features that support material categorization remain largely unknown, but recent work suggests that observersâ\u20AC™ abilities in a number of tasks that depend on peripheral vision can be accounted for by assuming that the visual system has access to only summary statistics (texture-like descriptors) of image structure. We therefore hypothesized that a model of peripheral vision based on the Portilla-Simoncelli texture synthesis algorithm might account for material categorization abilities in the visual periphery. Using natural texture images and synthetic images made from these stimuli, we compared performance across material categories to determine whether observer performance with natural inputs could be predicted by their performance with synthetic images that reflect the constraints of a texture code."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3542","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3542","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3543","fieldValue":" In this article, we detail a series of experiments that examines the effect of vertical field-of-view extension and the addition of non-specific peripheral visual stimulation on gait characteristics and distance judgments in a head-worn virtual environment. Specifically, we examined four field-of-view configurations: a common 60Â° diagonal field of view (48Â° Ã\u2014 40Â°), a 60Â° diagonal field of view with the addition of a luminous white frame in the far periphery, a field of view with an extended upper edge, and a field of view with an extended lower edge. We found that extension of the field of view, either with spatially congruent or spatially non-informative visuals, resulted in improved distance judgments and changes in observed posture. However, these effects were not equal across all field-of-view configurations, suggesting that some configurations may be more appropriate than others when balancing performance, cost, and ergonomics."}{"fieldName":"dc.publisher","informationCode":"WARN_TEXT_LENGTH_SMALL","handle":"12345678_acm\/3543","fieldValue":"ACM"}{"fieldName":"dc.publisher","informationCode":"WARN_ALL_WORD_UPPER","handle":"12345678_acm\/3543","fieldValue":"ACM"}{"fieldName":"dc.description.abstract","informationCode":"ERR_SPACE_AT_EDGE","handle":"12345678_acm\/3544","fieldValue":" Audio, visual, and proprioceptive actions are involved when manipulating a graphic tablet musical interface. Previous works suggested a possible dominance of the visual over the auditory modality in this situation. The main goal of the present study is to examine the interferences between these modalities in visual, audio, and audio-visual target acquisition tasks. Experiments are based on a movement replication paradigm, where a subject controls a cursor on a screen or the pitch of a synthesized sound by changing the stylus position on a covered graphic tablet. The experiments consisted of the following tasks: (1) a target acquisition task that was aimed at a visual target (reaching a cue with the cursor displayed on a screen), an audio target (reaching a reference note by changing the pitch of the sound played in headsets), or an audio-visual target, and (2) the replication of the target acquisition movement in the opposite direction. In the return phase, visual and audio feedback were suppressed. Different gain factors perturbed the relationships among the stylus movements, visual cursor movements, and audio pitch movements. The deviations between acquisition and return movements were analyzed. The results showed that hand amplitudes varied in accordance with visual, audio, and audio-visual perturbed gains, showing a larger effect for the visual modality. This indicates that visual, audio, and audio-visual actions interfered with the motor modality and confirms the spatial representation of pitch reported in previous studies. In the audio-visual situation, vision dominated over audition, as the latter had no significant influence on motor movement. Consequently, visual feedback is helpful for musical targeting of pitch on a graphic tablet, at least during the learning phase of the instrument. This result is linked to the underlying spatial organization of pitch perception. Finally, this work brings a complementary approach to previous studies showing that audition may dominate over vision for other aspects of musical sound (e.g., timing, rhythm, and timbre)."}{"fieldName":"dc.description","informationCode":"ERR_FOUND_HTML_TAG","handle":"12345678_acm\/3544","fieldValue":"Author Affiliation: LIMSI, CNRS, Universit&#233; Paris-Saclay, Orsay, France (Perrotin, Olivier; Dalessandro, Christophe)"}